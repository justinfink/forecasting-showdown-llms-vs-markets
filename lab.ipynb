{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting Showdown: Prediction Markets vs. Frontier LLMs\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This project compares forecasting accuracy across three categories of forecasters:\n",
    "\n",
    "1. **Prediction Markets** (Polymarket + Kalshi) â€” real-money markets where participants trade on event outcomes\n",
    "2. **Frontier LLMs â€” Vanilla** (GPT-5, Gemini, Claude) â€” prompted with only the question, relying on training data\n",
    "3. **Frontier LLMs â€” Tool-Augmented** (same models with real-time data tools) â€” given access to FRED and EIA APIs\n",
    "\n",
    "### Metrics\n",
    "\n",
    "**Brier Score** measures calibration â€” how well probability estimates match actual outcomes:\n",
    "\n",
    "$$BS = \\frac{1}{N} \\sum_{i=1}^{N} (p_i - o_i)^2$$\n",
    "\n",
    "- $p_i$ = predicted probability, $o_i$ = outcome (0 or 1)\n",
    "- Lower is better: 0 = perfect, 0.25 = no skill (always predicting 50%), 1 = worst\n",
    "\n",
    "**Hypothetical Returns** test profitability via a threshold-based betting strategy against prediction market prices.\n",
    "\n",
    "### Domains\n",
    "- **Federal Funds Rate**: Will the Fed cut rates at upcoming FOMC meetings?\n",
    "- **Gas Prices**: Will US national average gasoline prices exceed/fall below specific thresholds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Environment Setup\n# Loads API keys from a .env file (local) or Colab Secrets (Google Colab).\nimport os\nimport sys\nfrom pathlib import Path\n\n# --- Google Colab Support ---\nif \"google.colab\" in sys.modules:\n    print(\"Running in Google Colab\")\n    print(\"Add your API keys to Colab Secrets (key icon in the left sidebar).\")\n    try:\n        from google.colab import userdata\n        for key in [\n            \"OPENAI_API_KEY\", \"GOOGLE_API_KEY\", \"GEMINI_API_KEY\",\n            \"ANTHROPIC_API_KEY\", \"FRED_API_KEY\", \"EIA_API_KEY\",\n        ]:\n            try:\n                os.environ[key] = userdata.get(key)\n            except Exception:\n                pass  # Key not set in Colab secrets -- that's ok\n    except ImportError:\n        pass\n\n# --- Local: load from .env file ---\nelse:\n    try:\n        from dotenv import load_dotenv\n        env_file = Path(\".env\")\n        if env_file.exists():\n            load_dotenv(env_file, override=True)\n            print(\"Loaded API keys from .env\")\n        else:\n            print(\"No .env file found -- using existing environment variables.\")\n            print(\"Copy .env.example to .env and fill in your keys.\")\n    except ImportError:\n        print(\"python-dotenv not installed -- run: pip install python-dotenv\")\n\n# --- Report key status ---\nKEYS = {\n    \"OPENAI_API_KEY\":    \"Required -- GPT models\",\n    \"GOOGLE_API_KEY\":    \"Required -- Gemini models\",\n    \"GEMINI_API_KEY\":    \"Required -- Gemini models (alias)\",\n    \"ANTHROPIC_API_KEY\": \"Required -- Claude models\",\n    \"FRED_API_KEY\":      \"Required -- Fed rate data  (free at fred.stlouisfed.org/docs/api/api_key.html)\",\n    \"EIA_API_KEY\":       \"Required -- Gas price data (free at eia.gov/opendata)\",\n}\nall_set = True\nfor key, desc in KEYS.items():\n    status = \"set\" if os.environ.get(key) else \"MISSING\"\n    if not os.environ.get(key):\n        all_set = False\n    print(f\"  {status}  {key}  ({desc})\")\n\nif not all_set:\n    print(\"Some keys are missing. See README.md for setup instructions.\")\nelse:\n    print(\"All API keys loaded.\")"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded.\n",
      "FRED API key: MISSING\n",
      "EIA API key: MISSING\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import seaborn as sns\n",
    "from fredapi import Fred\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# --- Model Configuration ---\n",
    "MODELS = {\n",
    "    \"gemini\": {\n",
    "        \"name\": \"Gemini 2.5 Flash Lite\",\n",
    "        \"provider\": \"google\",\n",
    "        \"model_id\": \"gemini-2.5-flash-lite\",\n",
    "    },\n",
    "    \"gpt\": {\n",
    "        \"name\": \"GPT-5\",\n",
    "        \"provider\": \"openai\",\n",
    "        \"model_id\": \"gpt-5-2025-08-07\",\n",
    "    },\n",
    "    \"claude\": {\n",
    "        \"name\": \"Claude Sonnet 4.5\",\n",
    "        \"provider\": \"anthropic\",\n",
    "        \"model_id\": \"claude-sonnet-4-5-20250929\",\n",
    "    },\n",
    "}\n",
    "\n",
    "# --- API Keys ---\n",
    "FRED_API_KEY = os.environ.get(\"FRED_API_KEY\", \"\")\n",
    "EIA_API_KEY = os.environ.get(\"EIA_API_KEY\", \"\")\n",
    "\n",
    "# --- Prediction Market API Base URLs ---\n",
    "POLYMARKET_GAMMA_BASE = \"https://gamma-api.polymarket.com\"\n",
    "POLYMARKET_CLOB_BASE = \"https://clob.polymarket.com\"\n",
    "KALSHI_BASE = \"https://api.elections.kalshi.com/trade-api/v2\"\n",
    "\n",
    "# --- FRED Series IDs ---\n",
    "FRED_SERIES = {\n",
    "    \"fed_funds_rate\": \"DFF\",\n",
    "    \"fed_funds_target_upper\": \"DFEDTARU\",\n",
    "    \"fed_funds_target_lower\": \"DFEDTARL\",\n",
    "}\n",
    "\n",
    "# --- EIA Endpoint ---\n",
    "EIA_GAS_PRICE_URL = \"https://api.eia.gov/v2/petroleum/pri/gp/data/\"\n",
    "\n",
    "# --- 2026 FOMC Meeting Dates (announcement day) ---\n",
    "FOMC_DATES_2026 = [\n",
    "    {\"meeting\": \"January\",   \"date\": \"2026-01-28\"},\n",
    "    {\"meeting\": \"March\",     \"date\": \"2026-03-18\"},\n",
    "    {\"meeting\": \"April\",     \"date\": \"2026-04-29\"},\n",
    "    {\"meeting\": \"June\",      \"date\": \"2026-06-17\"},\n",
    "    {\"meeting\": \"July\",      \"date\": \"2026-07-29\"},\n",
    "    {\"meeting\": \"September\", \"date\": \"2026-09-16\"},\n",
    "    {\"meeting\": \"October\",   \"date\": \"2026-10-28\"},\n",
    "    {\"meeting\": \"December\",  \"date\": \"2026-12-09\"},\n",
    "]\n",
    "\n",
    "# Ensure cache directory exists\n",
    "Path(\"cache\").mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Configuration loaded.\")\n",
    "print(f\"FRED API key: {'set' if FRED_API_KEY else 'MISSING'}\")\n",
    "print(f\"EIA API key: {'set' if EIA_API_KEY else 'MISSING'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Caching Infrastructure ---\n",
    "# Same pattern as lab_02: JSON file-based cache to avoid redundant API calls\n",
    "\n",
    "CACHE_FILE = Path(\"cache/response_cache.json\")\n",
    "\n",
    "\n",
    "def load_cache():\n",
    "    if CACHE_FILE.exists():\n",
    "        return json.loads(CACHE_FILE.read_text())\n",
    "    return {}\n",
    "\n",
    "\n",
    "def save_cache(cache):\n",
    "    CACHE_FILE.write_text(json.dumps(cache, indent=2))\n",
    "\n",
    "\n",
    "def get_cache_key(prefix, *args):\n",
    "    key_str = f\"{prefix}:\" + \":\".join(str(a) for a in args)\n",
    "    return hashlib.sha256(key_str.encode()).hexdigest()[:16]\n",
    "\n",
    "\n",
    "def cached_call(cache, key, func, *args, **kwargs):\n",
    "    \"\"\"Execute func if key not in cache; otherwise return cached result.\"\"\"\n",
    "    if key in cache:\n",
    "        return cache[key]\n",
    "    result = func(*args, **kwargs)\n",
    "    cache[key] = result\n",
    "    save_cache(cache)\n",
    "    return result\n",
    "\n",
    "\n",
    "print(\"Caching infrastructure ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Data Collection\n",
    "\n",
    "We pull data from four external sources:\n",
    "\n",
    "| Source | What It Provides | API | Auth |\n",
    "|--------|-----------------|-----|------|\n",
    "| **FRED** (St. Louis Fed) | Federal funds rate (daily), target rate range | `fredapi` Python library | Free API key |\n",
    "| **EIA** (Energy Information Administration) | Weekly US retail gasoline prices | REST API v2 | Free API key |\n",
    "| **Polymarket** | Prediction market probabilities | Gamma + CLOB REST APIs | None |\n",
    "| **Kalshi** | Prediction market probabilities | REST API v2 | None (public data) |\n",
    "\n",
    "The FRED and EIA data serve two purposes:\n",
    "1. **Ground truth** for resolving our binary questions\n",
    "2. **Tool data** for the tool-augmented LLM category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1.1 FRED: Federal Funds Rate ---\n",
    "\n",
    "def fetch_fred_data():\n",
    "    \"\"\"Fetch federal funds rate data from FRED.\"\"\"\n",
    "    fred = Fred(api_key=FRED_API_KEY)\n",
    "\n",
    "    fed_funds = fred.get_series(\"DFF\", observation_start=\"2024-01-01\")\n",
    "    target_upper = fred.get_series(\"DFEDTARU\", observation_start=\"2024-01-01\")\n",
    "    target_lower = fred.get_series(\"DFEDTARL\", observation_start=\"2024-01-01\")\n",
    "\n",
    "    return {\n",
    "        \"fed_funds_rate\": fed_funds,\n",
    "        \"target_upper\": target_upper,\n",
    "        \"target_lower\": target_lower,\n",
    "    }\n",
    "\n",
    "\n",
    "fred_data = fetch_fred_data()\n",
    "print(f\"Fed funds rate: {len(fred_data['fed_funds_rate'])} observations\")\n",
    "print(f\"Latest effective rate: {fred_data['fed_funds_rate'].dropna().iloc[-1]:.2f}%\")\n",
    "print(\n",
    "    f\"Current target range: {fred_data['target_lower'].dropna().iloc[-1]:.2f}%\"\n",
    "    f\" - {fred_data['target_upper'].dropna().iloc[-1]:.2f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1.2 EIA: US Retail Gasoline Prices ---\n",
    "\n",
    "def fetch_eia_gas_prices(n_weeks=200):\n",
    "    \"\"\"Fetch weekly US regular gasoline retail prices from EIA API v2.\"\"\"\n",
    "    params = {\n",
    "        \"api_key\": EIA_API_KEY,\n",
    "        \"frequency\": \"weekly\",\n",
    "        \"data[0]\": \"value\",\n",
    "        \"facets[product][]\": \"EPMR\",   # Regular gasoline, all formulations\n",
    "        \"facets[duoarea][]\": \"NUS\",     # National US\n",
    "        \"sort[0][column]\": \"period\",\n",
    "        \"sort[0][direction]\": \"desc\",\n",
    "        \"offset\": 0,\n",
    "        \"length\": n_weeks,\n",
    "    }\n",
    "    response = requests.get(EIA_GAS_PRICE_URL, params=params)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "\n",
    "    records = data[\"response\"][\"data\"]\n",
    "    df = pd.DataFrame(records)\n",
    "    df[\"period\"] = pd.to_datetime(df[\"period\"])\n",
    "    df[\"value\"] = pd.to_numeric(df[\"value\"])\n",
    "    df = df.sort_values(\"period\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "gas_prices = fetch_eia_gas_prices()\n",
    "print(f\"Gas price data: {len(gas_prices)} weekly observations\")\n",
    "print(\n",
    "    f\"Latest: ${gas_prices['value'].iloc[-1]:.3f}/gal\"\n",
    "    f\" (week of {gas_prices['period'].iloc[-1].strftime('%Y-%m-%d')})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1.3 Polymarket ---\n",
    "\n",
    "def fetch_polymarket_events(search_term, limit=50):\n",
    "    \"\"\"Search Polymarket Gamma API for events matching a term.\"\"\"\n",
    "    url = f\"{POLYMARKET_GAMMA_BASE}/events\"\n",
    "    params = {\"closed\": \"false\", \"limit\": limit}\n",
    "    response = requests.get(url, params=params)\n",
    "    response.raise_for_status()\n",
    "    events = response.json()\n",
    "\n",
    "    relevant = []\n",
    "    for event in events:\n",
    "        title = event.get(\"title\", \"\").lower()\n",
    "        if search_term.lower() in title:\n",
    "            relevant.append(event)\n",
    "    return relevant\n",
    "\n",
    "\n",
    "def fetch_polymarket_price_history(token_id, interval=\"max\", fidelity=60):\n",
    "    \"\"\"Fetch price history for a Polymarket CLOB token.\"\"\"\n",
    "    url = f\"{POLYMARKET_CLOB_BASE}/prices-history\"\n",
    "    params = {\"market\": token_id, \"interval\": interval, \"fidelity\": fidelity}\n",
    "    response = requests.get(url, params=params)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    history = data.get(\"history\", [])\n",
    "    df = pd.DataFrame(history)\n",
    "    if not df.empty:\n",
    "        df[\"timestamp\"] = pd.to_datetime(df[\"t\"], unit=\"s\")\n",
    "        df[\"price\"] = df[\"p\"].astype(float)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Search for relevant markets\n",
    "poly_fed_events = fetch_polymarket_events(\"fed\")\n",
    "poly_gas_events = fetch_polymarket_events(\"gas\")\n",
    "print(f\"Polymarket: {len(poly_fed_events)} Fed-related events, {len(poly_gas_events)} gas-related events\")\n",
    "\n",
    "for e in poly_fed_events[:5]:\n",
    "    print(f\"  Fed: {e.get('title', 'N/A')}\")\n",
    "for e in poly_gas_events[:5]:\n",
    "    print(f\"  Gas: {e.get('title', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1.4 Kalshi ---\n",
    "\n",
    "def fetch_kalshi_markets(series_ticker, status=\"open\", limit=100):\n",
    "    \"\"\"Fetch markets from Kalshi for a given series.\"\"\"\n",
    "    url = f\"{KALSHI_BASE}/markets\"\n",
    "    params = {\"series_ticker\": series_ticker, \"status\": status, \"limit\": limit}\n",
    "    response = requests.get(url, params=params)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    return data.get(\"markets\", [])\n",
    "\n",
    "\n",
    "# Fetch Fed rate and gas price markets\n",
    "kalshi_fed = fetch_kalshi_markets(\"KXFED\")\n",
    "kalshi_gas = fetch_kalshi_markets(\"KXAAAGASM\")\n",
    "print(f\"Kalshi: {len(kalshi_fed)} Fed rate markets (KXFED), {len(kalshi_gas)} gas price markets (KXAAAGASM)\")\n",
    "\n",
    "print(\"\\nFed rate markets:\")\n",
    "for m in kalshi_fed[:5]:\n",
    "    yes_bid = m.get(\"yes_bid\", m.get(\"last_price\", \"N/A\"))\n",
    "    print(f\"  {m.get('ticker', 'N/A')}: {m.get('title', 'N/A')} | Yes: {yes_bid}\")\n",
    "\n",
    "print(\"\\nGas price markets:\")\n",
    "for m in kalshi_gas[:5]:\n",
    "    yes_bid = m.get(\"yes_bid\", m.get(\"last_price\", \"N/A\"))\n",
    "    print(f\"  {m.get('ticker', 'N/A')}: {m.get('title', 'N/A')} | Yes: {yes_bid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1.5 Temperature Markets\n\nWe add a third forecasting domain: **monthly average daily high temperatures** for six\ngeographically diverse US cities.\n\n| Source | What It Provides | API | Auth |\n|--------|-----------------|-----|------|\n| **Open-Meteo** | Daily max temperature (ERA5 reanalysis) | REST API | None — no key required |\n| **Kalshi** | Temperature market prices | REST API v2 | None (public data) |\n\n**Question design**: Each binary question asks whether the average daily high will exceed\nthe 10-year historical median for that city/month.  Using the median as the threshold sets\nthe expected base rate at ≈ 50%, which maximises statistical power and calibration signal.\n\n**Why these months?**  March–June 2026 resolution dates are well past all frontier LLM\ntraining cutoffs (≤ Aug 2025), ensuring models must genuinely forecast rather than recall\noutcomes from training data."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# --- 1.5 Open-Meteo + Kalshi: Temperature Data ---\n\nOPEN_METEO_ARCHIVE = \"https://archive-api.open-meteo.com/v1/archive\"\n\n# Six geographically diverse US cities\nCITIES = {\n    \"new_york\":    {\"name\": \"New York\",    \"lat\": 40.71, \"lon\": -74.01},\n    \"chicago\":     {\"name\": \"Chicago\",     \"lat\": 41.85, \"lon\": -87.65},\n    \"miami\":       {\"name\": \"Miami\",       \"lat\": 25.77, \"lon\": -80.19},\n    \"los_angeles\": {\"name\": \"Los Angeles\", \"lat\": 34.05, \"lon\": -118.24},\n    \"denver\":      {\"name\": \"Denver\",      \"lat\": 39.74, \"lon\": -104.98},\n    \"seattle\":     {\"name\": \"Seattle\",     \"lat\": 47.61, \"lon\": -122.33},\n}\n\n# Forecast months — all well past any frontier LLM training cutoff (≤ Aug 2025)\nTEMP_MONTHS = [\n    {\"year\": 2026, \"month\": 3, \"name\": \"March\"},\n    {\"year\": 2026, \"month\": 4, \"name\": \"April\"},\n    {\"year\": 2026, \"month\": 5, \"name\": \"May\"},\n    {\"year\": 2026, \"month\": 6, \"name\": \"June\"},\n]\n\n\ndef fetch_temp_history(lat, lon, start_date, end_date):\n    \"\"\"Fetch daily max temperatures (°F) from Open-Meteo ERA5 archive.\"\"\"\n    params = {\n        \"latitude\": lat, \"longitude\": lon,\n        \"start_date\": start_date, \"end_date\": end_date,\n        \"daily\": \"temperature_2m_max\",\n        \"temperature_unit\": \"fahrenheit\",\n        \"timezone\": \"auto\",\n    }\n    resp = requests.get(OPEN_METEO_ARCHIVE, params=params)\n    resp.raise_for_status()\n    data = resp.json()\n    df = pd.DataFrame({\n        \"date\": pd.to_datetime(data[\"daily\"][\"time\"]),\n        \"temp_max_f\": pd.to_numeric(data[\"daily\"][\"temperature_2m_max\"], errors=\"coerce\"),\n    })\n    return df.dropna()\n\n\ndef compute_city_normals(city_key, lat, lon, n_years=10):\n    \"\"\"\n    Compute 10-year median monthly avg-high (°F) for all 12 months.\n    Makes one API call per city for the full historical window; cached after first run.\n    \"\"\"\n    cache = load_cache()\n    ck = get_cache_key(\"temp_normals\", city_key, n_years)\n    if ck in cache:\n        return {int(k): v for k, v in cache[ck].items()}\n\n    end_year = datetime.now().year - 1\n    start_year = end_year - n_years + 1\n    print(f\"  Fetching {n_years}-year history for {city_key} ({start_year}–{end_year})...\")\n    df = fetch_temp_history(lat, lon, f\"{start_year}-01-01\", f\"{end_year}-12-31\")\n    df[\"year\"] = df[\"date\"].dt.year\n    df[\"month\"] = df[\"date\"].dt.month\n    # Monthly avg-high per year, then take the median across years for each month\n    monthly = df.groupby([\"year\", \"month\"])[\"temp_max_f\"].mean()\n    normals = monthly.groupby(\"month\").median().to_dict()\n\n    cache[ck] = {str(k): v for k, v in normals.items()}\n    save_cache(cache)\n    return normals\n\n\ndef fetch_kalshi_temp_markets(limit=200):\n    \"\"\"Search Kalshi open markets for temperature / weather contracts.\"\"\"\n    url = f\"{KALSHI_BASE}/markets\"\n    params = {\"status\": \"open\", \"limit\": limit}\n    try:\n        resp = requests.get(url, params=params)\n        resp.raise_for_status()\n        markets = resp.json().get(\"markets\", [])\n    except Exception as e:\n        print(f\"Warning: Kalshi temperature market fetch failed: {e}\")\n        return []\n    temp_keywords = [\"temperature\", \"high temp\", \"low temp\", \"weather\", \"degrees\", \"\\u00b0f\"]\n    return [\n        m for m in markets\n        if any(kw in m.get(\"title\", \"\").lower() for kw in temp_keywords)\n        or \"weather\" in m.get(\"category\", \"\").lower()\n    ]\n\n\n# --- Run ---\nprint(\"Computing 10-year climate normals (ERA5, cached after first run)...\")\ncity_normals = {}\nfor city_key, city_info in CITIES.items():\n    city_normals[city_key] = compute_city_normals(city_key, city_info[\"lat\"], city_info[\"lon\"])\n\nimport calendar as _cal\nprint(\"\\nHistorical median avg-high (°F):\")\nprint(f\"{'City':<14}\" + \"\".join(f\"  {m['name'][:3]}\" for m in TEMP_MONTHS))\nfor city_key, normals in city_normals.items():\n    row = f\"{CITIES[city_key]['name']:<14}\"\n    for m in TEMP_MONTHS:\n        val = normals.get(m[\"month\"], float(\"nan\"))\n        row += f\"  {val:5.1f}\"\n    print(row)\n\nkalshi_temp_markets = fetch_kalshi_temp_markets()\nprint(f\"\\nKalshi temperature markets found: {len(kalshi_temp_markets)}\")\nfor m in kalshi_temp_markets[:5]:\n    print(f\"  {m.get('ticker', 'N/A')}: {m.get('title', 'N/A')}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1.6 Kalshi: Historic NYC Temperature Markets\n\nWe pull the full history of **finalized** Kalshi NYC high-temperature markets from the\npublic API.  Each market resolves as YES/NO against a daily high-temperature threshold.\n\nThis data establishes our **train / validate** benchmark for the temperature domain —\nwe have both the market probability (pre-settlement price) and the actual outcome.\n\n| Split | Period | Purpose |\n|-------|--------|---------|\n| **Train** | before 2025-01-01 | Calibration & baseline Brier |\n| **Validate** | 2025 | Threshold-tuning (e.g. betting delta) |\n| **Test** | 2026 | Held-out evaluation |\n\nAll six cities are retained for LLM evaluation; Kalshi NYC data is a supplemental\nhistorical benchmark for the temperature domain."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# --- 1.6 Kalshi: Historic NYC Temperature Markets ---\n\n# ── Split boundaries ────────────────────────────────────────────────────────\nSPLIT_TRAIN_END = \"2025-01-01\"\nSPLIT_VAL_END   = \"2026-01-01\"\n\ndef assign_split(resolution_date_str):\n    \"\"\"Assign train / validate / test based on resolution date.\"\"\"\n    dt = datetime.strptime(resolution_date_str[:10], \"%Y-%m-%d\")\n    if dt < datetime(2025, 1, 1):\n        return \"train\"\n    elif dt < datetime(2026, 1, 1):\n        return \"validate\"\n    else:\n        return \"test\"\n\n\ndef fetch_kalshi_nyc_weather_history(max_pages=15):\n    \"\"\"\n    Fetch all finalized Kalshi markets for NYC daily high temperature.\n    Tries the KXHIGHNYC series first; falls back to a keyword search across\n    all finalized markets.  Results are cached.\n\n    Returns a DataFrame with columns:\n        ticker, title, resolution_date, threshold_f, market_prob, outcome, split\n    \"\"\"\n    cache = load_cache()\n    ck = get_cache_key(\"kalshi_nyc_history\", \"v1\", max_pages)\n    if ck in cache:\n        df = pd.DataFrame(cache[ck])\n        if not df.empty:\n            df[\"resolution_date\"] = pd.to_datetime(df[\"resolution_date\"])\n        return df\n\n    url = f\"{KALSHI_BASE}/markets\"\n    all_markets = []\n\n    # 1. Try known series tickers for NYC temperature\n    for series in [\"KXHIGHNYC\", \"HIGHNYC\", \"KXHIGH-NYC\", \"KXTEMPHIGHNYC\"]:\n        params = {\"series_ticker\": series, \"status\": \"finalized\", \"limit\": 200}\n        try:\n            resp = requests.get(url, params=params, timeout=10)\n            resp.raise_for_status()\n            data = resp.json()\n            batch = data.get(\"markets\", [])\n            if batch:\n                all_markets.extend(batch)\n                cursor = data.get(\"cursor\")\n                for _ in range(max_pages - 1):\n                    if not cursor:\n                        break\n                    r2 = requests.get(url, params={**params, \"cursor\": cursor}, timeout=10)\n                    r2.raise_for_status()\n                    d2 = r2.json()\n                    all_markets.extend(d2.get(\"markets\", []))\n                    cursor = d2.get(\"cursor\")\n                print(f\"  Found {len(all_markets)} markets via series {series}\")\n                break\n        except Exception:\n            continue\n\n    # 2. Fallback: keyword search through all finalized markets\n    if not all_markets:\n        print(\"  Series search returned nothing; scanning finalized markets...\")\n        cursor = None\n        nyc_kws  = [\"new york\", \"nyc\", \" ny \"]\n        temp_kws = [\"high temp\", \"temperature\", \"degrees\", \"\\u00b0f\", \"high of\"]\n        for page in range(max_pages):\n            params = {\"status\": \"finalized\", \"limit\": 200}\n            if cursor:\n                params[\"cursor\"] = cursor\n            try:\n                resp = requests.get(url, params=params, timeout=10)\n                resp.raise_for_status()\n                data = resp.json()\n                for m in data.get(\"markets\", []):\n                    t = m.get(\"title\", \"\").lower()\n                    if any(k in t for k in nyc_kws) and any(k in t for k in temp_kws):\n                        all_markets.append(m)\n                cursor = data.get(\"cursor\")\n                if not cursor:\n                    break\n            except Exception as e:\n                print(f\"    page {page}: {e}\")\n                break\n\n    # 3. Parse into rows\n    rows = []\n    for m in all_markets:\n        title = m.get(\"title\", \"\")\n\n        # Extract temperature threshold from title (e.g. \"exceed 45°F\" or \"above 72\")\n        temps = re.findall(r\"(\\d+(?:\\.\\d+)?)\\s*\\u00b0?\\s*[Ff]\", title)\n        threshold_f = float(temps[0]) if temps else np.nan\n\n        # Resolution date\n        res_date = None\n        for df_key in [\"close_time\", \"expiration_time\", \"end_date\"]:\n            raw = m.get(df_key)\n            if raw:\n                try:\n                    res_date = pd.to_datetime(raw).strftime(\"%Y-%m-%d\")\n                    break\n                except Exception:\n                    pass\n\n        # Market probability — the pre-settlement price\n        market_prob = np.nan\n        for price_key in [\"last_price\", \"previous_price\", \"yes_bid\"]:\n            val = m.get(price_key)\n            if val is not None:\n                v = float(val)\n                # Skip exact settlement values (0, 1, 0, 100)\n                if v not in {0, 1, 0.0, 1.0, 100, 100.0}:\n                    market_prob = v / 100.0 if v > 1.0 else v\n                    break\n\n        # Outcome\n        result = m.get(\"result\", \"\").lower()\n        outcome = 1 if result == \"yes\" else (0 if result == \"no\" else np.nan)\n\n        if res_date and not np.isnan(outcome):\n            rows.append({\n                \"ticker\":          m.get(\"ticker\", \"\"),\n                \"title\":           title,\n                \"resolution_date\": res_date,\n                \"threshold_f\":     threshold_f,\n                \"market_prob\":     market_prob,\n                \"outcome\":         outcome,\n                \"split\":           assign_split(res_date),\n            })\n\n    df = pd.DataFrame(rows)\n    if not df.empty:\n        df[\"resolution_date\"] = pd.to_datetime(df[\"resolution_date\"])\n        df = df.sort_values(\"resolution_date\").reset_index(drop=True)\n\n    # Cache\n    cache_payload = df.copy()\n    if not cache_payload.empty:\n        cache_payload[\"resolution_date\"] = cache_payload[\"resolution_date\"].astype(str)\n    cache[ck] = cache_payload.to_dict(\"records\")\n    save_cache(cache)\n    return df\n\n\n# ── Run ─────────────────────────────────────────────────────────────────────\nkalshi_nyc_history = fetch_kalshi_nyc_weather_history()\nprint(f\"Kalshi NYC historical temperature markets: {len(kalshi_nyc_history)}\")\n\nif not kalshi_nyc_history.empty:\n    for split_name, grp in kalshi_nyc_history.groupby(\"split\"):\n        cov   = grp[\"market_prob\"].notna().mean()\n        valid = grp.dropna(subset=[\"market_prob\"])\n        bs    = ((valid[\"market_prob\"] - valid[\"outcome\"]) ** 2).mean() if len(valid) > 0 else np.nan\n        print(f\"  {split_name:10s}: {len(grp):4d} markets | \"\n              f\"Kalshi Brier={bs:.4f} | price coverage={cov:.0%}\")\n    print()\n    print(\"Sample markets:\")\n    for _, row in kalshi_nyc_history.head(3).iterrows():\n        print(f\"  {row['ticker']}: threshold={row['threshold_f']}\\u00b0F  \"\n              f\"outcome={'YES' if row['outcome']==1 else 'NO'}  \"\n              f\"mkt_prob={row['market_prob']:.2f}\" if pd.notna(row['market_prob'])\n              else f\"  {row['ticker']}: threshold={row['threshold_f']}\\u00b0F  \"\n              f\"outcome={'YES' if row['outcome']==1 else 'NO'}  mkt_prob=N/A\")\nelse:\n    print(\"  No historical data returned (Kalshi may not expose public temperature history)\")\n    print(\"  Proceeding with LLM-only train/validate evaluation.\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Binary Question Design\n",
    "\n",
    "## Design Principles\n",
    "1. **Clear resolution criteria**: each question has an unambiguous yes/no outcome\n",
    "2. **Authoritative data source**: resolution determined by a specific FRED/EIA data release\n",
    "3. **Alignment with prediction markets**: questions map to existing Kalshi/Polymarket contracts where possible\n",
    "4. **Diverse time horizons**: mix of near-term and medium-term questions\n",
    "\n",
    "## Question Categories\n",
    "\n",
    "### Category A: Federal Funds Rate (FOMC Decisions)\n",
    "**Template**: \"Will the Fed cut the federal funds rate at the [Month] 2026 FOMC meeting?\"\n",
    "- Resolves YES if the FRED target rate upper bound (`DFEDTARU`) decreases after the meeting\n",
    "- Resolves NO otherwise\n",
    "\n",
    "### Category B: US Retail Gas Prices\n",
    "**Template**: \"Will the US national average gas price exceed $X.XX per gallon by [date]?\"\n",
    "- Resolves YES if EIA weekly price exceeds the threshold\n",
    "- Thresholds set relative to the current price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# --- 2.1 Question Generation (all splits) ---\nimport calendar as _cal\n\n# ── Helpers ─────────────────────────────────────────────────────────────────\ndef _add_meta(questions, split_name):\n    \"\"\"Stamp each question with its split and a 30-day-before forecast_date.\"\"\"\n    for q in questions:\n        q[\"split\"] = split_name\n        res = datetime.strptime(q[\"resolution_date\"][:10], \"%Y-%m-%d\")\n        q.setdefault(\"forecast_date\", (res - timedelta(days=30)).strftime(\"%Y-%m-%d\"))\n    return questions\n\n\n# ── Fed-rate question generators ─────────────────────────────────────────────\ndef generate_fed_questions(fomc_dates, current_rate_upper):\n    \"\"\"2026 FOMC questions (test split).\"\"\"\n    questions = []\n    for meeting in fomc_dates:\n        meeting_date = datetime.strptime(meeting[\"date\"], \"%Y-%m-%d\")\n        if meeting_date > datetime.now():\n            questions.append({\n                \"id\": f\"fed_cut_{meeting['meeting'].lower()}_2026\",\n                \"category\": \"fed_rate\",\n                \"text\": (f\"Will the Fed cut the federal funds rate at the\"\n                         f\" {meeting['meeting']} 2026 FOMC meeting?\"),\n                \"resolution_date\": meeting[\"date\"],\n                \"resolution_source\": \"FRED DFEDTARU\",\n                \"current_rate\": float(current_rate_upper),\n                \"kalshi_series\": \"KXFED\",\n                \"meeting_month\": meeting[\"meeting\"].lower(),\n                \"split\": \"test\",\n                \"forecast_date\": datetime.now().strftime(\"%Y-%m-%d\"),\n            })\n    return questions\n\n\ndef generate_fed_questions_historical(fomc_dates, year):\n    \"\"\"Historical FOMC questions (train or validate split).\"\"\"\n    questions = []\n    for meeting in fomc_dates:\n        meeting_date = datetime.strptime(meeting[\"date\"], \"%Y-%m-%d\")\n        forecast_date = meeting_date - timedelta(days=30)\n        # Rate as-of 30 days before meeting (from FRED data)\n        rate_series = fred_data[\"target_upper\"]\n        pre = rate_series[rate_series.index < pd.Timestamp(forecast_date)]\n        hist_rate = float(pre.iloc[-1]) if len(pre) > 0 else float(current_rate)\n        questions.append({\n            \"id\": f\"fed_cut_{meeting['meeting'].lower()}_{year}\",\n            \"category\": \"fed_rate\",\n            \"text\": (f\"Will the Fed cut the federal funds rate at the\"\n                     f\" {meeting['meeting']} {year} FOMC meeting?\"),\n            \"resolution_date\": meeting[\"date\"],\n            \"resolution_source\": \"FRED DFEDTARU\",\n            \"current_rate\": hist_rate,\n            \"kalshi_series\": \"KXFED\",\n            \"meeting_month\": meeting[\"meeting\"].lower(),\n            \"forecast_date\": forecast_date.strftime(\"%Y-%m-%d\"),\n            \"split\": assign_split(meeting[\"date\"]),\n        })\n    return questions\n\n\n# ── Gas-price question generators ────────────────────────────────────────────\ndef generate_gas_questions(current_price, weeks_ahead=(4, 8, 12)):\n    \"\"\"2026 gas-price questions (test split).\"\"\"\n    questions = []\n    offsets = [0.25, 0.50, -0.25]\n    for weeks in weeks_ahead:\n        target_date = datetime.now() + timedelta(weeks=weeks)\n        target_date_str = target_date.strftime(\"%Y-%m-%d\")\n        for offset in offsets:\n            threshold = round(current_price + offset, 2)\n            direction = \"exceed\" if offset > 0 else \"fall below\"\n            questions.append({\n                \"id\": f\"gas_{'above' if offset > 0 else 'below'}_{threshold:.2f}_{weeks}w\",\n                \"category\": \"gas_price\",\n                \"text\": (f\"Will the US national average gas price {direction}\"\n                         f\" ${threshold:.2f}/gal by the week of {target_date_str}?\"),\n                \"resolution_date\": target_date_str,\n                \"resolution_source\": \"EIA Weekly Retail Gasoline Prices\",\n                \"threshold\": threshold,\n                \"current_price\": float(current_price),\n                \"kalshi_series\": \"KXAAAGASM\",\n                \"split\": \"test\",\n                \"forecast_date\": datetime.now().strftime(\"%Y-%m-%d\"),\n            })\n    return questions\n\n\ndef generate_historical_gas_questions(gas_prices_df, as_of_dates, split_name):\n    \"\"\"Historical gas questions from past quarterly as-of dates.\"\"\"\n    questions = []\n    offsets = [0.25, -0.25]      # two thresholds per period (keeps count manageable)\n    weeks_ahead = (4, 8)\n    for as_of in as_of_dates:\n        prices_at = gas_prices_df[gas_prices_df[\"period\"] <= pd.Timestamp(as_of)]\n        if len(prices_at) == 0:\n            continue\n        current_price = float(prices_at[\"value\"].iloc[-1])\n        compact = as_of.replace(\"-\", \"\")[:6]\n        for weeks in weeks_ahead:\n            target_date = datetime.strptime(as_of, \"%Y-%m-%d\") + timedelta(weeks=weeks)\n            target_str = target_date.strftime(\"%Y-%m-%d\")\n            for offset in offsets:\n                threshold = round(current_price + offset, 2)\n                direction = \"exceed\" if offset > 0 else \"fall below\"\n                questions.append({\n                    \"id\": f\"gas_hist_{compact}_{'ab' if offset > 0 else 'bl'}_{threshold:.2f}_{weeks}w\",\n                    \"category\": \"gas_price\",\n                    \"text\": (f\"Will the US national average gas price {direction}\"\n                             f\" ${threshold:.2f}/gal by the week of {target_str}?\"),\n                    \"resolution_date\": target_str,\n                    \"resolution_source\": \"EIA Weekly Retail Gasoline Prices\",\n                    \"threshold\": threshold,\n                    \"current_price\": current_price,\n                    \"kalshi_series\": \"KXAAAGASM\",\n                    \"forecast_date\": as_of,\n                    \"split\": split_name,\n                })\n    return questions\n\n\n# ── Temperature question generator ───────────────────────────────────────────\ndef generate_temperature_questions(cities, months, normals_by_city):\n    \"\"\"\n    Binary questions: 'Will avg-high in [city] exceed [threshold]\\u00b0F in [month]?'\n    Threshold = 10-year historical median avg-high  →  base rate \\u2248 50%.\n    All 6 cities (New York, Chicago, Miami, Los Angeles, Denver, Seattle) are included.\n    \"\"\"\n    questions = []\n    for m_info in months:\n        yr, mo, mo_name = m_info[\"year\"], m_info[\"month\"], m_info[\"name\"]\n        last_day = _cal.monthrange(yr, mo)[1]\n        resolution_date = f\"{yr}-{mo:02d}-{last_day}\"\n        for city_key, city_info in cities.items():\n            threshold = normals_by_city.get(city_key, {}).get(mo)\n            if threshold is None or np.isnan(threshold):\n                continue\n            threshold = round(threshold, 1)\n            questions.append({\n                \"id\": f\"temp_{city_key}_{mo_name.lower()}_{yr}\",\n                \"category\": \"temperature\",\n                \"text\": (f\"Will the average daily high temperature in {city_info['name']}\"\n                         f\" exceed {threshold}\\u00b0F in {mo_name} {yr}?\"),\n                \"resolution_date\": resolution_date,\n                \"resolution_source\": \"Open-Meteo ERA5\",\n                \"city_key\": city_key,\n                \"city_name\": city_info[\"name\"],\n                \"lat\": city_info[\"lat\"],\n                \"lon\": city_info[\"lon\"],\n                \"month\": mo,\n                \"year\": yr,\n                \"threshold_f\": threshold,\n                \"historical_normal_f\": threshold,\n            })\n    return questions\n\n\n# ── Historical FOMC dates ────────────────────────────────────────────────────\nFOMC_DATES_2024 = [\n    {\"meeting\": \"January\",   \"date\": \"2024-01-31\"},\n    {\"meeting\": \"March\",     \"date\": \"2024-03-20\"},\n    {\"meeting\": \"May\",       \"date\": \"2024-05-01\"},\n    {\"meeting\": \"June\",      \"date\": \"2024-06-12\"},\n    {\"meeting\": \"July\",      \"date\": \"2024-07-31\"},\n    {\"meeting\": \"September\", \"date\": \"2024-09-18\"},\n    {\"meeting\": \"November\",  \"date\": \"2024-11-07\"},\n    {\"meeting\": \"December\",  \"date\": \"2024-12-18\"},\n]\nFOMC_DATES_2025 = [\n    {\"meeting\": \"January\",   \"date\": \"2025-01-29\"},\n    {\"meeting\": \"March\",     \"date\": \"2025-03-19\"},\n    {\"meeting\": \"May\",       \"date\": \"2025-05-07\"},\n    {\"meeting\": \"June\",      \"date\": \"2025-06-18\"},\n    {\"meeting\": \"July\",      \"date\": \"2025-07-30\"},\n    {\"meeting\": \"September\", \"date\": \"2025-09-17\"},\n    {\"meeting\": \"October\",   \"date\": \"2025-10-29\"},\n    {\"meeting\": \"December\",  \"date\": \"2025-12-10\"},\n]\n\n# Historical temperature months\nHIST_TEMP_MONTHS_TRAIN = [\n    {\"year\": 2024, \"month\": m, \"name\": _cal.month_name[m]}\n    for m in range(3, 13)  # Mar–Dec 2024\n]\nHIST_TEMP_MONTHS_VAL = [\n    {\"year\": 2025, \"month\": m, \"name\": _cal.month_name[m]}\n    for m in range(1, 13)  # All of 2025\n    if datetime(2025, m, _cal.monthrange(2025, m)[1]) < datetime.now()\n]\n\n# Historical gas as-of dates (quarterly)\nGAS_AS_OF_TRAIN = [\"2024-01-08\", \"2024-04-01\", \"2024-07-08\", \"2024-10-07\"]\nGAS_AS_OF_VAL   = [\"2025-01-06\", \"2025-04-07\", \"2025-07-07\", \"2025-10-06\"]\n\n\n# ── Generate all questions ───────────────────────────────────────────────────\ncurrent_rate = fred_data[\"target_upper\"].dropna().iloc[-1]\ncurrent_gas  = gas_prices[\"value\"].iloc[-1]\n\n# TEST split (2026)\nfed_questions  = generate_fed_questions(FOMC_DATES_2026, current_rate)\ngas_questions  = generate_gas_questions(current_gas)\ntemp_questions = _add_meta(\n    generate_temperature_questions(CITIES, TEMP_MONTHS, city_normals), \"test\"\n)\nfor q in temp_questions:\n    q[\"forecast_date\"] = datetime.now().strftime(\"%Y-%m-%d\")\n\n# TRAIN split (2024)\nhist_fed_train  = generate_fed_questions_historical(FOMC_DATES_2024, 2024)\nhist_gas_train  = generate_historical_gas_questions(gas_prices, GAS_AS_OF_TRAIN, \"train\")\nhist_temp_train = _add_meta(\n    generate_temperature_questions(CITIES, HIST_TEMP_MONTHS_TRAIN, city_normals), \"train\"\n)\n\n# VALIDATE split (2025)\nhist_fed_val  = generate_fed_questions_historical(FOMC_DATES_2025, 2025)\nhist_gas_val  = generate_historical_gas_questions(gas_prices, GAS_AS_OF_VAL, \"validate\")\nhist_temp_val = _add_meta(\n    generate_temperature_questions(CITIES, HIST_TEMP_MONTHS_VAL, city_normals), \"validate\"\n)\n\nall_questions = (\n    fed_questions + gas_questions + temp_questions\n    + hist_fed_train + hist_gas_train + hist_temp_train\n    + hist_fed_val   + hist_gas_val   + hist_temp_val\n)\n\n# Convenience: test-only questions (for tool-augmented forecasting)\ntest_questions = [q for q in all_questions if q[\"split\"] == \"test\"]\n\n# ── Summary ──────────────────────────────────────────────────────────────────\nsplit_counts = {}\nfor q in all_questions:\n    k = (q[\"split\"], q[\"category\"])\n    split_counts[k] = split_counts.get(k, 0) + 1\n\nprint(f\"Total questions: {len(all_questions)}\")\nprint(f\"{'Split':<12} {'Category':<14} {'Count':>5}\")\nfor (split_name, cat), cnt in sorted(split_counts.items()):\n    print(f\"  {split_name:<10} {cat:<14} {cnt:>5}\")\nprint(f\"\\nTest questions: {len(test_questions)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# --- 2.2 Collect Prediction Market Probabilities ---\n\ndef match_kalshi_market(markets, question):\n    \"\"\"Find the Kalshi market that best matches our question (Fed / gas).\"\"\"\n    for m in markets:\n        title_lower = m.get(\"title\", \"\").lower()\n        if question[\"category\"] == \"fed_rate\":\n            month = question[\"meeting_month\"]\n            if month in title_lower and (\"cut\" in title_lower or \"rate\" in title_lower):\n                return m\n        elif question[\"category\"] == \"gas_price\":\n            threshold_str = f\"{question['threshold']:.2f}\"\n            if threshold_str in title_lower or str(question[\"threshold\"]) in title_lower:\n                return m\n    return None\n\n\ndef match_kalshi_temp_market(markets, question):\n    \"\"\"Best-effort: find a Kalshi temperature market overlapping our city/threshold.\"\"\"\n    city_words = [w for w in question[\"city_name\"].lower().split() if len(w) > 3]\n    threshold = question[\"threshold_f\"]\n    for m in markets:\n        title_lower = m.get(\"title\", \"\").lower()\n        city_match = any(w in title_lower for w in city_words)\n        numbers = re.findall(r\"\\\\d+\\\\.?\\\\d*\", title_lower)\n        temp_match = any(abs(float(n) - threshold) <= 5 for n in numbers)\n        if city_match and temp_match:\n            return m\n    return None\n\n\ndef match_polymarket_event(events, question):\n    \"\"\"Find the Polymarket event that best matches our question.\"\"\"\n    for e in events:\n        title_lower = e.get(\"title\", \"\").lower()\n        if question[\"category\"] == \"fed_rate\":\n            month = question[\"meeting_month\"]\n            if month in title_lower and \"fed\" in title_lower:\n                return e\n        elif question[\"category\"] == \"gas_price\":\n            if \"gas\" in title_lower:\n                return e\n        elif question[\"category\"] == \"temperature\":\n            city_words = [w for w in question[\"city_name\"].lower().split() if len(w) > 3]\n            if any(w in title_lower for w in city_words) and (\n                \"temperature\" in title_lower or \"weather\" in title_lower\n            ):\n                return e\n    return None\n\n\ndef get_market_price(market_obj, source):\n    \"\"\"Extract the YES probability from a market object.\"\"\"\n    if source == \"kalshi\":\n        for key in [\"yes_bid\", \"last_price\", \"yes_ask\"]:\n            val = market_obj.get(key)\n            if val is not None:\n                val = float(val)\n                return val / 100 if val > 1 else val\n    elif source == \"polymarket\":\n        markets = market_obj.get(\"markets\", [])\n        if markets:\n            for mkt in markets:\n                price = mkt.get(\"outcomePrices\")\n                if price:\n                    prices = json.loads(price) if isinstance(price, str) else price\n                    if prices:\n                        return float(prices[0])\n        if \"price\" in market_obj:\n            return float(market_obj[\"price\"])\n    return np.nan\n\n\ndef collect_market_probabilities(questions, kalshi_fed, kalshi_gas, kalshi_temp,\n                                  poly_fed, poly_gas):\n    \"\"\"Collect prediction market probabilities for all questions.\"\"\"\n    results = []\n    for q in questions:\n        row = {\"question_id\": q[\"id\"], \"question_text\": q[\"text\"]}\n\n        # Kalshi\n        if q[\"category\"] == \"fed_rate\":\n            match = match_kalshi_market(kalshi_fed, q)\n        elif q[\"category\"] == \"gas_price\":\n            match = match_kalshi_market(kalshi_gas, q)\n        elif q[\"category\"] == \"temperature\":\n            match = match_kalshi_temp_market(kalshi_temp, q)\n        else:\n            match = None\n\n        if match:\n            row[\"kalshi_prob\"]   = get_market_price(match, \"kalshi\")\n            row[\"kalshi_ticker\"] = match.get(\"ticker\", \"\")\n        else:\n            row[\"kalshi_prob\"]   = np.nan\n            row[\"kalshi_ticker\"] = None\n\n        # Polymarket (temperature markets rarely on Polymarket; fall back to NaN)\n        if q[\"category\"] == \"temperature\":\n            poly_pool = []\n        elif q[\"category\"] == \"fed_rate\":\n            poly_pool = poly_fed\n        else:\n            poly_pool = poly_gas\n        match = match_polymarket_event(poly_pool, q)\n        row[\"polymarket_prob\"] = get_market_price(match, \"polymarket\") if match else np.nan\n\n        results.append(row)\n    return pd.DataFrame(results)\n\n\nmarket_probs = collect_market_probabilities(\n    all_questions, kalshi_fed, kalshi_gas, kalshi_temp_markets,\n    poly_fed_events, poly_gas_events,\n)\n\nprint(\"Prediction Market Probabilities:\")\nprint(market_probs[[\"question_id\", \"kalshi_prob\", \"polymarket_prob\"]].to_string(index=False))\n\nkalshi_cov = market_probs[\"kalshi_prob\"].notna().sum()\npoly_cov   = market_probs[\"polymarket_prob\"].notna().sum()\nprint(f\"\\nCoverage: Kalshi {kalshi_cov}/{len(all_questions)}, Polymarket {poly_cov}/{len(all_questions)}\")\n\ntemp_mask = market_probs[\"question_id\"].str.startswith(\"temp_\")\nprint(f\"Temperature Kalshi coverage: {market_probs.loc[temp_mask, 'kalshi_prob'].notna().sum()}\"\n      f\"/{temp_mask.sum()}  (many will be NaN — Kalshi temp markets use daily, not monthly, contracts)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: LLM Forecasting\n",
    "\n",
    "## 3.1 Vanilla Prompting (No Tools)\n",
    "\n",
    "Each model receives:\n",
    "1. A **system prompt** establishing the forecasting persona\n",
    "2. A **user prompt** with the specific binary question and resolution criteria\n",
    "3. Instructions to output a probability between 0.0 and 1.0\n",
    "\n",
    "No external data access â€” the model relies entirely on its training data and reasoning.\n",
    "\n",
    "**Key design choice**: prompts deliberately exclude prediction market prices to ensure LLM forecasts are independent and can be fairly compared against market prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3.1 Vanilla Prompting Setup ---\n",
    "\n",
    "VANILLA_SYSTEM_PROMPT = \"\"\"You are an expert forecaster and superforecaster. Your task is to estimate\n",
    "the probability that a specific event will occur. You must provide a single\n",
    "probability estimate between 0.0 (certainly will NOT happen) and 1.0 (certainly WILL happen).\n",
    "\n",
    "Guidelines:\n",
    "- Consider base rates and historical patterns\n",
    "- Account for current economic conditions based on your training data\n",
    "- Be well-calibrated: events you assign 70% probability should occur about 70% of the time\n",
    "- Avoid anchoring to round numbers (0.5, 0.25, 0.75) unless truly justified\n",
    "- Consider both arguments for and against the event occurring\n",
    "\n",
    "You MUST end your response with exactly one line in this format:\n",
    "PROBABILITY: X.XX\n",
    "\n",
    "where X.XX is your probability estimate between 0.00 and 1.00.\"\"\"\n",
    "\n",
    "VANILLA_USER_TEMPLATE = \"\"\"Today's date is {today_date}.\n",
    "\n",
    "Question: {question_text}\n",
    "\n",
    "Resolution criteria: {resolution_criteria}\n",
    "\n",
    "Please reason through this step by step, then provide your probability estimate.\"\"\"\n",
    "\n",
    "\n",
    "def parse_probability_from_response(text):\n",
    "    \"\"\"Extract the probability value from an LLM response.\"\"\"\n",
    "    text = str(text)\n",
    "    # Look for PROBABILITY: X.XX pattern\n",
    "    match = re.search(r\"PROBABILITY:\\s*(0\\.\\d+|1\\.00?|0\\.0+|1\\.0)\", text)\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    # Fallback: look for any decimal between 0 and 1 near the end\n",
    "    matches = re.findall(r\"\\b(0\\.\\d+|1\\.0)\\b\", text[-300:])\n",
    "    if matches:\n",
    "        return float(matches[-1])\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "def get_llm_instance(model_key, temperature=0):\n",
    "    \"\"\"Factory function to create an LLM instance.\"\"\"\n",
    "    config = MODELS[model_key]\n",
    "    if config[\"provider\"] == \"google\":\n",
    "        return ChatGoogleGenerativeAI(model=config[\"model_id\"], temperature=temperature)\n",
    "    elif config[\"provider\"] == \"openai\":\n",
    "        return ChatOpenAI(model=config[\"model_id\"], temperature=temperature)\n",
    "    elif config[\"provider\"] == \"anthropic\":\n",
    "        return ChatAnthropic(model=config[\"model_id\"], temperature=temperature)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown provider: {config['provider']}\")\n",
    "\n",
    "\n",
    "def get_resolution_criteria(question):\n",
    "    \"\"\"Build resolution criteria string for a question.\"\"\"\n",
    "    if question[\"category\"] == \"fed_rate\":\n",
    "        return (\n",
    "            f\"Resolves YES if the FRED federal funds target rate upper bound (DFEDTARU)\"\n",
    "            f\" decreases after the {question['resolution_date']} FOMC meeting.\"\n",
    "            f\" Current target rate upper bound: {question['current_rate']:.2f}%.\"\n",
    "        )\n",
    "    else:\n",
    "        return (\n",
    "            f\"Resolves YES if the EIA weekly US national average retail gasoline price\"\n",
    "            f\" exceeds ${question['threshold']:.2f}/gal by {question['resolution_date']}.\"\n",
    "            f\" Current price: ${question['current_price']:.3f}/gal.\"\n",
    "        )\n",
    "\n",
    "\n",
    "print(\"Vanilla prompting setup complete.\")\n",
    "print(f\"Models to evaluate: {', '.join(MODELS[k]['name'] for k in MODELS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# --- 3.1 Run Vanilla Forecasting ---\n# Runs on ALL questions (train, validate, test).\n# For historical questions the prompt date is set to 30 days before resolution,\n# so the LLM is asked to forecast \"as of\" that earlier date.\n\ndef run_vanilla_forecasting(questions, cache):\n    \"\"\"Run vanilla (no-tool) LLM forecasting across all models and questions.\"\"\"\n    results = []\n    today_default = datetime.now().strftime(\"%Y-%m-%d\")\n\n    for model_key in MODELS:\n        print(f\"\\nForecasting with {MODELS[model_key]['name']} (vanilla)...\")\n        llm = get_llm_instance(model_key, temperature=0)\n\n        for q in tqdm(questions, desc=MODELS[model_key][\"name\"]):\n            cache_key = get_cache_key(\"vanilla\", model_key, q[\"id\"])\n            forecast_date = q.get(\"forecast_date\", today_default)\n\n            if cache_key in cache:\n                output = cache[cache_key][\"output\"]\n            else:\n                criteria = get_resolution_criteria(q)\n                messages = [\n                    SystemMessage(content=VANILLA_SYSTEM_PROMPT),\n                    HumanMessage(content=VANILLA_USER_TEMPLATE.format(\n                        today_date=forecast_date,\n                        question_text=q[\"text\"],\n                        resolution_criteria=criteria,\n                    )),\n                ]\n                try:\n                    response = llm.invoke(messages)\n                    output = response.content\n                except Exception as e:\n                    print(f\"  Error ({model_key}, {q['id']}): {e}\")\n                    output = f\"ERROR: {str(e)}\"\n\n                cache[cache_key] = {\"output\": output}\n                save_cache(cache)\n\n            prob = parse_probability_from_response(output)\n            results.append({\n                \"question_id\":   q[\"id\"],\n                \"model\":         MODELS[model_key][\"name\"],\n                \"method\":        \"vanilla\",\n                \"probability\":   prob,\n                \"split\":         q.get(\"split\", \"test\"),\n                \"raw_output\":    str(output)[-300:],\n            })\n\n    return pd.DataFrame(results)\n\n\ncache = load_cache()\nvanilla_results = run_vanilla_forecasting(all_questions, cache)\nprint(f\"\\nCollected {len(vanilla_results)} vanilla forecasts\")\nprint(vanilla_results.groupby([\"split\", \"model\"])[\"probability\"].describe().round(3))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Tool-Augmented LLM Forecasting\n",
    "\n",
    "Now we give the same models access to real-time data tools:\n",
    "1. **`get_federal_funds_rate`**: Fetch current and historical federal funds rate data from FRED\n",
    "2. **`get_gas_prices`**: Fetch current and historical gasoline prices from EIA\n",
    "3. **`get_fomc_schedule`**: Get the 2026 FOMC meeting schedule with past/upcoming status\n",
    "\n",
    "We use LangChain's `bind_tools()` interface, which works across all three providers. The model decides which tools to call, receives the results, and then produces its forecast.\n",
    "\n",
    "**The key question: does tool access improve forecasting accuracy?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# --- 3.2 Tool Definitions ---\n\n@tool\ndef get_federal_funds_rate(lookback_days: int = 90) -> str:\n    \"\"\"Fetch the current and recent federal funds rate data from FRED.\n\n    Args:\n        lookback_days: Number of days of historical data to return (default 90)\n\n    Returns:\n        A string summary of the federal funds rate data.\n    \"\"\"\n    fred = Fred(api_key=FRED_API_KEY)\n    start = (datetime.now() - timedelta(days=lookback_days)).strftime(\"%Y-%m-%d\")\n\n    rate         = fred.get_series(\"DFF\",      observation_start=start)\n    target_upper = fred.get_series(\"DFEDTARU\", observation_start=start)\n    target_lower = fred.get_series(\"DFEDTARL\", observation_start=start)\n\n    current_rate  = rate.dropna().iloc[-1]\n    current_upper = target_upper.dropna().iloc[-1]\n    current_lower = target_lower.dropna().iloc[-1]\n\n    changes = target_upper.diff().dropna()\n    cuts  = changes[changes < 0]\n    hikes = changes[changes > 0]\n\n    return (\n        f\"Federal Funds Rate Data (last {lookback_days} days):\\n\"\n        f\"- Current effective rate: {current_rate:.2f}%\\n\"\n        f\"- Current target range: {current_lower:.2f}% - {current_upper:.2f}%\\n\"\n        f\"- Rate cuts in period: {len(cuts)} (total: {cuts.sum():.2f}pp)\\n\"\n        f\"- Rate hikes in period: {len(hikes)} (total: {hikes.sum():.2f}pp)\\n\"\n        f\"- Rate on {rate.dropna().index[-1].strftime('%Y-%m-%d')}: {current_rate:.2f}%\\n\"\n        f\"- Rate {lookback_days} days ago: {rate.dropna().iloc[0]:.2f}%\"\n    )\n\n\n@tool\ndef get_gas_prices(weeks: int = 12) -> str:\n    \"\"\"Fetch recent US retail gasoline price data from the EIA.\n\n    Args:\n        weeks: Number of weeks of historical data to return (default 12)\n\n    Returns:\n        A string summary of gasoline price data.\n    \"\"\"\n    params = {\n        \"api_key\": EIA_API_KEY,\n        \"frequency\": \"weekly\",\n        \"data[0]\": \"value\",\n        \"facets[product][]\": \"EPMR\",\n        \"facets[duoarea][]\": \"NUS\",\n        \"sort[0][column]\": \"period\",\n        \"sort[0][direction]\": \"desc\",\n        \"offset\": 0,\n        \"length\": weeks,\n    }\n    response = requests.get(EIA_GAS_PRICE_URL, params=params)\n    data = response.json()[\"response\"][\"data\"]\n\n    prices = [(d[\"period\"], float(d[\"value\"])) for d in data]\n    prices.sort(key=lambda x: x[0])\n\n    current = prices[-1][1]\n    high    = max(p[1] for p in prices)\n    low     = min(p[1] for p in prices)\n    avg     = sum(p[1] for p in prices) / len(prices)\n    trend   = current - prices[0][1]\n\n    return (\n        f\"US Retail Gasoline Prices (last {weeks} weeks):\\n\"\n        f\"- Current price: ${current:.3f}/gal (week of {prices[-1][0]})\\n\"\n        f\"- {weeks}-week high: ${high:.3f}/gal\\n\"\n        f\"- {weeks}-week low: ${low:.3f}/gal\\n\"\n        f\"- {weeks}-week average: ${avg:.3f}/gal\\n\"\n        f\"- Trend: {'Up' if trend > 0 else 'Down'} ${abs(trend):.3f}/gal over {weeks} weeks\\n\"\n        f\"- Recent weekly prices: {', '.join(f'${p[1]:.3f}' for p in prices[-6:])}\"\n    )\n\n\n@tool\ndef get_fomc_schedule() -> str:\n    \"\"\"Get the 2026 FOMC meeting schedule and status.\n\n    Returns:\n        A string listing upcoming FOMC meetings with dates and status.\n    \"\"\"\n    lines = []\n    for m in FOMC_DATES_2026:\n        meeting_date = datetime.strptime(m[\"date\"], \"%Y-%m-%d\")\n        status = \"PAST\" if meeting_date < datetime.now() else \"UPCOMING\"\n        lines.append(f\"  {m['meeting']} 2026 ({m['date']}): {status}\")\n\n    return (\n        \"2026 FOMC Meeting Schedule:\\n\"\n        + \"\\n\".join(lines)\n        + \"\\n\\nNote: The Fed announces its rate decision on the second day of each meeting.\"\n    )\n\n\n@tool\ndef get_temperature_data(city_name: str, lookback_months: int = 3) -> str:\n    \"\"\"Get recent average daily high temperatures and 10-year climate normals for a US city.\n\n    Args:\n        city_name: City to query. One of: New York, Chicago, Miami, Los Angeles,\n                   Denver, Seattle.\n        lookback_months: Months of recent history to fetch (default 3).\n\n    Returns:\n        Recent monthly avg-high temperatures compared to historical normals, plus\n        the historical median for each upcoming forecast month.\n    \"\"\"\n    # Match city name\n    city_key = None\n    for k, v in CITIES.items():\n        if city_name.lower() in [k.replace(\"_\", \" \"), v[\"name\"].lower(), k]:\n            city_key = k\n            break\n    if city_key is None:\n        for k, v in CITIES.items():\n            if city_name.lower() in v[\"name\"].lower() or v[\"name\"].lower() in city_name.lower():\n                city_key = k\n                break\n    if city_key is None:\n        return (\n            f\"City '{city_name}' not recognized. \"\n            f\"Available: {', '.join(v['name'] for v in CITIES.values())}\"\n        )\n\n    city     = CITIES[city_key]\n    end_date = datetime.now().strftime(\"%Y-%m-%d\")\n    start_date = (datetime.now() - timedelta(days=lookback_months * 31)).strftime(\"%Y-%m-%d\")\n\n    try:\n        recent_df = fetch_temp_history(city[\"lat\"], city[\"lon\"], start_date, end_date)\n        recent_df[\"month\"] = recent_df[\"date\"].dt.month\n        recent_df[\"year\"]  = recent_df[\"date\"].dt.year\n        monthly_recent = recent_df.groupby([\"year\", \"month\"])[\"temp_max_f\"].mean()\n\n        normals = city_normals.get(city_key, {})\n        import calendar as _cal\n\n        lines = [f\"Temperature data for {city['name']}:\"]\n        lines.append(\"\\nRecent monthly avg-high temperatures:\")\n        for (yr, mo), mean in monthly_recent.items():\n            normal = normals.get(mo, float(\"nan\"))\n            if not np.isnan(normal):\n                dev = mean - normal\n                lines.append(\n                    f\"  {_cal.month_name[mo]} {yr}: {mean:.1f}\\u00b0F\"\n                    f\"  ({dev:+.1f}\\u00b0F vs 10-yr normal of {normal:.1f}\\u00b0F)\"\n                )\n            else:\n                lines.append(f\"  {_cal.month_name[mo]} {yr}: {mean:.1f}\\u00b0F\")\n\n        lines.append(\"\\n10-year median avg-high (forecast months):\")\n        for m_info in TEMP_MONTHS:\n            mo = m_info[\"month\"]\n            normal = normals.get(mo, float(\"nan\"))\n            if not np.isnan(normal):\n                lines.append(f\"  {m_info['name']} 2026: {normal:.1f}\\u00b0F (historical median)\")\n\n        return \"\\n\".join(lines)\n\n    except Exception as e:\n        return f\"Error fetching temperature data for {city['name']}: {e}\"\n\n\nTOOLS = [get_federal_funds_rate, get_gas_prices, get_fomc_schedule, get_temperature_data]\nprint(f\"Defined {len(TOOLS)} tools: {[t.name for t in TOOLS]}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# --- 3.2 Run Tool-Augmented Forecasting ---\n# Tool-augmented forecasting runs on TEST questions only.\n# Tools fetch real-time data (FRED, EIA, Open-Meteo) which is irrelevant for\n# historical questions; using it on train/validate would contaminate the\n# train/validate Brier comparison.\n\nTOOL_SYSTEM_PROMPT = \"\"\"You are an expert forecaster with access to real-time economic data tools.\nYour task is to estimate the probability that a specific event will occur.\n\nYou have access to the following tools:\n- get_federal_funds_rate: Fetch current and historical federal funds rate data\n- get_gas_prices: Fetch recent US retail gasoline price data\n- get_fomc_schedule: Get the 2026 FOMC meeting schedule\n- get_temperature_data: Fetch recent avg-high temperatures and 10-year normals for a US city\n\nInstructions:\n1. FIRST, use the relevant tools to gather current data\n2. THEN, reason through the question using the data you retrieved\n3. Consider base rates, trends, and current conditions\n4. Provide a well-calibrated probability estimate\n\nYou MUST end your response with exactly one line in this format:\nPROBABILITY: X.XX\"\"\"\n\nTOOL_USER_TEMPLATE = \"\"\"Today's date is {today_date}.\n\nQuestion: {question_text}\n\nResolution criteria: {resolution_criteria}\n\nPlease use the available tools to gather relevant data, then reason through this\nstep by step and provide your probability estimate.\"\"\"\n\n\ndef run_tool_augmented_forecasting(questions, cache):\n    \"\"\"Run tool-augmented LLM forecasting (test questions only).\"\"\"\n    results = []\n    today = datetime.now().strftime(\"%Y-%m-%d\")\n    tool_map = {t.name: t for t in TOOLS}\n\n    for model_key in MODELS:\n        print(f\"\\nForecasting with {MODELS[model_key]['name']} (with tools)...\")\n        llm = get_llm_instance(model_key, temperature=0)\n        llm_with_tools = llm.bind_tools(TOOLS)\n\n        for q in tqdm(questions, desc=f\"{MODELS[model_key]['name']} + tools\"):\n            cache_key = get_cache_key(\"tool\", model_key, q[\"id\"])\n\n            if cache_key in cache:\n                output = cache[cache_key][\"output\"]\n            else:\n                criteria = get_resolution_criteria(q)\n                messages = [\n                    SystemMessage(content=TOOL_SYSTEM_PROMPT),\n                    HumanMessage(content=TOOL_USER_TEMPLATE.format(\n                        today_date=today,\n                        question_text=q[\"text\"],\n                        resolution_criteria=criteria,\n                    )),\n                ]\n                output = \"ERROR: max iterations reached\"\n                for _ in range(5):\n                    try:\n                        resp = llm_with_tools.invoke(messages)\n                    except Exception as e:\n                        output = f\"ERROR: {str(e)}\"\n                        break\n                    messages.append(resp)\n                    if resp.tool_calls:\n                        for tc in resp.tool_calls:\n                            tool_fn = tool_map[tc[\"name\"]]\n                            tool_result = tool_fn.invoke(tc[\"args\"])\n                            messages.append(ToolMessage(\n                                content=str(tool_result),\n                                tool_call_id=tc[\"id\"],\n                            ))\n                    else:\n                        output = resp.content\n                        break\n                cache[cache_key] = {\"output\": output}\n                save_cache(cache)\n\n            prob = parse_probability_from_response(output)\n            results.append({\n                \"question_id\": q[\"id\"],\n                \"model\":       MODELS[model_key][\"name\"],\n                \"method\":      \"tool_augmented\",\n                \"probability\": prob,\n                \"split\":       q.get(\"split\", \"test\"),\n                \"raw_output\":  str(output)[-300:],\n            })\n\n    return pd.DataFrame(results)\n\n\ncache = load_cache()\ntool_results = run_tool_augmented_forecasting(test_questions, cache)\nprint(f\"\\nCollected {len(tool_results)} tool-augmented forecasts (test split only)\")\nprint(tool_results.groupby(\"model\")[\"probability\"].describe().round(3))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4: Scoring and Evaluation\n",
    "\n",
    "## 4.1 Brier Score\n",
    "\n",
    "$$BS = \\frac{1}{N} \\sum_{i=1}^{N} (p_i - o_i)^2$$\n",
    "\n",
    "Reference benchmarks:\n",
    "- **Perfect forecaster**: BS = 0.000\n",
    "- **Always predict 50%** (no skill): BS = 0.250\n",
    "- **Always 100% confident and wrong**: BS = 1.000\n",
    "\n",
    "## 4.2 Hypothetical Returns\n",
    "\n",
    "We simulate a threshold-based betting strategy:\n",
    "- If forecast differs from market price by more than $\\delta$ (default 10pp):\n",
    "  - **Buy YES** if forecast > market + $\\delta$ (cost = market price, payout = $1 if YES)\n",
    "  - **Buy NO** if forecast < market - $\\delta$ (cost = 1 - market price, payout = $1 if NO)\n",
    "- Each bet is $1 notional\n",
    "\n",
    "This tests whether the forecaster can identify **mispriced** markets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# --- 4.1 Resolution & Scoring ---\n\ndef resolve_questions(questions, fred_data, gas_prices):\n    \"\"\"Determine the actual outcomes for resolved questions.\"\"\"\n    outcomes  = {}\n    today     = datetime.now()\n    cache_obj = load_cache()\n\n    for q in questions:\n        res_date = datetime.strptime(q[\"resolution_date\"], \"%Y-%m-%d\")\n        if res_date > today:\n            outcomes[q[\"id\"]] = np.nan\n            continue\n\n        if q[\"category\"] == \"fed_rate\":\n            target = fred_data[\"target_upper\"]\n            pre  = target[target.index <  res_date]\n            post = target[target.index >= res_date]\n            if len(pre) > 0 and len(post) > 0:\n                outcomes[q[\"id\"]] = 1 if post.iloc[0] < pre.iloc[-1] else 0\n            else:\n                outcomes[q[\"id\"]] = np.nan\n\n        elif q[\"category\"] == \"gas_price\":\n            prices_before = gas_prices[gas_prices[\"period\"] <= res_date.strftime(\"%Y-%m-%d\")]\n            if len(prices_before) > 0:\n                outcomes[q[\"id\"]] = 1 if prices_before[\"value\"].iloc[-1] > q[\"threshold\"] else 0\n            else:\n                outcomes[q[\"id\"]] = np.nan\n\n        elif q[\"category\"] == \"temperature\":\n            import calendar as _cal\n            yr, mo = q[\"year\"], q[\"month\"]\n            ck = get_cache_key(\"temp_actual\", q[\"city_key\"], yr, mo)\n            if ck in cache_obj:\n                actual_mean = cache_obj[ck]\n            else:\n                try:\n                    last_day = _cal.monthrange(yr, mo)[1]\n                    df = fetch_temp_history(\n                        q[\"lat\"], q[\"lon\"],\n                        f\"{yr}-{mo:02d}-01\",\n                        f\"{yr}-{mo:02d}-{last_day}\",\n                    )\n                    actual_mean = float(df[\"temp_max_f\"].mean()) if len(df) > 0 else float(\"nan\")\n                except Exception:\n                    actual_mean = float(\"nan\")\n                cache_obj[ck] = actual_mean\n                save_cache(cache_obj)\n\n            if np.isnan(actual_mean):\n                outcomes[q[\"id\"]] = np.nan\n            else:\n                outcomes[q[\"id\"]] = 1 if actual_mean > q[\"threshold_f\"] else 0\n\n    return outcomes\n\n\ndef get_resolution_criteria(question):\n    \"\"\"Build a resolution-criteria string for the LLM prompt.\"\"\"\n    if question[\"category\"] == \"fed_rate\":\n        return (\n            f\"Resolves YES if the FRED federal funds target rate upper bound (DFEDTARU)\"\n            f\" decreases after the {question['resolution_date']} FOMC meeting.\"\n            f\" Current target rate upper bound: {question['current_rate']:.2f}%.\"\n        )\n    elif question[\"category\"] == \"gas_price\":\n        return (\n            f\"Resolves YES if the EIA weekly US national average retail gasoline price\"\n            f\" exceeds ${question['threshold']:.2f}/gal by {question['resolution_date']}.\"\n            f\" Current price: ${question['current_price']:.3f}/gal.\"\n        )\n    elif question[\"category\"] == \"temperature\":\n        return (\n            f\"Resolves YES if the average daily high temperature in {question['city_name']}\"\n            f\" exceeds {question['threshold_f']}\\u00b0F in\"\n            f\" {question['year']}-{question['month']:02d},\"\n            f\" measured as the mean of ERA5 daily maximum temperatures from Open-Meteo.\"\n            f\" Threshold = 10-year historical median ({question['historical_normal_f']}\\u00b0F),\"\n            f\" so the expected base rate is ~50%.\"\n        )\n    else:\n        return f\"Resolution criteria not defined for category: {question['category']}\"\n\n\ndef compute_brier_scores(forecast_df, outcomes):\n    \"\"\"Compute Brier scores for each forecast.\"\"\"\n    df = forecast_df.copy()\n    df[\"outcome\"] = df[\"question_id\"].map(outcomes)\n    df = df.dropna(subset=[\"outcome\", \"probability\"])\n    if len(df) == 0:\n        print(\"WARNING: No resolved questions with valid forecasts. Brier scores cannot be computed.\")\n        return df\n    df[\"brier_score\"] = (df[\"probability\"] - df[\"outcome\"]) ** 2\n    return df\n\n\ndef compute_returns(forecast_df, market_probs, outcomes, delta=0.10):\n    \"\"\"Compute hypothetical returns from threshold-based betting against Kalshi.\"\"\"\n    df = forecast_df.copy()\n    df[\"outcome\"] = df[\"question_id\"].map(outcomes)\n    df = df.merge(market_probs[[\"question_id\", \"kalshi_prob\"]], on=\"question_id\", how=\"left\")\n    df = df.dropna(subset=[\"outcome\", \"probability\", \"kalshi_prob\"])\n\n    rows = []\n    for _, row in df.iterrows():\n        p_f, p_m, outcome = row[\"probability\"], row[\"kalshi_prob\"], row[\"outcome\"]\n        if p_f > p_m + delta:\n            rows.append({**row, \"action\": \"BUY_YES\", \"profit\": outcome * 1.0 - p_m})\n        elif p_f < p_m - delta:\n            rows.append({**row, \"action\": \"BUY_NO\",  \"profit\": (1 - outcome) * 1.0 - (1 - p_m)})\n        else:\n            rows.append({**row, \"action\": \"NO_BET\",  \"profit\": 0.0})\n    return pd.DataFrame(rows)\n\n\nprint(\"Scoring functions defined.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# --- 4.2 Compute Results ---\n\n# Build split lookup from questions\nsplit_map = {q[\"id\"]: q.get(\"split\", \"test\") for q in all_questions}\n\n# Combine all forecasts and stamp split\nall_forecasts = pd.concat([vanilla_results, tool_results], ignore_index=True)\nif \"split\" not in all_forecasts.columns:\n    all_forecasts[\"split\"] = all_forecasts[\"question_id\"].map(split_map)\n\n# Add prediction market forecasts\nmarket_rows = []\nfor _, row in market_probs.iterrows():\n    s = split_map.get(row[\"question_id\"], \"test\")\n    if pd.notna(row.get(\"kalshi_prob\")):\n        market_rows.append({\n            \"question_id\": row[\"question_id\"],\n            \"model\": \"Kalshi (Market)\",\n            \"method\": \"prediction_market\",\n            \"probability\": row[\"kalshi_prob\"],\n            \"split\": s,\n            \"raw_output\": \"\",\n        })\n    if pd.notna(row.get(\"polymarket_prob\")):\n        market_rows.append({\n            \"question_id\": row[\"question_id\"],\n            \"model\": \"Polymarket (Market)\",\n            \"method\": \"prediction_market\",\n            \"probability\": row[\"polymarket_prob\"],\n            \"split\": s,\n            \"raw_output\": \"\",\n        })\nif market_rows:\n    all_forecasts = pd.concat([all_forecasts, pd.DataFrame(market_rows)], ignore_index=True)\n\nprint(f\"Total forecasts: {len(all_forecasts)}\")\nprint(all_forecasts.groupby([\"split\", \"method\", \"model\"]).size().reset_index(name=\"n\").to_string(index=False))\n\n# Resolve questions (all splits)\noutcomes = resolve_questions(all_questions, fred_data, gas_prices)\nby_split = {}\nfor q in all_questions:\n    s = q.get(\"split\", \"test\")\n    by_split.setdefault(s, {\"resolved\": 0, \"pending\": 0})\n    if pd.notna(outcomes.get(q[\"id\"])):\n        by_split[s][\"resolved\"] += 1\n    else:\n        by_split[s][\"pending\"] += 1\n\nprint(\"\\nResolution status by split:\")\nfor s, counts in sorted(by_split.items()):\n    print(f\"  {s}: {counts['resolved']} resolved, {counts['pending']} pending\")\n\n# Brier scores — overall and by split\nscored_df = compute_brier_scores(all_forecasts, outcomes)\nif len(scored_df) > 0:\n    # Add split column to scored_df\n    if \"split\" not in scored_df.columns:\n        scored_df[\"split\"] = scored_df[\"question_id\"].map(split_map)\n\n    print(\"\\n\" + \"=\" * 70)\n    print(\"BRIER SCORES — overall (all resolved questions)\")\n    print(\"=\" * 70)\n    overall = (scored_df.groupby([\"method\", \"model\"])[\"brier_score\"]\n               .agg([\"mean\", \"std\", \"count\"]).rename(\n               columns={\"mean\": \"Mean\", \"std\": \"Std\", \"count\": \"N\"})\n               .sort_values(\"Mean\").round(4))\n    print(overall)\n\n    print(\"\\n\" + \"=\" * 70)\n    print(\"BRIER SCORES — by split\")\n    print(\"=\" * 70)\n    by_split_bs = (scored_df.groupby([\"split\", \"method\", \"model\"])[\"brier_score\"]\n                   .agg([\"mean\", \"count\"]).rename(columns={\"mean\": \"Mean Brier\", \"count\": \"N\"})\n                   .round(4))\n    print(by_split_bs)\n\n    # Kalshi NYC historical benchmark\n    if not kalshi_nyc_history.empty:\n        nyc_valid = kalshi_nyc_history.dropna(subset=[\"market_prob\"])\n        if len(nyc_valid) > 0:\n            print(\"\\n\" + \"=\" * 70)\n            print(\"KALSHI NYC HISTORICAL BENCHMARK (Brier by split)\")\n            print(\"=\" * 70)\n            for s, g in nyc_valid.groupby(\"split\"):\n                bs = ((g[\"market_prob\"] - g[\"outcome\"]) ** 2).mean()\n                print(f\"  {s}: N={len(g)}, Brier={bs:.4f}\")\nelse:\n    print(\"\\nNo questions resolved yet — re-run after resolution dates.\")\n\n# Hypothetical returns (test split + market benchmark only)\nreturns_df = compute_returns(all_forecasts, market_probs, outcomes, delta=0.10)\nif len(returns_df) > 0 and returns_df[\"profit\"].abs().sum() > 0:\n    print(\"\\n\" + \"=\" * 70)\n    print(\"HYPOTHETICAL RETURNS vs. Kalshi (delta=0.10)\")\n    print(\"=\" * 70)\n    ret_sum = (returns_df.groupby([\"method\", \"model\"])[\"profit\"]\n               .agg([\"sum\", \"mean\", \"count\"]).rename(\n               columns={\"sum\": \"Total P&L\", \"mean\": \"Avg/Bet\", \"count\": \"N Bets\"})\n               .sort_values(\"Total P&L\", ascending=False).round(4))\n    print(ret_sum)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5: Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# --- 5.1 Brier Score and Returns Charts ---\n\nfig, axs = plt.subplots(1, 3, figsize=(18, 6))\n\n# Plot 1: Mean Brier Score by forecaster (overall)\nif len(scored_df) > 0:\n    brier_by_method = scored_df.groupby([\"model\", \"method\"])[\"brier_score\"].mean().reset_index()\n    sns.barplot(data=brier_by_method, x=\"model\", y=\"brier_score\", hue=\"method\", ax=axs[0])\n    axs[0].set_title(\"Mean Brier Score by Forecaster\\n(all resolved questions, lower = better)\")\n    axs[0].set_xlabel(\"\")\n    axs[0].set_ylabel(\"Mean Brier Score\")\n    axs[0].tick_params(axis=\"x\", rotation=45)\n    axs[0].axhline(y=0.25, color=\"red\", linestyle=\"--\", alpha=0.5, label=\"No-skill (0.25)\")\n    axs[0].legend(fontsize=7)\nelse:\n    axs[0].text(0.5, 0.5, \"No resolved questions yet\", ha=\"center\", va=\"center\",\n                transform=axs[0].transAxes)\n    axs[0].set_title(\"Mean Brier Score (pending)\")\n\n# Plot 2: Brier Score by split — shows train/validate/test generalisation gap\nif len(scored_df) > 0 and \"split\" in scored_df.columns:\n    split_brier = (scored_df.groupby([\"split\", \"method\"])[\"brier_score\"]\n                   .mean().reset_index())\n    split_order = [s for s in [\"train\", \"validate\", \"test\"] if s in split_brier[\"split\"].values]\n    sns.barplot(data=split_brier, x=\"split\", y=\"brier_score\", hue=\"method\",\n                order=split_order, ax=axs[1])\n    axs[1].set_title(\"Brier Score by Split\\n(train/validate = in-training-data)\")\n    axs[1].set_xlabel(\"\")\n    axs[1].set_ylabel(\"Mean Brier Score\")\n    axs[1].axhline(y=0.25, color=\"red\", linestyle=\"--\", alpha=0.5)\n    axs[1].legend(fontsize=7)\nelse:\n    axs[1].text(0.5, 0.5, \"No resolved questions yet\", ha=\"center\", va=\"center\",\n                transform=axs[1].transAxes)\n    axs[1].set_title(\"Brier by Split (pending)\")\n\n# Plot 3: Cumulative returns\nif len(returns_df) > 0 and returns_df[\"profit\"].abs().sum() > 0:\n    for name, group in returns_df.groupby([\"model\", \"method\"]):\n        label = f\"{name[0]} ({name[1]})\"\n        cumulative = group[\"profit\"].cumsum()\n        axs[2].plot(range(len(cumulative)), cumulative, label=label, marker=\"o\", markersize=3)\n    axs[2].set_title(\"Cumulative Hypothetical Returns\")\n    axs[2].set_xlabel(\"Bet Number\")\n    axs[2].set_ylabel(\"Cumulative P&L ($)\")\n    axs[2].axhline(y=0, color=\"black\", linestyle=\"-\", linewidth=0.5)\n    axs[2].legend(fontsize=6)\nelse:\n    axs[2].text(0.5, 0.5, \"No bets placed yet\", ha=\"center\", va=\"center\",\n                transform=axs[2].transAxes)\n    axs[2].set_title(\"Cumulative Returns (pending)\")\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5.2 Calibration Plot ---\n",
    "\n",
    "def plot_calibration(scored_df, n_bins=5):\n",
    "    \"\"\"Plot calibration curves for each forecaster.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    for (model, method), group in scored_df.groupby([\"model\", \"method\"]):\n",
    "        probs = group[\"probability\"].values\n",
    "        outcomes_arr = group[\"outcome\"].values\n",
    "\n",
    "        bins = np.linspace(0, 1, n_bins + 1)\n",
    "        bin_means = []\n",
    "        bin_freqs = []\n",
    "        for i in range(n_bins):\n",
    "            mask = (probs >= bins[i]) & (probs < bins[i + 1])\n",
    "            if mask.sum() > 0:\n",
    "                bin_means.append(probs[mask].mean())\n",
    "                bin_freqs.append(outcomes_arr[mask].mean())\n",
    "\n",
    "        if bin_means:\n",
    "            ax.plot(bin_means, bin_freqs, marker=\"o\", label=f\"{model} ({method})\")\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], \"k--\", label=\"Perfect calibration\")\n",
    "    ax.set_xlabel(\"Predicted Probability\")\n",
    "    ax.set_ylabel(\"Observed Frequency\")\n",
    "    ax.set_title(\"Calibration Plot\")\n",
    "    ax.legend(loc=\"lower right\", fontsize=7)\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if len(scored_df) > 0:\n",
    "    plot_calibration(scored_df)\n",
    "else:\n",
    "    print(\"Calibration plot will be available once questions resolve.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5.3 Forecast Comparison Heatmap ---\n",
    "\n",
    "def plot_forecast_heatmap(forecasts, questions):\n",
    "    \"\"\"Heatmap of all probabilities: questions (rows) x forecasters (columns).\"\"\"\n",
    "    forecasts = forecasts.copy()\n",
    "    forecasts[\"forecaster\"] = forecasts[\"model\"] + \"\\n(\" + forecasts[\"method\"] + \")\"\n",
    "\n",
    "    pivot = forecasts.pivot_table(\n",
    "        index=\"question_id\",\n",
    "        columns=\"forecaster\",\n",
    "        values=\"probability\",\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(16, max(8, len(pivot) * 0.5)))\n",
    "    sns.heatmap(\n",
    "        pivot, annot=True, fmt=\".2f\", cmap=\"RdYlGn\", center=0.5,\n",
    "        vmin=0, vmax=1, ax=ax, cbar_kws={\"label\": \"Probability\"},\n",
    "    )\n",
    "    ax.set_title(\"Forecast Comparison Heatmap\")\n",
    "    ax.set_ylabel(\"Question\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_forecast_heatmap(all_forecasts, all_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 6: Discussion and Conclusions\n",
    "\n",
    "## Key Questions\n",
    "\n",
    "1. **Do prediction markets outperform LLMs?**\n",
    "   - Compare Brier scores of Kalshi/Polymarket vs. vanilla LLMs vs. tool-augmented LLMs\n",
    "   - Markets aggregate information from many participants; can a single LLM match this?\n",
    "\n",
    "2. **Does tool access improve LLM forecasting?**\n",
    "   - Compare vanilla vs. tool-augmented Brier scores for each model\n",
    "   - Real-time data should help, but does the model use it effectively?\n",
    "\n",
    "3. **Which LLM is the best forecaster?**\n",
    "   - Rank GPT-5, Gemini, Claude by Brier score and returns\n",
    "   - Does the ranking change between vanilla and tool-augmented conditions?\n",
    "\n",
    "4. **Are there category-specific patterns?**\n",
    "   - Fed rate questions may favor models with strong economic reasoning\n",
    "   - Gas price questions may favor models with access to trend data\n",
    "\n",
    "5. **Can any forecaster generate positive returns against the market?**\n",
    "   - A positive total P&L means the forecaster identified genuine mispricings\n",
    "   - How sensitive are returns to the betting threshold delta?\n",
    "\n",
    "## Limitations\n",
    "\n",
    "- **Small sample size**: limited by the number of resolvable questions within the project timeframe\n",
    "- **Single market snapshot**: prediction market prices were captured at one point in time (markets update continuously)\n",
    "- **LLM training cutoffs**: models may lack recent economic data in their training, which is exactly what tool augmentation addresses\n",
    "- **Question design**: our questions may not perfectly overlap with existing prediction market contracts\n",
    "- **Not all questions may resolve**: FOMC meetings later in 2026 won't have outcomes during the semester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# --- 6.1 Summary Statistics ---\n\nif len(scored_df) > 0:\n    # Overall ranking\n    summary = scored_df.groupby([\"method\", \"model\"]).agg({\n        \"brier_score\": [\"mean\", \"std\"],\n        \"probability\": [\"mean\", \"std\"],\n        \"question_id\": \"count\",\n    }).round(4)\n    summary.columns = [\"Mean Brier\", \"Std Brier\", \"Mean Prob\", \"Std Prob\", \"N\"]\n    summary = summary.sort_values(\"Mean Brier\")\n\n    print(\"=\" * 70)\n    print(\"FINAL RESULTS: Forecaster Ranking by Brier Score (all resolved)\")\n    print(\"=\" * 70)\n    print(summary)\n    print(f\"\\nBaseline (always 0.5): Brier = 0.2500  |  Perfect: Brier = 0.0000\")\n\n    # Split breakdown\n    if \"split\" in scored_df.columns:\n        print(\"\\n\" + \"=\" * 70)\n        print(\"TRAIN / VALIDATE / TEST BREAKDOWN\")\n        print(\"(train & validate = in-LLM-training-data; test = post-cutoff)\")\n        print(\"=\" * 70)\n        split_summary = scored_df.groupby([\"split\", \"method\", \"model\"]).agg({\n            \"brier_score\": [\"mean\", \"count\"],\n        }).round(4)\n        split_summary.columns = [\"Mean Brier\", \"N\"]\n        print(split_summary.sort_index())\n\n        # Generalisation gap: test Brier vs. validate Brier\n        print(\"\\n--- Generalisation gap (test - validate Brier) ---\")\n        for (method, model), grp in scored_df.groupby([\"method\", \"model\"]):\n            val_bs  = grp.loc[grp[\"split\"] == \"validate\", \"brier_score\"].mean()\n            test_bs = grp.loc[grp[\"split\"] == \"test\",     \"brier_score\"].mean()\n            if pd.notna(val_bs) and pd.notna(test_bs):\n                gap = test_bs - val_bs\n                print(f\"  {model} ({method}): validate={val_bs:.4f}  test={test_bs:.4f}  gap={gap:+.4f}\")\n\n    # Kalshi NYC historical benchmark\n    if not kalshi_nyc_history.empty:\n        nyc_v = kalshi_nyc_history.dropna(subset=[\"market_prob\"])\n        if len(nyc_v) > 0:\n            print(\"\\n\" + \"=\" * 70)\n            print(\"KALSHI NYC HISTORICAL MARKET ACCURACY\")\n            print(\"=\" * 70)\n            for s, g in nyc_v.groupby(\"split\"):\n                bs = ((g[\"market_prob\"] - g[\"outcome\"]) ** 2).mean()\n                n  = len(g)\n                print(f\"  {s}: N={n:4d}, Brier={bs:.4f}\")\n\nelse:\n    print(\"=\" * 70)\n    print(\"FORECAST SUMMARY (questions not yet resolved)\")\n    print(\"=\" * 70)\n    prob_summary = all_forecasts.groupby([\"split\", \"method\", \"model\"])[\"probability\"].agg(\n        [\"mean\", \"std\", \"count\"])\n    prob_summary.columns = [\"Mean Prob\", \"Std Prob\", \"N\"]\n    print(prob_summary.round(4))\n    print(\"\\nBrier scores will be computed after resolution dates pass.\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}