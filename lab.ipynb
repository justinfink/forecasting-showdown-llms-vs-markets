{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Forecasting Showdown: LLMs vs Kalshi Weather Prediction Markets\n\n## Overview\nWe evaluate whether frontier LLMs are well-calibrated on **Kalshi daily\nhigh-temperature binary markets** across six US cities, and benchmark them\nagainst the **Kalshi prediction market itself** at the same T-1 snapshot.\n\n### Experimental Design\n\n| Forecaster | Snapshot | Weather context |\n|---|---|---|\n| **GPT-4o** | T-1 (eve of event) | 10-day historical highs injected into prompt |\n| **Gemini 2.0 Flash** | T-1 | Same |\n| **Claude 3.5 Sonnet** | T-1 | Same |\n| **Kalshi T-1** | T-1 (last pre-midnight candle) | N/A — live prediction market |\n| **Baseline: Always-50%** | — | None |\n| **Baseline: City-Month Rate** | — | Historical YES rate for that city × month |\n\n**Why T-1?**  Kalshi weather markets open ~10 hours before event_date midnight\nand close ~29 hours *after* event_date midnight — by which point the NWS\nofficial temperature is already on record.  The final `last_price` is **NOT**\na pre-event forecast (it reflects post-outcome knowledge).\n\nInstead, we use the **Kalshi T-1 price**: the last hourly candlestick that\nclosed at or before event_date midnight UTC, fetched from Kalshi's historical\ncandlestick API.  This is the market's last pre-event consensus — a genuine\ncrowd forecast made before the temperature was observed — and constitutes the\nprimary market benchmark that all three AI models compete against.\n\n**Why competitive markets only?**  ~94% of all settled Kalshi weather markets\nhave `last_price` near 0 or 1 (trivially certain outcomes — e.g. \"Will NYC high\nexceed 100°F in January?\").  Including them makes every forecaster look\nartificially accurate.  We restrict to markets where `last_price` fell in\n[0.10, 0.90] — markets where the outcome was genuinely near-threshold.\n\n**Weather context:**  For each T-1 prompt the model receives the 10 observed\ndaily high temperatures immediately preceding the event, fetched from the\nOpen-Meteo ERA5 reanalysis archive.  This is historically accurate for every\nmarket date, not relative to today.\n\n**Metric:** Brier Score  $BS = \\frac{1}{N}\\sum(p_i - o_i)^2$\n(0 = perfect · 0.25 = always-50% baseline · 1 = maximally wrong)\n\n**Knowledge-cutoff analysis:**\n\n| Model | Knowledge Cutoff | Provider |\n|---|---|---|\n| GPT-4o | October 2023 | OpenAI |\n| Claude 3.5 Sonnet | April 2024 | Anthropic |\n| Gemini 2.0 Flash | August 2024 | Google |\n\nAll three cutoffs fall within the Kalshi data window (Aug 2021 – present),\nproviding substantial data *both before and after* each model's cutoff.\nGPT-4o has the most balanced pre/post split: its Oct 2023 cutoff sits near the midpoint of the Aug 2021–present data window."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Install dependencies (safe to re-run) ────────────────────────────────\n%pip install -q \\\n    python-dotenv \\\n    langchain-core langchain-google-genai langchain-openai langchain-anthropic \\\n    pandas pyarrow numpy matplotlib seaborn requests tqdm\nprint(\"Dependencies ready.\")\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Environment Setup ─────────────────────────────────────────────────────\nimport os\nfrom pathlib import Path\n\ntry:\n    from dotenv import load_dotenv\n    if Path(\".env\").exists():\n        load_dotenv(\".env\", override=True)\n        print(\"Loaded .env\")\nexcept ImportError:\n    pass\n\nKALSHI_API_KEY    = os.environ.get(\"KALSHI_API_KEY\",    \"\")\nOPENAI_API_KEY    = os.environ.get(\"OPENAI_API_KEY\",    \"\")\nGOOGLE_API_KEY    = os.environ.get(\"GOOGLE_API_KEY\",    \"\")\nANTHROPIC_API_KEY = os.environ.get(\"ANTHROPIC_API_KEY\", \"\")\n\nfor k, v in {\"KALSHI_API_KEY\": KALSHI_API_KEY, \"OPENAI_API_KEY\": OPENAI_API_KEY,\n             \"GOOGLE_API_KEY\": GOOGLE_API_KEY, \"ANTHROPIC_API_KEY\": ANTHROPIC_API_KEY}.items():\n    print(f\"  {'SET    ' if v else 'MISSING'}  {k}\")\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Imports & Constants ───────────────────────────────────────────────────\nimport hashlib, json, re, time, threading\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nfrom datetime import date, datetime, timedelta\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport requests\nimport seaborn as sns\nfrom tqdm.auto import tqdm\n\nfrom langchain_anthropic import ChatAnthropic\nfrom langchain_core.messages import HumanMessage, SystemMessage\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom langchain_openai import ChatOpenAI\n\n# ── Kalshi API ────────────────────────────────────────────────────────────\nKALSHI_BASE    = \"https://api.elections.kalshi.com/trade-api/v2\"\nKALSHI_HEADERS = {\"Authorization\": f\"Bearer {KALSHI_API_KEY}\"}\n\n# ── Open-Meteo (no key required) ─────────────────────────────────────────\nOPEN_METEO_ARCHIVE = \"https://archive-api.open-meteo.com/v1/archive\"\n\n# ── Cities ────────────────────────────────────────────────────────────────\nCITY_SERIES = {\n    \"New York City\": {\"series\": \"KXHIGHNY\",   \"lat\": 40.71, \"lon\": -74.01},\n    \"Chicago\":       {\"series\": \"KXHIGHCHI\",  \"lat\": 41.85, \"lon\": -87.65},\n    \"Miami\":         {\"series\": \"KXHIGHMIA\",  \"lat\": 25.77, \"lon\": -80.19},\n    \"Los Angeles\":   {\"series\": \"KXHIGHLAX\",  \"lat\": 34.05, \"lon\": -118.24},\n    \"Denver\":        {\"series\": \"KXHIGHDEN\",  \"lat\": 39.74, \"lon\": -104.98},\n    \"Seattle\":       {\"series\": \"KXHIGHTSEA\", \"lat\": 47.61, \"lon\": -122.33},\n}\n\n# ── LLM models  (cutoffs chosen to be close & straddle the data window) ──\nMODELS = {\n    \"gpt\":    {\"name\": \"GPT-4o\",           \"provider\": \"openai\",    \"model_id\": \"gpt-4o\",\n               \"knowledge_cutoff\": date(2023, 10, 1)},\n    \"gemini\": {\"name\": \"Gemini 2.0 Flash\", \"provider\": \"google\",    \"model_id\": \"gemini-2.0-flash\",\n               \"knowledge_cutoff\": date(2024, 8, 1)},\n    \"claude\": {\"name\": \"Claude 3.5 Sonnet\",\"provider\": \"anthropic\", \"model_id\": \"claude-3-5-sonnet-20241022\",\n               \"knowledge_cutoff\": date(2024, 4, 1)},\n}\n\n# ── Sample cap ────────────────────────────────────────────────────────────\n# Max competitive markets per city to send to LLMs.\n# Lower to reduce first-run API cost; raise for richer analysis.\nTARGET_PER_CITY = 150\n\n# ── Competitive-market filter ─────────────────────────────────────────────\n# Only markets where Kalshi's final price was in [0.10, 0.90].\n# These are the near-threshold events that actually test forecasting skill.\nCOMP_MIN, COMP_MAX = 0.10, 0.90\n\n# ── File paths ────────────────────────────────────────────────────────────\nPath(\"cache\").mkdir(exist_ok=True)\nCACHE_FILE      = Path(\"cache/response_cache.json\")\nMARKETS_CACHE   = Path(\"cache/markets.parquet\")\nWEATHER_CACHE   = Path(\"cache/weather.parquet\")\nRESULTS_FILE    = Path(\"cache/results.parquet\")\n\nMONTH_MAP = {m: i for i, m in enumerate(\n    [\"JAN\",\"FEB\",\"MAR\",\"APR\",\"MAY\",\"JUN\",\"JUL\",\"AUG\",\"SEP\",\"OCT\",\"NOV\",\"DEC\"], start=1)}\n\nprint(\"Config loaded.\")\nprint(f\"Models: {[MODELS[k]['name'] for k in MODELS]}\")\ncutoffs_str = \", \".join(\n    MODELS[k][\"name\"] + \": \" + MODELS[k][\"knowledge_cutoff\"].strftime(\"%b %Y\")\n    for k in MODELS\n)\nprint(f\"Cutoffs: {cutoffs_str}\")\nprint(f\"Cities: {list(CITY_SERIES.keys())}\")\nprint(f\"Competitive filter: kalshi_prob in [{COMP_MIN}, {COMP_MAX}]\")\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Caching Helpers ───────────────────────────────────────────────────────\nCACHE_LOCK = threading.Lock()\n\ndef load_cache():\n    if CACHE_FILE.exists():\n        return json.loads(CACHE_FILE.read_text(encoding=\"utf-8\"))\n    return {}\n\ndef save_cache(cache):\n    CACHE_FILE.write_text(json.dumps(cache, indent=2, ensure_ascii=False),\n                          encoding=\"utf-8\")\n\ndef ck(*args):\n    \"\"\"16-char SHA-256 cache key.\"\"\"\n    return hashlib.sha256(\":\".join(str(a) for a in args).encode()).hexdigest()[:16]\n\nprint(\"Cache ready.\")\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Fetch Settled Kalshi Markets ──────────────────────────────────────────\n\ndef parse_event_date(event_ticker: str):\n    \"\"\"Parse event date from ticker like KXHIGHNY-24FEB21.\"\"\"\n    m = re.search(r\"-(\\d{2})([A-Z]{3})(\\d{2})$\", event_ticker)\n    if not m:\n        return None\n    yy, mon, dd = m.groups()\n    mo = MONTH_MAP.get(mon)\n    if not mo:\n        return None\n    try:\n        return date(2000 + int(yy), mo, int(dd))\n    except ValueError:\n        return None\n\n\ndef fetch_settled_series(series_ticker: str, max_pages: int = 80,\n                         delay: float = 0.15) -> list:\n    \"\"\"Page through all settled markets for a Kalshi series.\"\"\"\n    markets, cursor = [], None\n    for _ in range(max_pages):\n        params = {\"series_ticker\": series_ticker, \"status\": \"settled\", \"limit\": 200}\n        if cursor:\n            params[\"cursor\"] = cursor\n        try:\n            r = requests.get(KALSHI_BASE + \"/markets\",\n                             headers=KALSHI_HEADERS, params=params, timeout=20)\n            r.raise_for_status()\n            data = r.json()\n        except Exception as e:\n            print(f\"    warn: {e}\")\n            break\n        batch = data.get(\"markets\", [])\n        if not batch:\n            break\n        markets.extend(batch)\n        cursor = data.get(\"cursor\")\n        if not cursor:\n            break\n        time.sleep(delay)\n    return markets\n\n\ndef market_to_row(m: dict, city: str, info: dict):\n    \"\"\"Convert raw Kalshi market dict to a flat row. Returns None to skip.\"\"\"\n    ev         = m.get(\"event_ticker\", \"\")\n    event_date = parse_event_date(ev)\n    if event_date is None:\n        return None\n\n    floor     = m.get(\"floor_strike\")\n    cap       = m.get(\"cap_strike\")\n    threshold = floor if floor is not None else cap\n    direction = m.get(\"strike_type\", \"greater\")\n\n    try:\n        actual_temp = float(m.get(\"expiration_value\") or \"nan\")\n    except (ValueError, TypeError):\n        actual_temp = np.nan\n\n    lp          = m.get(\"last_price\")\n    kalshi_prob = float(lp) / 100.0 if lp is not None else np.nan\n\n    result  = m.get(\"result\", \"\").lower()\n    outcome = 1 if result == \"yes\" else (0 if result == \"no\" else np.nan)\n\n    return {\n        \"ticker\":        m.get(\"ticker\", \"\"),\n        \"event_ticker\":  ev,\n        \"series\":        info[\"series\"],\n        \"city\":          city,\n        \"lat\":           info[\"lat\"],\n        \"lon\":           info[\"lon\"],\n        \"event_date\":    event_date,\n        \"threshold_f\":   float(threshold) if threshold is not None else np.nan,\n        \"direction\":     direction,\n        \"title\":         m.get(\"title\", \"\"),\n        \"rules_primary\": m.get(\"rules_primary\", \"\"),\n        \"result\":        result,\n        \"outcome\":       outcome,\n        \"actual_temp_f\": actual_temp,\n        \"kalshi_prob\":   kalshi_prob,\n        \"volume\":        int(m.get(\"volume\", 0) or 0),\n        \"open_time\":     m.get(\"open_time\", \"\"),\n        \"close_time\":    m.get(\"close_time\", \"\"),\n    }\n\n\ndef build_markets_df() -> pd.DataFrame:\n    rows = []\n    for city, info in CITY_SERIES.items():\n        print(f\"  {info['series']:12s} ({city})...\", end=\" \", flush=True)\n        raw = fetch_settled_series(info[\"series\"])\n        print(f\"{len(raw):,}\")\n        for m in raw:\n            row = market_to_row(m, city, info)\n            if row:\n                rows.append(row)\n    df = pd.DataFrame(rows)\n    df[\"event_date\"] = pd.to_datetime(df[\"event_date\"])\n    df = df.drop_duplicates(subset=\"ticker\")\n    df = df.sort_values([\"city\", \"event_date\", \"threshold_f\"]).reset_index(drop=True)\n    return df\n\n\nif MARKETS_CACHE.exists():\n    print(\"Loading markets from parquet cache...\")\n    markets_df = pd.read_parquet(MARKETS_CACHE)\n    print(f\"  {len(markets_df):,} markets loaded\")\nelse:\n    print(\"Fetching all settled markets from Kalshi (~2 min)...\")\n    markets_df = build_markets_df()\n    markets_df.to_parquet(MARKETS_CACHE, index=False)\n    print(f\"Cached {len(markets_df):,} markets\")\n\nprint(f\"Date range: {markets_df['event_date'].min().date()} to \"\n      f\"{markets_df['event_date'].max().date()}\")\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Fetch Historical Weather from Open-Meteo ERA5 Archive ─────────────────\n# Pre-fetch full daily high temperature history per city.\n# Injected into T-1 prompts as accurate historical context —\n# avoids the tool-call problem where get_recent_weather() returns today's\n# temperatures for a December 2022 question.\n\ndef fetch_city_weather(city: str, info: dict,\n                       start: str = \"2021-07-01\") -> pd.DataFrame:\n    \"\"\"Fetch daily max temperatures from Open-Meteo archive.\"\"\"\n    end = datetime.now().strftime(\"%Y-%m-%d\")\n    params = {\n        \"latitude\":          info[\"lat\"],\n        \"longitude\":         info[\"lon\"],\n        \"start_date\":        start,\n        \"end_date\":          end,\n        \"daily\":             \"temperature_2m_max\",\n        \"temperature_unit\":  \"fahrenheit\",\n        \"timezone\":          \"auto\",\n    }\n    r = requests.get(OPEN_METEO_ARCHIVE, params=params, timeout=30)\n    r.raise_for_status()\n    data = r.json()\n    return pd.DataFrame({\n        \"city\": city,\n        \"date\": pd.to_datetime(data[\"daily\"][\"time\"]),\n        \"temp_f\": data[\"daily\"][\"temperature_2m_max\"],\n    })\n\n\nif WEATHER_CACHE.exists():\n    print(\"Loading weather from cache...\")\n    weather_df = pd.read_parquet(WEATHER_CACHE)\nelse:\n    print(\"Fetching historical weather from Open-Meteo archive (6 cities)...\")\n    frames = []\n    for city, info in CITY_SERIES.items():\n        print(f\"  {city}...\", end=\" \", flush=True)\n        try:\n            df = fetch_city_weather(city, info)\n            frames.append(df)\n            print(f\"{len(df)} days\")\n        except Exception as e:\n            print(f\"ERROR: {e}\")\n    weather_df = pd.concat(frames, ignore_index=True)\n    weather_df.to_parquet(WEATHER_CACHE, index=False)\n    print(f\"Cached {len(weather_df):,} rows\")\n\n\ndef get_weather_context(city: str, forecast_date: str, days_back: int = 10) -> str:\n    \"\"\"Return the N observed daily highs immediately before forecast_date.\"\"\"\n    fd  = pd.Timestamp(forecast_date)\n    cw  = weather_df[(weather_df[\"city\"] == city) &\n                     (weather_df[\"date\"] < fd)].sort_values(\"date\").tail(days_back)\n    if len(cw) == 0:\n        return f\"(No weather history available for {city} before {forecast_date})\"\n    lines = [f\"Observed daily high temperatures for {city} (degF):\"]\n    for _, row in cw.iterrows():\n        if pd.notna(row[\"temp_f\"]):\n            lines.append(f\"  {row['date'].strftime('%Y-%m-%d')}: {row['temp_f']:.1f}\")\n    return \"\\n\".join(lines)\n\n\nprint(f\"Weather coverage: {weather_df['date'].min().date()} to \"\n      f\"{weather_df['date'].max().date()}\")\nprint(f\"Cities: {sorted(weather_df['city'].unique())}\")\n# Quick sanity check\nsample_ctx = get_weather_context(\"New York City\", \"2024-02-15\", days_back=5)\nprint(\"\\nSample context (NYC, 5 days before 2024-02-15):\")\nprint(sample_ctx)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 1: Market Data\n\n### Why Kalshi last_price cannot be used as a forecaster\n\nKalshi daily high-temperature markets close approximately **29 hours after\nthe event_date midnight** — early the next morning, after the NWS official\ndaily maximum has been recorded.  At close time, any trader can look up the\nexact temperature on weather.com or the NWS website.  As a result:\n\n- **~71% of markets** settle with `last_price < 0.10` (near-certain NO).\n- **~16% settle** with `last_price > 0.90` (near-certain YES).\n- Kalshi's overall Brier score across all markets is **≈ 0.014** — not \"crowd\n  wisdom\" but post-outcome pricing.\n\n### Competitive market selection\n\nWe restrict to markets where `last_price ∈ [0.10, 0.90]` — the cases where\nthe temperature was genuinely near the threshold.  This ensures we test\n*calibration skill* rather than the ability to distinguish 95°F from 50°F in\nJanuary.\n\nNote: Kalshi weather markets come in three direction types:\n- **greater** — \"Will high exceed X°F?\"\n- **less** — \"Will high stay below X°F?\"\n- **between** — \"Will high be in the X–Y°F range?\" (2-degree bins)\n\nAll three are included; the exact `rules_primary` text is fed verbatim to the\nLLM so it sees the same question market participants traded on.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Market Data Overview ──────────────────────────────────────────────────\nprint(f\"Total settled markets : {len(markets_df):,}\")\nprint(f\"Direction breakdown   : {markets_df['direction'].value_counts().to_dict()}\")\n\n# ── Timing: last_price is post-event ─────────────────────────────────────\ndf_t = markets_df.copy()\ndf_t[\"close_dt\"]  = pd.to_datetime(df_t[\"close_time\"], utc=True, errors=\"coerce\")\ndf_t[\"event_dt\"]  = pd.to_datetime(df_t[\"event_date\"], utc=True)\ndf_t[\"hrs_after\"] = (df_t[\"close_dt\"] - df_t[\"event_dt\"]).dt.total_seconds() / 3600\nprint(f\"\\nHours market closes AFTER event_date midnight:\")\nprint(f\"  median = {df_t['hrs_after'].median():.1f} h  \"\n      f\"(range {df_t['hrs_after'].min():.0f}–{df_t['hrs_after'].max():.0f} h)\")\nprint(\"  => last_price reflects post-outcome knowledge; not used as a forecaster.\")\n\n# ── Probability distribution ─────────────────────────────────────────────\nvalid = markets_df.dropna(subset=[\"kalshi_prob\",\"outcome\"])\nprint(f\"\\nkalshi_prob distribution (all {len(valid):,} settled markets):\")\nbuckets = pd.cut(valid[\"kalshi_prob\"],\n                 bins=[0, 0.10, 0.20, 0.40, 0.60, 0.80, 0.90, 1.0])\nprint(buckets.value_counts().sort_index().to_string())\nprint(f\"\\nKalshi Brier on ALL markets: {((valid['kalshi_prob']-valid['outcome'])**2).mean():.4f}\"\n      f\"  (deceptively low — post-event pricing)\")\n\n# ── Competitive subset ────────────────────────────────────────────────────\ncomp = valid[(valid[\"kalshi_prob\"] >= COMP_MIN) & (valid[\"kalshi_prob\"] <= COMP_MAX)]\nprint(f\"\\nCompetitive markets ({COMP_MIN}–{COMP_MAX}): {len(comp):,} \"\n      f\"({100*len(comp)/len(valid):.1f}% of all)\")\nprint(f\"Kalshi Brier on competitive only: {((comp['kalshi_prob']-comp['outcome'])**2).mean():.4f}\")\nprint(f\"YES rate (competitive): {comp['outcome'].mean():.3f}\")\nprint(\"\\nCompetitive markets per city:\")\nprint(comp.groupby(\"city\").size().sort_values(ascending=False).to_string())\nprint(\"\\nCompetitive markets per year:\")\ncomp2 = comp.copy()\ncomp2[\"year\"] = pd.to_datetime(comp2[\"event_date\"]).dt.year\nprint(comp2.groupby([\"city\",\"year\"]).size().unstack(fill_value=0).to_string())\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Competitive Market Sample for LLM Evaluation ─────────────────────────\n# Filter to competitive markets, then cap per city for API cost control.\n# All directions (greater / less / between) are included — the LLM sees\n# the exact rules_primary text, so \"between X-Y\" markets are handled.\n\neligible = markets_df[\n    markets_df[\"kalshi_prob\"].between(COMP_MIN, COMP_MAX) &\n    markets_df[\"outcome\"].notna() &\n    markets_df[\"rules_primary\"].str.len().gt(30) &\n    markets_df[\"actual_temp_f\"].notna()\n].copy()\n\n# Assign knowledge-cutoff split labels\neligible[\"event_dt\"] = pd.to_datetime(eligible[\"event_date\"], utc=True)\n\nearliest_cutoff = min(cfg[\"knowledge_cutoff\"] for cfg in MODELS.values())   # Oct 2023\nlatest_cutoff   = max(cfg[\"knowledge_cutoff\"] for cfg in MODELS.values())   # Aug 2024\n\ndef cutoff_period(event_date):\n    d = pd.Timestamp(event_date).date()\n    if d < earliest_cutoff:\n        return \"pre_all\"         # before ALL model cutoffs\n    if d >= latest_cutoff:\n        return \"post_all\"        # after ALL model cutoffs\n    return \"transition\"          # in the Oct-2023 to Apr-2024 window\n\neligible[\"cutoff_period\"] = eligible[\"event_date\"].apply(cutoff_period)\n\n# Per-city cap: sample by highest volume within competitive range\n# Prefer even spread across cutoff_period labels\nparts = []\nfor city, grp in eligible.groupby(\"city\"):\n    if len(grp) == 0:\n        continue\n    # Sort by volume descending within each cutoff_period, take evenly\n    sampled = (grp.sort_values(\"volume\", ascending=False)\n                  .groupby(\"cutoff_period\", group_keys=False)\n                  .apply(lambda g: g.head(TARGET_PER_CITY // 3))\n                  .reset_index(drop=True))\n    # Top up with remaining if we have room\n    already = set(sampled[\"ticker\"])\n    remaining = grp[~grp[\"ticker\"].isin(already)].sort_values(\"volume\", ascending=False)\n    fill = max(0, TARGET_PER_CITY - len(sampled))\n    sampled = pd.concat([sampled, remaining.head(fill)], ignore_index=True)\n    parts.append(sampled)\n\nsample_df = (pd.concat(parts, ignore_index=True)\n               .sort_values([\"city\", \"event_date\"])\n               .reset_index(drop=True))\n\n# Add per-model post_cutoff flag\nfor mk, cfg in MODELS.items():\n    col = f\"post_cutoff_{mk}\"\n    sample_df[col] = pd.to_datetime(sample_df[\"event_date\"]).dt.date >= cfg[\"knowledge_cutoff\"]\n\nprint(f\"Sample: {len(sample_df)} markets  x  {len(MODELS)} models  = \"\n      f\"{len(sample_df)*len(MODELS):,} LLM calls (all cached after first run)\")\nprint()\nprint(\"Per city:\")\nprint(sample_df.groupby(\"city\").size().sort_values(ascending=False).to_string())\nprint()\nprint(\"Per cutoff_period:\")\nprint(sample_df[\"cutoff_period\"].value_counts().to_string())\nprint()\nprint(\"Per-model post-cutoff counts:\")\nfor mk in MODELS:\n    col = f\"post_cutoff_{mk}\"\n    post = sample_df[col].sum()\n    print(f\"  {MODELS[mk]['name']:22s}: post={post}  pre={len(sample_df)-post}\")\nprint()\nprint(\"Example rows:\")\ncols = [\"ticker\",\"city\",\"event_date\",\"direction\",\"threshold_f\",\"title\",\n        \"outcome\",\"actual_temp_f\",\"kalshi_prob\",\"cutoff_period\"]\nprint(sample_df[cols].head(6).to_string(index=False))\n"
  },
  {
   "cell_type": "code",
   "id": "d8zojo9d42o",
   "source": [
    "# -- Fetch Kalshi T-1 Prices via Candlestick API (v2: timezone-aware) ------\n# Bug fix: original code used midnight UTC as T-1 cutoff.\n# US Kalshi weather markets measure temperature in LOCAL time, so the correct\n# T-1 cutoff is midnight LOCAL (= 5-8am UTC depending on city/DST).\n# Using midnight UTC: no pre-event candles found -> fallback any_[0] grabbed\n# the opening candle (naive initial price), which was anti-correlated with\n# outcomes (Brier > 0.42).  Fix: city-local midnight via zoneinfo.\n# No fallback: NaN if no pre-local-midnight candle rather than corrupt data.\n# Rate limiting: 2 workers + exponential backoff; 429s are NOT cached.\n\nfrom zoneinfo import ZoneInfo\nfrom datetime import datetime as _dt\n\nCITY_TZ = {\n    \"New York City\": \"America/New_York\",\n    \"Chicago\":       \"America/Chicago\",\n    \"Miami\":         \"America/New_York\",\n    \"Los Angeles\":   \"America/Los_Angeles\",\n    \"Denver\":        \"America/Denver\",\n    \"Seattle\":       \"America/Los_Angeles\",\n}\n\nKALSHI_T1_CACHE = Path(\"cache/kalshi_t1_prices.parquet\")\n\n\ndef fetch_t1_price(row: dict) -> tuple:\n    \"\"\"Return (result_dict, should_cache) for one market T-1 price.\"\"\"\n    ticker         = row[\"ticker\"]\n    series         = row[\"series\"]\n    city           = row.get(\"city\", \"Chicago\")\n    event_date_str = str(row[\"event_date\"])[:10]  # \"YYYY-MM-DD\"\n\n    # Compute local-midnight timestamp for this city\n    tz   = ZoneInfo(CITY_TZ.get(city, \"America/Chicago\"))\n    lmid = _dt.strptime(event_date_str, \"%Y-%m-%d\").replace(tzinfo=tz)\n    t1_ts    = int(lmid.timestamp())                          # midnight LOCAL\n    open_ts  = int((lmid - timedelta(hours=48)).timestamp())  # 48h look-back\n    close_ts = int((lmid + timedelta(hours=36)).timestamp())  # 36h post\n\n    url    = f\"{KALSHI_BASE}/series/{series}/markets/{ticker}/candlesticks\"\n    params = {\"start_ts\": open_ts, \"end_ts\": close_ts, \"period_interval\": 60}\n\n    for attempt in range(3):\n        try:\n            r = requests.get(url, headers=KALSHI_HEADERS,\n                             params=params, timeout=15)\n            if r.status_code == 429:\n                time.sleep(5 * 2 ** attempt)\n                continue   # retry; do NOT cache 429\n            r.raise_for_status()\n            candles = r.json().get(\"candlesticks\", [])\n            break\n        except requests.exceptions.HTTPError as e:\n            if attempt < 2:\n                time.sleep(3)\n                continue\n            return {\"ticker\": ticker, \"kalshi_t1_prob\": float(\"nan\"),\n                    \"t1_error\": str(e)[:80]}, True\n        except Exception as e:\n            return {\"ticker\": ticker, \"kalshi_t1_prob\": float(\"nan\"),\n                    \"t1_error\": str(e)[:80]}, True\n    else:\n        # All 3 attempts 429 -- do NOT cache, will retry next run\n        return {\"ticker\": ticker, \"kalshi_t1_prob\": float(\"nan\"),\n                \"t1_error\": \"429_rate_limit\"}, False\n\n    # Last candle ending at or before local midnight\n    pre = [c for c in candles\n           if c.get(\"end_period_ts\", 0) <= t1_ts\n           and c.get(\"price\", {}).get(\"close\") is not None]\n\n    if not pre:\n        # No genuine pre-event candle -- do NOT use opening-day price as proxy\n        return {\"ticker\": ticker, \"kalshi_t1_prob\": float(\"nan\"),\n                \"t1_error\": \"no_pre_candle\"}, True\n\n    raw = pre[-1][\"price\"][\"close\"]\n    return {\"ticker\": ticker, \"kalshi_t1_prob\": float(raw) / 100.0,\n            \"t1_error\": None}, True\n\n\n# -- Load or fetch T-1 prices ------------------------------------------\nif KALSHI_T1_CACHE.exists():\n    print(\"Loading Kalshi T-1 prices from cache...\")\n    t1_prices_df = pd.read_parquet(KALSHI_T1_CACHE)\n    fetched_tickers = set(t1_prices_df[\"ticker\"])\n    # Permanent NaN = no_pre_candle or HTTP error (don't retry)\n    permanent_nan = set(\n        t1_prices_df.loc[\n            t1_prices_df[\"kalshi_t1_prob\"].isna() &\n            (t1_prices_df[\"t1_error\"] != \"429_rate_limit\"),\n            \"ticker\"\n        ]\n    )\n    # Retry 429s and markets not yet attempted\n    retry_429       = set(t1_prices_df.loc[t1_prices_df[\"t1_error\"] == \"429_rate_limit\", \"ticker\"])\n    missing_tickers = set(sample_df[\"ticker\"]) - fetched_tickers - permanent_nan\n    to_fetch = missing_tickers | retry_429\n    if to_fetch:\n        print(f\"  Fetching {len(to_fetch)} missing/429-limited markets...\")\n        fetch_recs = (sample_df[sample_df[\"ticker\"].isin(to_fetch)]\n                      [[\"ticker\", \"series\", \"event_date\", \"city\"]].to_dict(\"records\"))\n        new_rows = []\n        with ThreadPoolExecutor(max_workers=2) as executor:\n            futs = {executor.submit(fetch_t1_price, r): r for r in fetch_recs}\n            for f in tqdm(as_completed(futs), total=len(futs), desc=\"T-1 prices\"):\n                result, should_cache = f.result()\n                if should_cache:\n                    new_rows.append(result)\n        # Drop old 429 rows for tickers we just retried\n        retried = {r[\"ticker\"] for r in new_rows if r[\"ticker\"] in retry_429}\n        t1_prices_df = t1_prices_df[~t1_prices_df[\"ticker\"].isin(retried)]\n        if new_rows:\n            t1_prices_df = pd.concat([t1_prices_df, pd.DataFrame(new_rows)],\n                                      ignore_index=True)\n        t1_prices_df.to_parquet(KALSHI_T1_CACHE, index=False)\n    print(f\"  {len(t1_prices_df):,} prices loaded\")\nelse:\n    print(f\"Fetching Kalshi T-1 prices for {len(sample_df):,} markets (2 workers)...\")\n    records = sample_df[[\"ticker\", \"series\", \"event_date\", \"city\"]].to_dict(\"records\")\n    t1_raw  = []\n    with ThreadPoolExecutor(max_workers=2) as executor:\n        futs = {executor.submit(fetch_t1_price, r): r for r in records}\n        for f in tqdm(as_completed(futs), total=len(futs), desc=\"T-1 prices\"):\n            result, should_cache = f.result()\n            if should_cache:\n                t1_raw.append(result)\n    t1_prices_df = pd.DataFrame(t1_raw)\n    t1_prices_df.to_parquet(KALSHI_T1_CACHE, index=False)\n    print(f\"Cached {len(t1_prices_df):,} prices\")\n\n# -- Coverage & sanity checks -------------------------------------------\nn_ok  = t1_prices_df[\"kalshi_t1_prob\"].notna().sum()\nn_tot = len(t1_prices_df)\nprint(f\"\\nT-1 price coverage: {n_ok}/{n_tot} ({100*n_ok/n_tot:.1f}%)\")\n\ndiag = (t1_prices_df\n        .merge(sample_df[[\"ticker\", \"kalshi_prob\", \"outcome\"]], on=\"ticker\")\n        .dropna(subset=[\"kalshi_t1_prob\", \"outcome\"]))\ndelta_mean = (diag[\"kalshi_t1_prob\"] - diag[\"kalshi_prob\"]).abs().mean()\ncorr       = diag[\"kalshi_t1_prob\"].corr(diag[\"kalshi_prob\"])\nprint(f\"Mean |T-1 - final|: {delta_mean:.3f}   T-1 vs final corr: {corr:.3f}\")\nt1_brier  = ((diag[\"kalshi_t1_prob\"] - diag[\"outcome\"]) ** 2).mean()\nfin_brier = ((diag[\"kalshi_prob\"]    - diag[\"outcome\"]) ** 2).mean()\nprint(f\"Kalshi T-1 Brier   : {t1_brier:.4f}  (pre-event market price)\")\nprint(f\"Kalshi final Brier : {fin_brier:.4f}  (post-event -- NOT used as a forecast)\")\nprint()\nprint(\"T-1 price distribution:\")\nbins_ = pd.cut(diag[\"kalshi_t1_prob\"],\n               bins=[0, .10, .20, .40, .60, .80, .90, 1.0]).value_counts().sort_index()\nprint(bins_.to_string())\nprint()\nprint(\"t1_error breakdown (for NaN markets):\")\nprint(t1_prices_df[t1_prices_df[\"kalshi_t1_prob\"].isna()][\"t1_error\"].value_counts().to_string())\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 2: LLM Forecasting\n\n### What the model sees\n\nEach model receives:\n1. **System prompt** — role as a calibrated superforecaster, format instructions.\n2. **Exact Kalshi market title** — verbatim, no paraphrasing.\n3. **Exact resolution criteria** (`rules_primary`) — the NWS source and threshold.\n4. **10-day weather context** — observed daily high temperatures immediately\n   before the forecast date, fetched from the Open-Meteo ERA5 archive.\n\nNo tools are used.  Weather context is pre-fetched and injected directly,\nensuring historical accuracy (a December 2022 market gets December 2022\ntemperatures, not today's).\n\n### Knowledge-cutoff hypothesis\n\nFor weather forecasting, the cutoff effect should be **small**: seasonal\ntemperature patterns for these cities are stable and well-represented in all\nmodels' training data regardless of cutoff.  The weather context further\nreduces the advantage of recent training data.  If we find no significant\ncutoff effect, that is itself an interesting result — LLM weather calibration\nappears robust to training-data recency.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Prompts & Model Factory ───────────────────────────────────────────────\nSYSTEM_PROMPT = (\n    \"You are an expert weather forecaster and superforecaster specialising in \"\n    \"prediction market calibration. Your sole task is to estimate the probability \"\n    \"that a specific Kalshi binary weather market resolves YES.\\n\\n\"\n    \"Guidelines:\\n\"\n    \"- Use the provided recent temperature observations as your primary evidence.\\n\"\n    \"- Ground your estimate in seasonal climatology for the city and month.\\n\"\n    \"- Be well-calibrated: a 70% probability should resolve YES ~70% of the time.\\n\"\n    \"- Avoid anchoring to round numbers (0.25, 0.50, 0.75) unless clearly justified.\\n\\n\"\n    \"End your response with EXACTLY one line:\\n\"\n    \"PROBABILITY: X.XX\\n\"\n    \"where X.XX is a decimal in [0.00, 1.00].\"\n)\n\nUSER_T1 = (\n    \"Today is {forecast_date} — the market resolves tomorrow.\\n\\n\"\n    \"Market title: {title}\\n\\n\"\n    \"Resolution criteria: {rules_primary}\\n\\n\"\n    \"{weather_context}\\n\\n\"\n    \"Based on the temperature observations above and your knowledge of \"\n    \"seasonal patterns for {city} in {month_name}, \"\n    \"estimate the probability this market resolves YES. \"\n    \"Think step by step, then state your probability.\"\n)\n\n\ndef parse_prob(text: str) -> float:\n    text = str(text)\n    m = re.search(r\"PROBABILITY:\\s*(0\\.\\d+|1\\.0+|0\\.0+)\", text)\n    if m:\n        return float(m.group(1))\n    hits = re.findall(r\"\\b(0\\.\\d+|1\\.0)\\b\", text[-500:])\n    return float(hits[-1]) if hits else np.nan\n\n\ndef get_llm(model_key: str):\n    cfg = MODELS[model_key]\n    if cfg[\"provider\"] == \"openai\":\n        return ChatOpenAI(model=cfg[\"model_id\"], temperature=0,\n                          api_key=OPENAI_API_KEY)\n    if cfg[\"provider\"] == \"google\":\n        return ChatGoogleGenerativeAI(model=cfg[\"model_id\"], temperature=0,\n                                      google_api_key=GOOGLE_API_KEY)\n    if cfg[\"provider\"] == \"anthropic\":\n        return ChatAnthropic(model=cfg[\"model_id\"], temperature=0,\n                             api_key=ANTHROPIC_API_KEY)\n    raise ValueError(f\"Unknown provider: {cfg['provider']}\")\n\n\nprint(\"AI setup complete.\")\nprint(f\"Models: {[MODELS[k]['name'] for k in MODELS]}\")\nprint(\"No tools — weather context injected directly into prompt.\")\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── T-1 Forecasting (parallel, weather context in prompt) ─────────────────\nN_WORKERS  = 4     # conservative: avoids GPT-4o 30k TPM rate limit\nSAVE_EVERY = 10    # flush cache every N new completions\n\n\ndef run_t1(df, cache):\n    llm_pool  = {mk: get_llm(mk) for mk in MODELS}\n    tasks     = [(mk, row) for mk in MODELS for _, row in df.iterrows()]\n    new_count = [0]\n\n    def forecast_one(args):\n        model_key, row = args\n        cfg = MODELS[model_key]\n        key = ck(\"t1v2\", model_key, row[\"ticker\"])\n\n        with CACHE_LOCK:\n            if key in cache:\n                output = cache[key][\"output\"]\n                return {\n                    \"ticker\": row[\"ticker\"], \"model\": cfg[\"name\"],\n                    \"model_key\": model_key, \"snapshot\": \"T-1\",\n                    \"probability\": parse_prob(output), \"raw_output\": str(output)[-400:],\n                }, None\n\n        fd  = (pd.Timestamp(row[\"event_date\"]) - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n        mon = pd.Timestamp(row[\"event_date\"]).strftime(\"%B\")\n        wx  = get_weather_context(row[\"city\"], fd)\n\n        msgs = [\n            SystemMessage(content=SYSTEM_PROMPT),\n            HumanMessage(content=USER_T1.format(\n                forecast_date=fd, title=row[\"title\"],\n                rules_primary=row[\"rules_primary\"],\n                city=row[\"city\"], month_name=mon, weather_context=wx,\n            )),\n        ]\n\n        # Retry up to 3 times with backoff on rate-limit errors\n        output = None\n        for attempt in range(3):\n            try:\n                output = llm_pool[model_key].invoke(msgs).content\n                break\n            except Exception as e:\n                err = str(e)\n                if attempt < 2 and (\"rate_limit\" in err.lower() or \"429\" in err):\n                    time.sleep(5 * (2 ** attempt))   # 5s then 10s\n                else:\n                    output = f\"ERROR: {e}\"\n                    break\n        if output is None:\n            output = \"ERROR: max retries exceeded\"\n\n        # Never cache error strings — let them retry on the next run\n        save_entry = None if str(output).startswith(\"ERROR:\") else (key, output)\n\n        return {\n            \"ticker\": row[\"ticker\"], \"model\": cfg[\"name\"],\n            \"model_key\": model_key, \"snapshot\": \"T-1\",\n            \"probability\": parse_prob(output), \"raw_output\": str(output)[-400:],\n        }, save_entry\n\n    results = []\n    with ThreadPoolExecutor(max_workers=N_WORKERS) as executor:\n        futures = {executor.submit(forecast_one, t): t for t in tasks}\n        for future in tqdm(as_completed(futures), total=len(futures), desc=\"T-1 forecasts\"):\n            result, update = future.result()\n            results.append(result)\n            if update:\n                k, out = update\n                with CACHE_LOCK:\n                    cache[k] = {\"output\": out}\n                    new_count[0] += 1\n                    if new_count[0] % SAVE_EVERY == 0:\n                        save_cache(cache)\n    save_cache(cache)\n\n    t1 = pd.DataFrame(results)\n    valid = t1.dropna(subset=[\"probability\"])\n    print(f\"T-1 forecasts: {len(t1)} | parse success: {len(valid)}/{len(t1)}\")\n    print(t1.groupby(\"model\")[\"probability\"].describe().round(3))\n    return t1\n\n\ncache      = load_cache()\nt1_results = run_t1(sample_df, cache)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Assemble Master Results DataFrame ─────────────────────────────────────\nMETA_COLS = [\n    \"ticker\",\"city\",\"event_date\",\"direction\",\"threshold_f\",\"title\",\n    \"rules_primary\",\"result\",\"outcome\",\"actual_temp_f\",\"kalshi_prob\",\n    \"volume\",\"cutoff_period\",\n] + [f\"post_cutoff_{mk}\" for mk in MODELS]\n\nresults_df = t1_results.merge(sample_df[META_COLS], on=\"ticker\", how=\"left\")\n\nresults_df[\"brier\"] = np.where(\n    results_df[[\"probability\",\"outcome\"]].notna().all(axis=1),\n    (results_df[\"probability\"] - results_df[\"outcome\"]) ** 2,\n    np.nan,\n)\n\n# ── Add per-model post_cutoff column (denormalised for easy filtering) ────\nresults_df[\"post_cutoff\"] = results_df.apply(\n    lambda r: bool(r.get(f\"post_cutoff_{r['model_key']}\", False))\n              if r[\"model_key\"] in MODELS else False,\n    axis=1,\n)\n\n# ── Compute city × month historical YES base rates (pre_all period only) ──\npre_data = sample_df[sample_df[\"cutoff_period\"] == \"pre_all\"].dropna(subset=[\"outcome\"])\npre_data = pre_data.copy()\npre_data[\"month\"] = pd.to_datetime(pre_data[\"event_date\"]).dt.month\nbase_rate_map = {}\nfor (city, month), g in pre_data.groupby([\"city\",\"month\"]):\n    if len(g) >= 3:\n        base_rate_map[(city, month)] = g[\"outcome\"].mean()\n    else:\n        base_rate_map[(city, month)] = sample_df[\"outcome\"].mean()\n\nglobal_yes_rate = sample_df[\"outcome\"].dropna().mean()\n\ndef get_base_rate(city, event_date):\n    month = pd.Timestamp(event_date).month\n    return base_rate_map.get((city, month), global_yes_rate)\n\n# ── Add baseline rows ─────────────────────────────────────────────────────\nbaseline_rows = []\nfor _, row in sample_df.dropna(subset=[\"outcome\"]).iterrows():\n    p50    = 0.50\n    p_base = get_base_rate(row[\"city\"], row[\"event_date\"])\n    for model_name, prob in [(\"Baseline: Always-50%\", p50),\n                              (\"Baseline: City-Month Rate\", p_base)]:\n        baseline_rows.append({\n            **{c: row[c] for c in META_COLS if c in row.index},\n            \"model\":       model_name,\n            \"model_key\":   \"baseline\",\n            \"snapshot\":    \"T-1\",\n            \"probability\": prob,\n            \"raw_output\":  \"\",\n            \"brier\":       (prob - row[\"outcome\"]) ** 2,\n            \"post_cutoff\": False,\n        })\n\n# ── Add Kalshi T-1 rows ───────────────────────────────────────────────────\n# Kalshi T-1 = last pre-midnight hourly candlestick price.\n# This is the market's genuine pre-event consensus, fetched via the\n# /series/{series}/markets/{ticker}/candlesticks endpoint.\nt1_map = t1_prices_df.set_index(\"ticker\")[\"kalshi_t1_prob\"].to_dict()\nkalshi_t1_rows = []\nfor _, row in sample_df.dropna(subset=[\"outcome\"]).iterrows():\n    prob = t1_map.get(row[\"ticker\"], np.nan)\n    if pd.isna(prob):\n        continue\n    kalshi_t1_rows.append({\n        **{c: row[c] for c in META_COLS if c in row.index},\n        \"model\":       \"Kalshi T-1\",\n        \"model_key\":   \"kalshi_t1\",\n        \"snapshot\":    \"T-1\",\n        \"probability\": prob,\n        \"raw_output\":  \"\",\n        \"brier\":       (prob - row[\"outcome\"]) ** 2,\n        \"post_cutoff\": False,\n    })\n\nresults_df = pd.concat(\n    [results_df, pd.DataFrame(baseline_rows), pd.DataFrame(kalshi_t1_rows)],\n    ignore_index=True,\n)\n\n# ── Persist ───────────────────────────────────────────────────────────────\nresults_df.to_parquet(RESULTS_FILE, index=False)\nresults_df.drop(columns=[\"raw_output\",\"rules_primary\"], errors=\"ignore\").to_csv(\n    \"cache/results.csv\", index=False)\n\nprint(f\"Saved: {RESULTS_FILE}  ({len(results_df):,} rows)\")\nprint(f\"Forecasters: {sorted(results_df['model'].unique())}\")\nprint(f\"\\nBase rates (city x month, from pre_all period):\")\nprint(f\"  Used {len(base_rate_map)} city-month combos  |  global fallback={global_yes_rate:.3f}\")\nprint(f\"Kalshi T-1 rows: {len(kalshi_t1_rows)}\")\nprint()\nprint(results_df[[\"ticker\",\"city\",\"event_date\",\"direction\",\"model\",\"probability\",\n                  \"outcome\",\"brier\",\"cutoff_period\",\"post_cutoff\"]\n                ].head(12).to_string(index=False))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 3: Brier Score Analysis\n\nFive views of forecast quality — all on **competitive markets only**\n( 10–90%) so results measure genuine calibration skill:\n\n1. **Overall** — mean Brier across all models and periods.\n2. **AI vs Kalshi T-1** — head-to-head at the same T-1 snapshot.\n3. **By city** — geographic variation in forecast difficulty.\n4. **Pre- vs post-cutoff** — per-model comparison using each model's own\n   knowledge-cutoff date.\n5. **Cutoff-period cohorts** — pre_all / transition / post_all analysis.\n6. **Calibration** — reliability diagram; a well-calibrated forecaster lies on\n   the diagonal."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Brier Score Analysis ───────────────────────────────────────────────────\nscored = results_df.dropna(subset=[\"brier\"]).copy()\nSEP = \"=\" * 72\n\n# ── Overall ───────────────────────────────────────────────────────────────\nprint(f\"\\n{SEP}\")\nprint(\"OVERALL BRIER SCORES  (lower = better | always-50% baseline = 0.2500)\")\nprint(SEP)\noverall = (\n    scored.groupby(\"model\")[\"brier\"]\n    .agg([\"mean\",\"std\",\"count\"])\n    .rename(columns={\"mean\":\"Mean Brier\",\"std\":\"Std\",\"count\":\"N\"})\n    .round(4)\n    .sort_values(\"Mean Brier\")\n)\nprint(overall.to_string())\n\n# ── AI models vs Kalshi T-1 ───────────────────────────────────────────────\nprint(f\"\\n{SEP}\")\nprint(\"AI MODELS vs KALSHI T-1  (same pre-event T-1 snapshot)\")\nprint(SEP)\nkt1_briers = scored[scored[\"model\"] == \"Kalshi T-1\"][\"brier\"]\nprint(f\"  Kalshi T-1 (market): {kt1_briers.mean():.4f}  (N={len(kt1_briers)})\")\nfor mk, cfg in MODELS.items():\n    ai_grp  = scored[scored[\"model_key\"] == mk][\"brier\"]\n    diff    = ai_grp.mean() - kt1_briers.mean()\n    verdict = (\"BEATS market\"   if diff < -0.005\n               else \"matches market\" if abs(diff) <= 0.005\n               else \"trails market\")\n    print(f\"  {cfg['name']:22s}: {ai_grp.mean():.4f}  \"\n          f\"delta={diff:+.4f}  [{verdict}]\")\n\n# ── By city ───────────────────────────────────────────────────────────────\nprint(f\"\\n{SEP}\")\nprint(\"MEAN BRIER BY CITY  (AI models + Kalshi T-1)\")\nprint(SEP)\ncity_tab = (\n    scored[~scored[\"model\"].str.startswith(\"Baseline\")]\n    .groupby([\"city\",\"model\"])[\"brier\"]\n    .mean().round(4).unstack()\n)\nif len(city_tab):\n    print(city_tab.to_string())\n\n# ── Per-model pre vs post cutoff ─────────────────────────────────────────\nprint(f\"\\n{SEP}\")\nprint(\"PER-MODEL PRE- vs POST-CUTOFF BRIER  (T-1 snapshot, AI models only)\")\nprint(SEP)\nai_scored = scored[scored[\"model_key\"].isin(MODELS.keys())]\nfor model_key, cfg in MODELS.items():\n    grp  = ai_scored[ai_scored[\"model_key\"] == model_key]\n    pre  = grp.loc[~grp[\"post_cutoff\"], \"brier\"]\n    post = grp.loc[ grp[\"post_cutoff\"], \"brier\"]\n    print(f\"  {cfg['name']}  (cutoff: {cfg['knowledge_cutoff']})\")\n    if len(pre):\n        print(f\"    PRE-cutoff:  N={len(pre):4d}  Brier={pre.mean():.4f}  \"\n              f\"std={pre.std():.4f}\")\n    if len(post):\n        gap = post.mean() - pre.mean() if len(pre) else float(\"nan\")\n        print(f\"    POST-cutoff: N={len(post):4d}  Brier={post.mean():.4f}  \"\n              f\"std={post.std():.4f}  delta={gap:+.4f}\")\n\n# ── Cutoff-period cohorts ─────────────────────────────────────────────────\nprint(f\"\\n{SEP}\")\nprint(\"BRIER BY CUTOFF-PERIOD COHORT  (pre_all / transition / post_all)\")\nprint(SEP)\ncohort_tab = (\n    scored.groupby([\"cutoff_period\",\"model\"])[\"brier\"]\n    .agg([\"mean\",\"count\"])\n    .rename(columns={\"mean\":\"Brier\",\"count\":\"N\"})\n    .round(4)\n)\nprint(cohort_tab.to_string())"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 4: Visualisations"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Plots ─────────────────────────────────────────────────────────────────\nfrom matplotlib.patches import Patch\n\nfig, axs = plt.subplots(2, 2, figsize=(16, 12))\nfig.suptitle(\"Forecasting Showdown: LLMs vs Kalshi Prediction Market (T-1 snapshot)\",\n             fontsize=14)\n\n# ── 1. Overall Brier by model ─────────────────────────────────────────────\nax = axs[0, 0]\nmeans = scored.groupby(\"model\")[\"brier\"].mean().sort_values()\ncolors = []\nfor m in means.index:\n    if m == \"Kalshi T-1\":\n        colors.append(\"darkorange\")\n    elif not m.startswith(\"Baseline\"):\n        colors.append(\"steelblue\")\n    else:\n        colors.append(\"lightgray\")\nmeans.plot(kind=\"barh\", ax=ax, color=colors, edgecolor=\"gray\", linewidth=0.5)\nax.axvline(0.25, color=\"red\", ls=\"--\", alpha=0.7)\nlegend_els = [\n    Patch(facecolor=\"steelblue\",  label=\"AI model\"),\n    Patch(facecolor=\"darkorange\", label=\"Kalshi T-1 market\"),\n    Patch(facecolor=\"lightgray\",  label=\"Naive baseline\"),\n    plt.Line2D([0],[0], color=\"red\", ls=\"--\", alpha=0.7, label=\"No-skill (0.25)\"),\n]\nax.legend(handles=legend_els, fontsize=8)\nax.set_title(\"Mean Brier Score (competitive markets, T-1 snapshot)\")\nax.set_xlabel(\"Mean Brier Score\")\n\n# ── 2. Pre vs post cutoff per model ──────────────────────────────────────\nax = axs[0, 1]\nai_sc = scored[scored[\"model_key\"].isin(MODELS.keys())].copy()\npp_data = (ai_sc.groupby([\"model\",\"post_cutoff\"])[\"brier\"]\n           .mean().unstack())\nif True in pp_data.columns and False in pp_data.columns:\n    pp_data[[False, True]].rename(columns={False:\"Pre-cutoff\", True:\"Post-cutoff\"}\n                                  ).plot(kind=\"bar\", ax=ax, rot=20, width=0.7)\n    ax.axhline(0.25, color=\"red\", ls=\"--\", alpha=0.7, label=\"No-skill (0.25)\")\n    if \"Kalshi T-1\" in scored[\"model\"].values:\n        kt1_mean = scored[scored[\"model\"] == \"Kalshi T-1\"][\"brier\"].mean()\n        ax.axhline(kt1_mean, color=\"darkorange\", ls=\"-.\", lw=1.8,\n                   label=f\"Kalshi T-1 ({kt1_mean:.3f})\")\n    ax.set_title(\"Pre- vs Post-Cutoff Brier per AI Model\")\n    ax.set_ylabel(\"Mean Brier\")\n    ax.set_xlabel(\"\")\n    ax.legend(fontsize=8)\nelse:\n    ax.text(0.5, 0.5, \"Insufficient pre/post data\", ha=\"center\", va=\"center\",\n            transform=ax.transAxes)\n    ax.set_title(\"Pre- vs Post-Cutoff (no data)\")\n\n# ── 3. Brier by cutoff-period cohort ─────────────────────────────────────\nax = axs[1, 0]\ncohort_order = [\"pre_all\",\"transition\",\"post_all\"]\ncohort_data  = (scored[scored[\"model_key\"].isin(MODELS.keys())]\n                .groupby([\"cutoff_period\",\"model\"])[\"brier\"]\n                .mean().reset_index())\ncohort_data[\"cutoff_period\"] = pd.Categorical(cohort_data[\"cutoff_period\"],\n                                               categories=cohort_order, ordered=True)\ncohort_data = cohort_data.sort_values(\"cutoff_period\")\nsns.barplot(data=cohort_data, x=\"cutoff_period\", y=\"brier\", hue=\"model\", ax=ax)\nax.axhline(0.25, color=\"red\", ls=\"--\", alpha=0.7)\nif \"Kalshi T-1\" in scored[\"model\"].values:\n    kt1_mean = scored[scored[\"model\"] == \"Kalshi T-1\"][\"brier\"].mean()\n    ax.axhline(kt1_mean, color=\"darkorange\", ls=\"-.\", lw=1.8,\n               label=f\"Kalshi T-1 ({kt1_mean:.3f})\")\nax.set_title(\"Brier by Temporal Cohort (AI models; Kalshi T-1 = dashed orange)\")\nax.set_ylabel(\"Mean Brier\")\nax.set_xlabel(\"\")\nax.legend(fontsize=7)\n\n# ── 4. Calibration curves ─────────────────────────────────────────────────\nax = axs[1, 1]\nbins = np.linspace(0, 1, 11)\n\ndef calibration_curve(sub):\n    mx, fy = [], []\n    for i in range(len(bins) - 1):\n        mask = (sub[\"probability\"] >= bins[i]) & (sub[\"probability\"] < bins[i+1])\n        if mask.sum() >= 5:\n            mx.append(sub.loc[mask, \"probability\"].mean())\n            fy.append(sub.loc[mask, \"outcome\"].mean())\n    return mx, fy\n\nmarkers = {\"GPT-4o\": \"o\", \"Gemini 1.5 Flash\": \"s\", \"Claude 3.5 Sonnet\": \"^\"}\nfor mk, cfg in MODELS.items():\n    sub = scored[scored[\"model_key\"] == mk].dropna(subset=[\"outcome\"])\n    if len(sub) < 10:\n        continue\n    mx, fy = calibration_curve(sub)\n    if mx:\n        ax.plot(mx, fy, marker=markers.get(cfg[\"name\"],\"o\"), lw=1.5,\n                label=cfg[\"name\"])\n\n# Kalshi T-1 calibration\nkt1_sub = scored[scored[\"model\"] == \"Kalshi T-1\"].dropna(subset=[\"outcome\"])\nif len(kt1_sub) >= 10:\n    mx, fy = calibration_curve(kt1_sub)\n    if mx:\n        ax.plot(mx, fy, marker=\"D\", lw=2, color=\"darkorange\", label=\"Kalshi T-1\")\n\n# Baselines\nfor bname, ls_ in [(\"Baseline: City-Month Rate\", \"--\"), (\"Baseline: Always-50%\", \":\")]:\n    sub = scored[scored[\"model\"] == bname].dropna(subset=[\"outcome\"])\n    if len(sub) >= 10:\n        mx, fy = calibration_curve(sub)\n        if mx:\n            ax.plot(mx, fy, ls=ls_, lw=1, color=\"gray\", label=bname)\n\nax.plot([0,1],[0,1], \"k--\", lw=0.8, alpha=0.4)\nax.set_xlabel(\"Predicted Probability\")\nax.set_ylabel(\"Observed YES Rate\")\nax.set_title(\"Calibration Curves (T-1 snapshot, all forecasters)\")\nax.legend(fontsize=7)\n\nplt.tight_layout()\nplt.savefig(\"cache/results_plots.png\", dpi=150, bbox_inches=\"tight\")\nplt.show()\nprint(\"Saved: cache/results_plots.png\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 5: Summary"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Final Summary ─────────────────────────────────────────────────────────\nSEP = \"=\" * 72\nprint(SEP)\nprint(\"FORECASTING SHOWDOWN — FINAL LEADERBOARD\")\nprint(\"LLMs (T-1) vs Kalshi Prediction Market (T-1) vs Baselines\")\nprint(SEP)\nprint(f\"Markets evaluated : {sample_df['ticker'].nunique():,} competitive markets\")\nprint(f\"Cities            : {', '.join(sorted(sample_df['city'].unique()))}\")\nev_dates = pd.to_datetime(sample_df['event_date'])\nprint(f\"Event date range  : {ev_dates.min().date()} to {ev_dates.max().date()}\")\nprint()\n\nleaderboard = (\n    scored.groupby(\"model\")[\"brier\"]\n    .mean().round(4).reset_index()\n    .rename(columns={\"brier\":\"Mean Brier\"})\n    .sort_values(\"Mean Brier\")\n)\nprint(leaderboard.to_string(index=False))\nprint()\nprint(f\"  Always-50% baseline:     0.2500\")\nprint(f\"  Perfect calibration:     0.0000\")\n\nprint(f\"\\n{SEP}\")\nprint(\"AI MODELS vs KALSHI PREDICTION MARKET  (both at T-1 snapshot)\")\nprint(SEP)\nkt1_brier = scored[scored[\"model\"] == \"Kalshi T-1\"][\"brier\"].mean()\nprint(f\"  Kalshi T-1 (market): {kt1_brier:.4f}  ← benchmark\")\nfor mk, cfg in MODELS.items():\n    ai_brier = scored[scored[\"model_key\"] == mk][\"brier\"].mean()\n    diff     = ai_brier - kt1_brier\n    verdict  = (\"BEATS market\"   if diff < -0.005\n                else \"matches market\" if abs(diff) <= 0.005\n                else \"trails market\")\n    print(f\"  {cfg['name']:22s}: {ai_brier:.4f}  \"\n          f\"(delta={diff:+.4f}  {verdict})\")\n\nprint(f\"\\n{SEP}\")\nprint(\"KNOWLEDGE CUTOFF EFFECT SUMMARY\")\nprint(SEP)\nai_sc2 = scored[scored[\"model_key\"].isin(MODELS.keys())]\nfor mk, cfg in MODELS.items():\n    grp  = ai_sc2[ai_sc2[\"model_key\"] == mk]\n    pre  = grp.loc[~grp[\"post_cutoff\"], \"brier\"].mean()\n    post = grp.loc[ grp[\"post_cutoff\"], \"brier\"].mean()\n    gap  = post - pre if pd.notna(pre) and pd.notna(post) else float(\"nan\")\n    flag = \"(degraded)\" if gap > 0.005 else \"(stable)\" if abs(gap) <= 0.005 else \"(improved?)\"\n    print(f\"  {cfg['name']:22s}: pre={pre:.4f}  post={post:.4f}  \"\n          f\"delta={gap:+.4f}  {flag}\")\n\nprint(f\"\\n{SEP}\")\nprint(\"INTERPRETATION\")\nprint(SEP)\nprint(\"  Core question: Can frontier LLMs match a liquid prediction market\")\nprint(\"  at forecasting binary weather outcomes, given the same information\")\nprint(\"  horizon (T-1 = eve of event)?\")\nprint()\nprint(\"  Kalshi T-1 = market's last hourly candle before event_date midnight,\")\nprint(\"  fetched via the series-level candlestick API.  This is 21–22 hours\")\nprint(\"  before the NWS official high temperature is recorded.\")\nprint()\nprint(\"  Knowledge cutoff: for weather markets, cutoff effect should be small.\")\nprint(\"  Seasonal temperature patterns are stable; 10-day weather context\")\nprint(\"  provides the key signal regardless of training-data recency.\")\nprint()\nprint(\"  A large positive delta = performance degrades post-cutoff.\")\nprint(\"  A near-zero delta = model skill is robust to training-data age.\")\n\nprint(f\"\\n{SEP}\")\nprint(\"HOW TO RELOAD RESULTS\")\nprint(SEP)\nprint(\"  import pandas as pd\")\nprint(\"  results_df = pd.read_parquet('cache/results.parquet')\")\nprint(\"  # key columns: ticker, city, event_date, direction, model, model_key,\")\nprint(\"  #   probability, outcome, brier, cutoff_period, post_cutoff\")"
  }
 ]
}