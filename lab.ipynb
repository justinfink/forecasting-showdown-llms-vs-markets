{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Forecasting Showdown: Kalshi Weather Markets vs Frontier LLMs\n\n## Overview\nWe evaluate whether frontier LLMs can beat **Kalshi daily high-temperature markets**\nacross six US cities.\n\n### Experimental Design\n\n| Forecaster | Prompt date | Tool access |\n|---|---|---|\n| **AI @ T-7** | event_date − 7 days | None — pure climatological priors |\n| **AI @ T-1** | event_date − 1 day | `get_recent_weather` via Open-Meteo |\n| **Kalshi Market** | Final settlement price | Live crowd wisdom |\n\n**Resolution**: Kalshi's own `expiration_value` field — the exact NWS-recorded\ntemperature used to settle each contract.\n\n**Metric**: Brier Score  $BS = \\frac{1}{N}\\sum(p_i - o_i)^2$\n(0 = perfect, 0.25 = always-50% baseline, 1 = maximally wrong)\n\n**Train / Validate / Test split** (fixed chronological boundaries):\n- **Train**: before 2024-01-01 — pre-cutoff for all three models\n- **Validate**: 2024-01-01 – 2025-08-31 — straddles per-model cutoffs (GPT-4o crosses at Jun 2024; Gemini 2.5 Flash at Jan 2025)\n- **Test**: 2025-09-01 onward — post-cutoff for all three models\n\nThe fixed splits enable a chronological hold-out evaluation. Within each split the\n`post_cutoff` column (per row in results) provides the precise per-model boundary:\na market is post-cutoff for a given model if its event date falls on or after that\nmodel's knowledge cutoff date.\n\n**Model Knowledge Cutoffs** (training data upper bounds):\n\n| Model | Knowledge Cutoff | First post-cutoff split |\n|---|---|---|\n| GPT-4o | June 2024 | Validate (Jul 2024 onward) |\n| Gemini 2.5 Flash | January 2025 | Validate (Jan 2025 onward) |\n| Claude Sonnet 4.6 | August 2025 | Test (Sep 2025 onward) |"
  },
  {
   "cell_type": "code",
   "id": "ae2mr3wdugj",
   "source": "# ── Install dependencies (safe to re-run; skips already-installed packages) ──\n%pip install -q \\\n    python-dotenv \\\n    langchain-core langchain-google-genai langchain-openai langchain-anthropic \\\n    pandas pyarrow numpy matplotlib seaborn requests tqdm\nprint(\"Dependencies ready.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Environment Setup ─────────────────────────────────────────────────────\nimport os\nfrom pathlib import Path\n\ntry:\n    from dotenv import load_dotenv\n    if Path(\".env\").exists():\n        load_dotenv(\".env\", override=True)\n        print(\"Loaded .env\")\nexcept ImportError:\n    print(\"python-dotenv not installed — using environment variables directly\")\n\nKALSHI_API_KEY    = os.environ.get(\"KALSHI_API_KEY\",    \"\")\nOPENAI_API_KEY    = os.environ.get(\"OPENAI_API_KEY\",    \"\")\nGOOGLE_API_KEY    = os.environ.get(\"GOOGLE_API_KEY\",    \"\")\nANTHROPIC_API_KEY = os.environ.get(\"ANTHROPIC_API_KEY\", \"\")\n\nfor k, v in {\n    \"KALSHI_API_KEY\":    KALSHI_API_KEY,\n    \"OPENAI_API_KEY\":    OPENAI_API_KEY,\n    \"GOOGLE_API_KEY\":    GOOGLE_API_KEY,\n    \"ANTHROPIC_API_KEY\": ANTHROPIC_API_KEY,\n}.items():\n    print(f\"  {'SET    ' if v else 'MISSING'}  {k}\")\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Imports & Constants ───────────────────────────────────────────────────\nimport hashlib\nimport json\nimport re\nimport time\nfrom datetime import date, datetime, timedelta\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport requests\nimport seaborn as sns\nfrom tqdm.auto import tqdm\n\nfrom langchain_anthropic import ChatAnthropic\nfrom langchain_core.messages import HumanMessage, SystemMessage, ToolMessage\nfrom langchain_core.tools import tool\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom langchain_openai import ChatOpenAI\n\n# ── Kalshi API ────────────────────────────────────────────────────────────\nKALSHI_BASE    = \"https://api.elections.kalshi.com/trade-api/v2\"\nKALSHI_HEADERS = {\"Authorization\": f\"Bearer {KALSHI_API_KEY}\"}\n\n# ── Open-Meteo endpoints (no key required) ────────────────────────────────\nOPEN_METEO_ARCHIVE  = \"https://archive-api.open-meteo.com/v1/archive\"\nOPEN_METEO_FORECAST = \"https://api.open-meteo.com/v1/forecast\"\n\n# ── City config: Kalshi series + coordinates ─────────────────────────────\n# Primary series (KXHIGH*) includes all historical HIGHXX markets via pagination\nCITY_SERIES = {\n    \"New York City\": {\"series\": \"KXHIGHNY\",   \"lat\": 40.71, \"lon\": -74.01},\n    \"Chicago\":       {\"series\": \"KXHIGHCHI\",  \"lat\": 41.85, \"lon\": -87.65},\n    \"Miami\":         {\"series\": \"KXHIGHMIA\",  \"lat\": 25.77, \"lon\": -80.19},\n    \"Los Angeles\":   {\"series\": \"KXHIGHLAX\",  \"lat\": 34.05, \"lon\": -118.24},\n    \"Denver\":        {\"series\": \"KXHIGHDEN\",  \"lat\": 39.74, \"lon\": -104.98},\n    \"Seattle\":       {\"series\": \"KXHIGHTSEA\", \"lat\": 47.61, \"lon\": -122.33},\n}\n\n# ── LLM models ────────────────────────────────────────────────────────────\n# knowledge_cutoff: upper bound of each model's training data (exclusive).\n# A market with event_date >= knowledge_cutoff is \"post-cutoff\" for that model —\n# the model cannot have seen patterns from that period during training.\nMODELS = {\n    \"gpt\":    {\"name\": \"GPT-4o\",            \"provider\": \"openai\",    \"model_id\": \"gpt-4o\",            \"knowledge_cutoff\": date(2024, 6, 1)},\n    \"gemini\": {\"name\": \"Gemini 2.5 Flash\",  \"provider\": \"google\",    \"model_id\": \"gemini-2.5-flash\",  \"knowledge_cutoff\": date(2025, 1, 1)},\n    \"claude\": {\"name\": \"Claude Sonnet 4.6\", \"provider\": \"anthropic\", \"model_id\": \"claude-sonnet-4-6\", \"knowledge_cutoff\": date(2025, 8, 1)},\n}\n\n# ── Split boundaries ──────────────────────────────────────────────────────\nTRAIN_END    = date(2024, 1, 1)   # train: before 2024\nVALIDATE_END = date(2025, 9, 1)   # validate: 2024-Jan through 2025-Aug\n                                   # test: 2025-Sep onward\n\n# ── Kalshi date parsing ───────────────────────────────────────────────────\nMONTH_MAP = {m: i for i, m in enumerate(\n    [\"JAN\",\"FEB\",\"MAR\",\"APR\",\"MAY\",\"JUN\",\"JUL\",\"AUG\",\"SEP\",\"OCT\",\"NOV\",\"DEC\"], start=1)}\n\n# ── File paths ────────────────────────────────────────────────────────────\nPath(\"cache\").mkdir(exist_ok=True)\nCACHE_FILE    = Path(\"cache/response_cache.json\")\nMARKETS_CACHE = Path(\"cache/markets.parquet\")\nRESULTS_FILE  = Path(\"cache/results.parquet\")\n\nprint(\"Config loaded.\")\nprint(f\"Models:  {[MODELS[k]['name'] for k in MODELS]}\")\nprint(f\"Cities:  {list(CITY_SERIES.keys())}\")\nprint(f\"Splits:  train < 2024 | validate 2024–Aug-2025 | test Sep-2025+\")\nprint(f\"Cutoffs: {', '.join(f\\\"{MODELS[k]['name']}: {MODELS[k]['knowledge_cutoff'].strftime('%b %Y')}\\\" for k in MODELS)}\")\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Caching Helpers ───────────────────────────────────────────────────────\ndef load_cache():\n    if CACHE_FILE.exists():\n        return json.loads(CACHE_FILE.read_text(encoding=\"utf-8\"))\n    return {}\n\ndef save_cache(cache):\n    CACHE_FILE.write_text(json.dumps(cache, indent=2, ensure_ascii=False),\n                          encoding=\"utf-8\")\n\ndef ck(*args):\n    \"\"\"Stable 16-char cache key from arbitrary args.\"\"\"\n    return hashlib.sha256(\":\".join(str(a) for a in args).encode()).hexdigest()[:16]\n\nprint(\"Cache ready.\")\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Fetch Settled Kalshi Markets ──────────────────────────────────────────\n\ndef parse_event_date(event_ticker: str):\n    \"\"\"Parse event date from Kalshi event ticker (e.g. KXHIGHNY-26FEB21).\"\"\"\n    m = re.search(r\"-(\\d{2})([A-Z]{3})(\\d{2})$\", event_ticker)\n    if not m:\n        return None\n    yy, mon, dd = m.groups()\n    mo = MONTH_MAP.get(mon)\n    if not mo:\n        return None\n    try:\n        return date(2000 + int(yy), mo, int(dd))\n    except ValueError:\n        return None\n\n\ndef fetch_settled_series(series_ticker: str, max_pages: int = 80,\n                          delay: float = 0.15) -> list:\n    \"\"\"Page through all settled markets for a series.\"\"\"\n    markets, cursor = [], None\n    for _ in range(max_pages):\n        params = {\"series_ticker\": series_ticker,\n                  \"status\": \"settled\", \"limit\": 200}\n        if cursor:\n            params[\"cursor\"] = cursor\n        try:\n            r = requests.get(KALSHI_BASE + \"/markets\",\n                             headers=KALSHI_HEADERS, params=params, timeout=20)\n            r.raise_for_status()\n            data = r.json()\n        except Exception as e:\n            print(f\"    warn: {e}\")\n            break\n        batch = data.get(\"markets\", [])\n        if not batch:\n            break\n        markets.extend(batch)\n        cursor = data.get(\"cursor\")\n        if not cursor:\n            break\n        time.sleep(delay)\n    return markets\n\n\ndef market_to_row(m: dict, city: str, info: dict) -> dict | None:\n    \"\"\"Convert a raw Kalshi market dict to a flat row. Returns None to skip.\"\"\"\n    ev = m.get(\"event_ticker\", \"\")\n    event_date = parse_event_date(ev)\n    if event_date is None:\n        return None\n\n    floor = m.get(\"floor_strike\")\n    cap   = m.get(\"cap_strike\")\n    threshold = floor if floor is not None else cap\n    direction = m.get(\"strike_type\", \"greater\")   # \"greater\" or \"less\"\n\n    try:\n        actual_temp = float(m.get(\"expiration_value\") or \"nan\")\n    except (ValueError, TypeError):\n        actual_temp = np.nan\n\n    lp = m.get(\"last_price\")\n    kalshi_prob = float(lp) / 100.0 if lp is not None else np.nan\n\n    result  = m.get(\"result\", \"\").lower()\n    outcome = 1 if result == \"yes\" else (0 if result == \"no\" else np.nan)\n\n    return {\n        \"ticker\":        m.get(\"ticker\", \"\"),\n        \"event_ticker\":  ev,\n        \"series\":        info[\"series\"],\n        \"city\":          city,\n        \"lat\":           info[\"lat\"],\n        \"lon\":           info[\"lon\"],\n        \"event_date\":    event_date,\n        \"threshold_f\":   float(threshold) if threshold is not None else np.nan,\n        \"direction\":     direction,\n        \"title\":         m.get(\"title\", \"\"),\n        \"rules_primary\": m.get(\"rules_primary\", \"\"),\n        \"result\":        result,\n        \"outcome\":       outcome,\n        \"actual_temp_f\": actual_temp,\n        \"kalshi_prob\":   kalshi_prob,\n        \"volume\":        int(m.get(\"volume\", 0) or 0),\n        \"open_time\":     m.get(\"open_time\", \"\"),\n        \"close_time\":    m.get(\"close_time\", \"\"),\n    }\n\n\ndef build_markets_df() -> pd.DataFrame:\n    rows = []\n    for city, info in CITY_SERIES.items():\n        print(f\"  {info['series']:12s} ({city})...\", end=\" \", flush=True)\n        raw = fetch_settled_series(info[\"series\"])\n        print(f\"{len(raw):,}\")\n        for m in raw:\n            row = market_to_row(m, city, info)\n            if row:\n                rows.append(row)\n\n    df = pd.DataFrame(rows)\n    df[\"event_date\"] = pd.to_datetime(df[\"event_date\"])\n    df = df.drop_duplicates(subset=\"ticker\")\n    df = df.sort_values([\"city\", \"event_date\", \"threshold_f\"]).reset_index(drop=True)\n    return df\n\n\ndef assign_split(event_date) -> str:\n    d = pd.Timestamp(event_date).date()\n    if d < TRAIN_END:\n        return \"train\"\n    if d < VALIDATE_END:\n        return \"validate\"\n    return \"test\"\n\n\n# ── Load or fetch ─────────────────────────────────────────────────────────\nif MARKETS_CACHE.exists():\n    print(\"Loading markets from parquet cache...\")\n    markets_df = pd.read_parquet(MARKETS_CACHE)\n    print(f\"  {len(markets_df):,} markets loaded from {MARKETS_CACHE}\")\nelse:\n    print(\"Fetching all settled markets from Kalshi (~2 min)...\")\n    markets_df = build_markets_df()\n    markets_df.to_parquet(MARKETS_CACHE, index=False)\n    print(f\"\\nCached {len(markets_df):,} markets → {MARKETS_CACHE}\")\n\nmarkets_df[\"split\"] = markets_df[\"event_date\"].apply(assign_split)\n\nprint(f\"\\nDate range: {markets_df['event_date'].min().date()} \"\n      f\"→ {markets_df['event_date'].max().date()}\")\nprint(\"\\nMarket counts by city × split:\")\nprint(markets_df.groupby([\"city\",\"split\"]).size().unstack(fill_value=0).to_string())\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 1: Market Data Overview\n\nLoads all settled Kalshi high-temperature markets across 6 US cities, assigns\ntrain / validate / test splits by event date, and computes the Kalshi market\nBrier score as a baseline. Then draws a stratified sample (up to 50 markets per\nsplit, highest-volume per city × month) for LLM evaluation."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Descriptive Statistics ────────────────────────────────────────────────\nprint(f\"Total settled markets : {len(markets_df):,}\")\nprint(f\"With actual_temp_f    : {markets_df['actual_temp_f'].notna().sum():,}\")\nprint(f\"With kalshi_prob      : {markets_df['kalshi_prob'].notna().sum():,}\")\nprint(f\"Direction breakdown   : {markets_df['direction'].value_counts().to_dict()}\")\n\nvalid = markets_df.dropna(subset=[\"kalshi_prob\",\"outcome\"])\nprint(f\"\\nKalshi market Brier (full dataset, N={len(valid):,}):\")\nprint(f\"  Overall : {((valid['kalshi_prob'] - valid['outcome'])**2).mean():.4f}\")\nfor split, g in valid.groupby(\"split\"):\n    bs = ((g[\"kalshi_prob\"] - g[\"outcome\"])**2).mean()\n    n  = len(g)\n    print(f\"  {split:10s}: {bs:.4f}  (N={n:,})\")\n\nprint(\"\\nOutcome base rates:\")\nfor direction, g in valid.groupby(\"direction\"):\n    print(f\"  {direction}: YES rate = {g['outcome'].mean():.3f}  (N={len(g):,})\")\n\nprint(\"\\nActual temperature sample (first 6):\")\nprint(valid[[\"ticker\",\"city\",\"event_date\",\"threshold_f\",\"direction\",\n             \"actual_temp_f\",\"result\",\"kalshi_prob\"]].head(6).to_string(index=False))\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Stratified Sample for AI Evaluation ──────────────────────────────────\n# Per city × calendar-month: take the highest-volume market.\n# Then cap each split at TARGET_PER_SPLIT to limit LLM API cost.\n# Total ≈ 3 × TARGET_PER_SPLIT rows → 3 × 3 × TARGET_PER_SPLIT AI calls.\n\nTARGET_PER_SPLIT = 50   # markets per split (train / validate / test)\n\neligible = markets_df.dropna(\n    subset=[\"kalshi_prob\",\"outcome\",\"actual_temp_f\",\"rules_primary\"]\n).copy()\n# Must have real resolution rules (not empty / placeholder)\neligible = eligible[eligible[\"rules_primary\"].str.len() > 30]\neligible[\"ym\"] = eligible[\"event_date\"].dt.to_period(\"M\")\n\nparts = []\nfor split in [\"train\", \"validate\", \"test\"]:\n    sp = eligible[eligible[\"split\"] == split]\n    # Best (highest-volume) market per city × month\n    best = (sp.sort_values(\"volume\", ascending=False)\n              .groupby([\"city\",\"ym\"], as_index=False)\n              .first())\n    if len(best) > TARGET_PER_SPLIT:\n        # Prefer recency: keep most-recent months\n        best = best.nlargest(TARGET_PER_SPLIT, \"event_date\")\n    parts.append(best)\n\nsample_df = (pd.concat(parts, ignore_index=True)\n               .sort_values([\"city\",\"event_date\"])\n               .reset_index(drop=True))\n\nprint(f\"Sample: {len(sample_df)} markets  \"\n      f\"(→ {len(sample_df) * len(MODELS) * 2:,} AI calls total, all cached after first run)\")\nprint()\nprint(sample_df.groupby([\"city\",\"split\"]).size().unstack(fill_value=0).to_string())\nprint()\nprint(\"Example rows:\")\ncols = [\"ticker\",\"city\",\"event_date\",\"threshold_f\",\"direction\",\n        \"title\",\"result\",\"actual_temp_f\",\"kalshi_prob\",\"split\"]\nprint(sample_df[cols].head(6).to_string(index=False))\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 2: LLM Forecasting\n\nEach sampled market is evaluated by three frontier LLMs at two snapshot dates:\n\n- **T-7 (vanilla)**: prompt date is 7 days before resolution; no tools. The model\n  relies entirely on its training knowledge of climatological patterns — making\n  knowledge cutoff the key variable.\n- **T-1 (tool-augmented)**: prompt date is 1 day before resolution; the model can\n  call `get_recent_weather` to fetch the last 10 days of observed highs, giving\n  it live situational awareness that partially offsets any cutoff disadvantage.\n\nThe exact **Kalshi market title** and **resolution criteria** (`rules_primary`) are\nfed verbatim into every prompt — no paraphrasing. This means:\n\n1. The AI sees the same question the market participants traded on.\n2. Any ambiguity in the market language affects AI and market equally.\n3. Results generalise to any Kalshi binary market, not just weather."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Prompts & Model Factory ───────────────────────────────────────────────\nSYSTEM_PROMPT = (\n    \"You are an expert weather forecaster and superforecaster specialising in \"\n    \"prediction market calibration. Your sole task is to estimate the probability \"\n    \"that a specific Kalshi binary weather market resolves YES.\\n\\n\"\n    \"Guidelines:\\n\"\n    \"- Ground your estimate in historical base rates for the city and month.\\n\"\n    \"- Consider the specific threshold relative to seasonal climatology.\\n\"\n    \"- Be well-calibrated: 70% probability should resolve YES ~70% of the time.\\n\"\n    \"- Avoid round-number anchoring (0.25, 0.50, 0.75) unless clearly justified.\\n\\n\"\n    \"End your response with EXACTLY one line:\\n\"\n    \"PROBABILITY: X.XX\\n\"\n    \"where X.XX is a decimal in [0.00, 1.00].\"\n)\n\nUSER_T7 = (\n    \"Today is {forecast_date} — the market resolves in 7 days.\\n\\n\"\n    \"Market title: {title}\\n\\n\"\n    \"Resolution criteria: {rules_primary}\\n\\n\"\n    \"Using historical climatological patterns for {city} in {month_name}, \"\n    \"estimate the probability this market resolves YES. \"\n    \"Think step by step, then state your probability.\"\n)\n\nUSER_T1 = (\n    \"Today is {forecast_date} — the market resolves tomorrow.\\n\\n\"\n    \"Market title: {title}\\n\\n\"\n    \"Resolution criteria: {rules_primary}\\n\\n\"\n    \"Call get_recent_weather for {city} to check current conditions, \"\n    \"then estimate the probability this market resolves YES. \"\n    \"Think step by step, then state your probability.\"\n)\n\n\ndef parse_prob(text: str) -> float:\n    text = str(text)\n    m = re.search(r\"PROBABILITY:\\s*(0\\.\\d+|1\\.0+|0\\.0+)\", text)\n    if m:\n        return float(m.group(1))\n    hits = re.findall(r\"\\b(0\\.\\d+|1\\.0)\\b\", text[-500:])\n    return float(hits[-1]) if hits else np.nan\n\n\ndef get_llm(model_key: str):\n    cfg = MODELS[model_key]\n    if cfg[\"provider\"] == \"openai\":\n        return ChatOpenAI(model=cfg[\"model_id\"], temperature=0,\n                          api_key=OPENAI_API_KEY)\n    if cfg[\"provider\"] == \"google\":\n        return ChatGoogleGenerativeAI(model=cfg[\"model_id\"], temperature=0,\n                                      google_api_key=GOOGLE_API_KEY)\n    if cfg[\"provider\"] == \"anthropic\":\n        return ChatAnthropic(model=cfg[\"model_id\"], temperature=0,\n                             api_key=ANTHROPIC_API_KEY)\n    raise ValueError(f\"Unknown provider: {cfg['provider']}\")\n\n\n@tool\ndef get_recent_weather(city: str, days_back: int = 10) -> str:\n    \"\"\"Fetch recent daily maximum temperatures (degF) for a US city from Open-Meteo.\n\n    Args:\n        city: One of: New York City, Chicago, Miami, Los Angeles, Denver, Seattle.\n        days_back: How many past days to return (default 10).\n\n    Returns:\n        Daily high temperatures as a text table.\n    \"\"\"\n    info = None\n    city_lower = city.lower().strip()\n    for k, v in CITY_SERIES.items():\n        if city_lower in k.lower() or k.lower() in city_lower:\n            info = v\n            break\n    if info is None:\n        return f\"City not recognised. Available: {list(CITY_SERIES.keys())}\"\n\n    end   = datetime.now()\n    start = end - timedelta(days=max(days_back, 1))\n    params = {\n        \"latitude\":          info[\"lat\"],\n        \"longitude\":         info[\"lon\"],\n        \"start_date\":        start.strftime(\"%Y-%m-%d\"),\n        \"end_date\":          end.strftime(\"%Y-%m-%d\"),\n        \"daily\":             \"temperature_2m_max\",\n        \"temperature_unit\":  \"fahrenheit\",\n        \"timezone\":          \"auto\",\n    }\n    for url in [OPEN_METEO_ARCHIVE, OPEN_METEO_FORECAST]:\n        try:\n            r = requests.get(url, params=params, timeout=12)\n            if r.ok:\n                data  = r.json()\n                times = data[\"daily\"][\"time\"]\n                temps = data[\"daily\"][\"temperature_2m_max\"]\n                lines = [f\"Recent daily highs for {city} (degF):\"]\n                for t, temp in zip(times, temps):\n                    if temp is not None:\n                        lines.append(f\"  {t}: {float(temp):.1f}\")\n                return \"\\n\".join(lines)\n        except Exception:\n            continue\n    return f\"Could not fetch weather data for {city}.\"\n\n\nTOOLS    = [get_recent_weather]\nTOOL_MAP = {t.name: t for t in TOOLS}\n\nprint(f\"Setup complete. Tools: {[t.name for t in TOOLS]}\")\nprint(f\"Models: {[MODELS[k]['name'] for k in MODELS]}\")\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── T-7 Vanilla Forecasting (parallel, no tools, pure climatological priors) ──\nimport threading\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\nCACHE_LOCK  = threading.Lock()\nT7_WORKERS  = 10   # parallel LLM calls — lower if you hit rate limits\nSAVE_EVERY  = 10   # flush cache to disk every N new completions\n\n\ndef run_t7(df: pd.DataFrame, cache: dict) -> pd.DataFrame:\n    # Create one LLM client per model; LangChain clients are thread-safe.\n    llm_pool = {mk: get_llm(mk) for mk in MODELS}\n    tasks    = [(mk, row) for mk in MODELS for _, row in df.iterrows()]\n    new_count = [0]   # mutable so the closure can update it\n\n    def forecast_one(args):\n        model_key, row = args\n        cfg = MODELS[model_key]\n        key = ck(\"t7\", model_key, row[\"ticker\"])\n\n        with CACHE_LOCK:\n            if key in cache:\n                output = cache[key][\"output\"]\n                return {\"ticker\":      row[\"ticker\"],\n                        \"model\":       cfg[\"name\"],\n                        \"model_key\":   model_key,\n                        \"snapshot\":    \"T-7\",\n                        \"method\":      \"vanilla\",\n                        \"probability\": parse_prob(output),\n                        \"raw_output\":  str(output)[-400:]}, None\n\n        fd  = (pd.Timestamp(row[\"event_date\"]) - timedelta(days=7)).strftime(\"%Y-%m-%d\")\n        mon = pd.Timestamp(row[\"event_date\"]).strftime(\"%B\")\n        msgs = [\n            SystemMessage(content=SYSTEM_PROMPT),\n            HumanMessage(content=USER_T7.format(\n                forecast_date=fd,\n                title=row[\"title\"],\n                rules_primary=row[\"rules_primary\"],\n                city=row[\"city\"],\n                month_name=mon,\n            )),\n        ]\n        try:\n            output = llm_pool[model_key].invoke(msgs).content\n        except Exception as e:\n            output = f\"ERROR: {e}\"\n\n        return {\"ticker\":      row[\"ticker\"],\n                \"model\":       cfg[\"name\"],\n                \"model_key\":   model_key,\n                \"snapshot\":    \"T-7\",\n                \"method\":      \"vanilla\",\n                \"probability\": parse_prob(output),\n                \"raw_output\":  str(output)[-400:]}, (key, output)\n\n    results = []\n    with ThreadPoolExecutor(max_workers=T7_WORKERS) as executor:\n        futures = {executor.submit(forecast_one, t): t for t in tasks}\n        for future in tqdm(as_completed(futures), total=len(futures), desc=\"T-7 forecasts\"):\n            result, update = future.result()\n            results.append(result)\n            if update:\n                key, output = update\n                with CACHE_LOCK:\n                    cache[key] = {\"output\": output}\n                    new_count[0] += 1\n                    if new_count[0] % SAVE_EVERY == 0:\n                        save_cache(cache)\n\n    save_cache(cache)   # final flush\n\n    t7_results = pd.DataFrame(results)\n    valid_t7   = t7_results.dropna(subset=[\"probability\"])\n    print(f\"\\nT-7 forecasts: {len(t7_results)} | Parse success: {len(valid_t7)}/{len(t7_results)}\")\n    print(t7_results.groupby(\"model\")[\"probability\"].describe().round(3))\n    return t7_results\n\n\ncache      = load_cache()\nt7_results = run_t7(sample_df, cache)\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── T-1 Tool-Augmented Forecasting (parallel) ────────────────────────────\nT1_WORKERS = 10   # parallel LLM calls — lower if you hit rate limits\n\n\ndef run_t1(df: pd.DataFrame, cache: dict) -> pd.DataFrame:\n    llm_pool            = {mk: get_llm(mk) for mk in MODELS}\n    llm_with_tools_pool = {mk: llm_pool[mk].bind_tools(TOOLS) for mk in MODELS}\n    tasks    = [(mk, row) for mk in MODELS for _, row in df.iterrows()]\n    new_count = [0]\n\n    def forecast_one(args):\n        model_key, row = args\n        cfg = MODELS[model_key]\n        key = ck(\"t1\", model_key, row[\"ticker\"])\n\n        with CACHE_LOCK:\n            if key in cache:\n                output = cache[key][\"output\"]\n                return {\"ticker\":      row[\"ticker\"],\n                        \"model\":       cfg[\"name\"],\n                        \"model_key\":   model_key,\n                        \"snapshot\":    \"T-1\",\n                        \"method\":      \"tool_augmented\",\n                        \"probability\": parse_prob(output),\n                        \"raw_output\":  str(output)[-400:]}, None\n\n        fd   = (pd.Timestamp(row[\"event_date\"]) - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n        msgs = [\n            SystemMessage(content=SYSTEM_PROMPT),\n            HumanMessage(content=USER_T1.format(\n                forecast_date=fd,\n                title=row[\"title\"],\n                rules_primary=row[\"rules_primary\"],\n                city=row[\"city\"],\n            )),\n        ]\n        output = \"ERROR: max_iterations\"\n        for _ in range(6):\n            try:\n                resp = llm_with_tools_pool[model_key].invoke(msgs)\n            except Exception as e:\n                output = f\"ERROR: {e}\"\n                break\n            msgs.append(resp)\n            if resp.tool_calls:\n                for tc in resp.tool_calls:\n                    fn = TOOL_MAP.get(tc[\"name\"])\n                    if fn:\n                        tool_out = fn.invoke(tc[\"args\"])\n                        msgs.append(ToolMessage(\n                            content=str(tool_out),\n                            tool_call_id=tc[\"id\"],\n                        ))\n            else:\n                output = resp.content\n                break\n\n        return {\"ticker\":      row[\"ticker\"],\n                \"model\":       cfg[\"name\"],\n                \"model_key\":   model_key,\n                \"snapshot\":    \"T-1\",\n                \"method\":      \"tool_augmented\",\n                \"probability\": parse_prob(output),\n                \"raw_output\":  str(output)[-400:]}, (key, output)\n\n    results = []\n    with ThreadPoolExecutor(max_workers=T1_WORKERS) as executor:\n        futures = {executor.submit(forecast_one, t): t for t in tasks}\n        for future in tqdm(as_completed(futures), total=len(futures), desc=\"T-1 forecasts\"):\n            result, update = future.result()\n            results.append(result)\n            if update:\n                key, output = update\n                with CACHE_LOCK:\n                    cache[key] = {\"output\": output}\n                    new_count[0] += 1\n                    if new_count[0] % SAVE_EVERY == 0:\n                        save_cache(cache)\n\n    save_cache(cache)   # final flush\n\n    t1_results = pd.DataFrame(results)\n    valid_t1   = t1_results.dropna(subset=[\"probability\"])\n    print(f\"\\nT-1 forecasts: {len(t1_results)} | Parse success: {len(valid_t1)}/{len(t1_results)}\")\n    print(t1_results.groupby(\"model\")[\"probability\"].describe().round(3))\n    return t1_results\n\n\nt1_results = run_t1(sample_df, cache)\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Assemble Master Results DataFrame ────────────────────────────────────\nMETA_COLS = [\n    \"ticker\",\"event_ticker\",\"city\",\"event_date\",\"threshold_f\",\"direction\",\n    \"title\",\"result\",\"outcome\",\"actual_temp_f\",\"kalshi_prob\",\"volume\",\"split\",\n]\n\nall_ai     = pd.concat([t7_results, t1_results], ignore_index=True)\nresults_df = all_ai.merge(sample_df[META_COLS], on=\"ticker\", how=\"left\")\n\nresults_df[\"brier\"] = np.where(\n    results_df[[\"probability\",\"outcome\"]].notna().all(axis=1),\n    (results_df[\"probability\"] - results_df[\"outcome\"]) ** 2,\n    np.nan,\n)\n\n# ── Add per-model post-cutoff flag ────────────────────────────────────────\n# post_cutoff=True means event_date >= that model's knowledge_cutoff,\n# i.e. the model had no training data from this time period.\ncutoff_map = {cfg[\"name\"]: cfg[\"knowledge_cutoff\"] for cfg in MODELS.values()}\nresults_df[\"post_cutoff\"] = results_df.apply(\n    lambda row: (pd.Timestamp(row[\"event_date\"]).date() >= cutoff_map[row[\"model\"]])\n    if row[\"model\"] in cutoff_map else False,\n    axis=1,\n)\n\n# ── Add Kalshi market as its own forecaster row ───────────────────────────\n# Kalshi final price is used as the market baseline at both snapshots.\nkalshi_rows = []\nfor _, row in sample_df.dropna(subset=[\"kalshi_prob\",\"outcome\"]).iterrows():\n    for snap in [\"T-7\", \"T-1\"]:\n        kalshi_rows.append({\n            **{c: row[c] for c in META_COLS},\n            \"model\":        \"Kalshi Market\",\n            \"model_key\":    \"kalshi\",\n            \"snapshot\":     snap,\n            \"method\":       \"prediction_market\",\n            \"probability\":  row[\"kalshi_prob\"],\n            \"raw_output\":   \"\",\n            \"brier\":        (row[\"kalshi_prob\"] - row[\"outcome\"]) ** 2,\n            \"post_cutoff\":  False,\n        })\n\nresults_df = pd.concat([results_df, pd.DataFrame(kalshi_rows)], ignore_index=True)\n\n# ── Persist ───────────────────────────────────────────────────────────────\nresults_df.to_parquet(RESULTS_FILE, index=False)\n(results_df.drop(columns=[\"raw_output\"], errors=\"ignore\")\n           .to_csv(\"cache/results.csv\", index=False))\n\nprint(f\"Saved: {RESULTS_FILE}  ({len(results_df):,} rows)\")\nprint(f\"       cache/results.csv\")\nprint(f\"\\nColumns: {list(results_df.columns)}\")\nprint(f\"\\nForecasters: {sorted(results_df['model'].unique())}\")\n\nprint(f\"\\nPost-cutoff market counts per AI model (T-7 snapshot):\")\nt7_ai = results_df[(results_df[\"snapshot\"] == \"T-7\") & (results_df[\"model\"] != \"Kalshi Market\")]\nprint(t7_ai.groupby(\"model\")[\"post_cutoff\"].value_counts().unstack(fill_value=0).to_string())\n\nprint()\nprint(results_df[[\"ticker\",\"city\",\"event_date\",\"snapshot\",\"model\",\n                  \"probability\",\"kalshi_prob\",\"outcome\",\"brier\",\"split\",\"post_cutoff\"]\n                ].head(12).to_string(index=False))\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 3: Brier Score Analysis\n\nFive views of forecast quality (lower Brier = better; always-0.5 baseline = 0.25):\n\n1. **Overall** — mean Brier by model × snapshot across all splits.\n2. **By split** — train / validate / test breakdown revealing chronological degradation.\n3. **By city** — geographic variation in forecast difficulty.\n4. **Generalisation gap** — test minus validate Brier; the primary out-of-distribution metric.\n5. **Knowledge cutoff effect** — for T-7 vanilla forecasts, pre-cutoff vs post-cutoff\n   Brier per model using each model's own training-data boundary (`post_cutoff` flag)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Brier Score Analysis ──────────────────────────────────────────────────\nscored = results_df.dropna(subset=[\"brier\"]).copy()\nprint(f\"Scored rows: {len(scored):,}  (of {len(results_df):,} total)\")\n\nSEP = \"=\" * 72\n\n# ── Overall ───────────────────────────────────────────────────────────────\nprint(f\"\\n{SEP}\")\nprint(\"OVERALL BRIER SCORES  (lower = better | baseline always-0.5 = 0.2500)\")\nprint(SEP)\noverall = (\n    scored.groupby([\"snapshot\",\"model\"])[\"brier\"]\n    .agg([\"mean\",\"std\",\"count\"])\n    .rename(columns={\"mean\":\"Mean Brier\",\"std\":\"Std\",\"count\":\"N\"})\n    .round(4)\n    .sort_values([\"snapshot\",\"Mean Brier\"])\n)\nprint(overall.to_string())\n\n# ── By split ──────────────────────────────────────────────────────────────\nprint(f\"\\n{SEP}\")\nprint(\"BRIER BY DATA SPLIT\")\nprint(SEP)\nby_split = (\n    scored.groupby([\"split\",\"snapshot\",\"model\"])[\"brier\"]\n    .agg([\"mean\",\"count\"])\n    .rename(columns={\"mean\":\"Mean Brier\",\"count\":\"N\"})\n    .round(4)\n    .sort_index()\n)\nprint(by_split.to_string())\n\n# ── By city ───────────────────────────────────────────────────────────────\nprint(f\"\\n{SEP}\")\nprint(\"MEAN BRIER BY CITY (all snapshots)\")\nprint(SEP)\nprint(\n    scored.groupby([\"city\",\"model\"])[\"brier\"]\n    .mean().round(4).unstack().to_string()\n)\n\n# ── Generalisation gap ────────────────────────────────────────────────────\nprint(f\"\\n{SEP}\")\nprint(\"GENERALISATION GAP  (test Brier − validate Brier)\")\nprint(SEP)\nfor (snap, model), grp in scored.groupby([\"snapshot\",\"model\"]):\n    val = grp.loc[grp[\"split\"] == \"validate\", \"brier\"].mean()\n    tst = grp.loc[grp[\"split\"] == \"test\",     \"brier\"].mean()\n    if pd.notna(val) and pd.notna(tst):\n        print(f\"  {model:25s} @ {snap}: \"\n              f\"validate={val:.4f}  test={tst:.4f}  gap={tst-val:+.4f}\")\n\n# ── Knowledge cutoff effect (T-7 vanilla, per-model) ─────────────────────\nprint(f\"\\n{SEP}\")\nprint(\"KNOWLEDGE CUTOFF EFFECT  (T-7 vanilla — pre-cutoff vs post-cutoff per model)\")\nprint(SEP)\nt7_ai = scored[(scored[\"snapshot\"] == \"T-7\") & (scored[\"model\"] != \"Kalshi Market\")]\nfor model, grp in t7_ai.groupby(\"model\"):\n    cutoff = cutoff_map.get(model, \"N/A\")\n    pre    = grp.loc[~grp[\"post_cutoff\"], \"brier\"]\n    post   = grp.loc[ grp[\"post_cutoff\"], \"brier\"]\n    print(f\"  {model}  (cutoff: {cutoff})\")\n    if len(pre):\n        print(f\"    pre-cutoff  N={len(pre):3d}  Brier={pre.mean():.4f}\")\n    if len(post):\n        gap = post.mean() - pre.mean() if len(pre) else float(\"nan\")\n        print(f\"    post-cutoff N={len(post):3d}  Brier={post.mean():.4f}  \"\n              f\"gap={gap:+.4f}\")\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 4: Visualisations\n\nFour panels saved to `cache/results_plots.png`:\n\n1. **Mean Brier by model × snapshot** — bar chart comparing T-7 and T-1 performance against the no-skill baseline.\n2. **Brier by split** — grouped bar chart showing train / validate / test degradation (generalisation gap) per model.\n3. **AI @ T-1 vs Kalshi** — scatter of AI probabilities against Kalshi final prices; alignment indicates agreement with crowd wisdom.\n4. **Calibration curves** — observed YES rate vs predicted probability; a well-calibrated forecaster tracks the diagonal."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Plots ─────────────────────────────────────────────────────────────────\nfig, axs = plt.subplots(2, 2, figsize=(16, 12))\nfig.suptitle(\"Forecasting Showdown: Kalshi Weather Markets vs LLMs\", fontsize=14)\n\n# ── 1. Mean Brier by model × snapshot ────────────────────────────────────\nax = axs[0, 0]\npiv = (scored.groupby([\"model\",\"snapshot\"])[\"brier\"]\n       .mean().unstack().round(4))\npiv.plot(kind=\"bar\", ax=ax, rot=30, width=0.65)\nax.axhline(0.25, color=\"red\", ls=\"--\", alpha=0.6, label=\"No-skill (0.25)\")\nax.set_title(\"Mean Brier: Model × Snapshot\")\nax.set_ylabel(\"Mean Brier Score\")\nax.set_xlabel(\"\")\nax.legend(fontsize=8)\n\n# ── 2. Generalisation gap (split × model) ────────────────────────────────\nax = axs[0, 1]\ngap_data = (scored[scored[\"model\"] != \"Kalshi Market\"]\n            .groupby([\"split\",\"model\"])[\"brier\"]\n            .mean().reset_index())\nsns.barplot(data=gap_data, x=\"split\", y=\"brier\", hue=\"model\",\n            order=[\"train\",\"validate\",\"test\"], ax=ax)\nax.axhline(0.25, color=\"red\", ls=\"--\", alpha=0.6)\nax.set_title(\"Brier by Split — Generalisation Gap\")\nax.set_ylabel(\"Mean Brier Score\")\nax.set_xlabel(\"\")\nax.legend(fontsize=7)\n\n# ── 3. AI T-1 prob vs Kalshi final price ─────────────────────────────────\nax = axs[1, 0]\nmarkers = {\"GPT-4o\": \"o\", \"Gemini 2.5 Flash\": \"s\", \"Claude Sonnet 4.6\": \"^\"}\nfor model_key, cfg in MODELS.items():\n    sub = scored[(scored[\"model\"] == cfg[\"name\"]) & (scored[\"snapshot\"] == \"T-1\")]\n    if len(sub):\n        mk = markers.get(cfg[\"name\"], \"o\")\n        ax.scatter(sub[\"kalshi_prob\"], sub[\"probability\"],\n                   label=cfg[\"name\"], alpha=0.4, s=22, marker=mk)\nax.plot([0, 1], [0, 1], \"k--\", lw=1, label=\"Perfect agreement\")\nax.set_xlabel(\"Kalshi Final Price\")\nax.set_ylabel(\"AI Probability @ T-1\")\nax.set_title(\"AI @ T-1  vs  Kalshi Market Consensus\")\nax.legend(fontsize=7)\n\n# ── 4. Calibration curves ─────────────────────────────────────────────────\nax = axs[1, 1]\nbins = np.linspace(0, 1, 11)\n\ndef calibration_curve(sub):\n    means, freqs = [], []\n    for i in range(len(bins) - 1):\n        mask = (sub[\"probability\"] >= bins[i]) & (sub[\"probability\"] < bins[i+1])\n        if mask.sum() >= 3:\n            means.append(sub.loc[mask, \"probability\"].mean())\n            freqs.append(sub.loc[mask, \"outcome\"].mean())\n    return means, freqs\n\nfor model_key, cfg in MODELS.items():\n    for snap, ls in [(\"T-7\", \"--\"), (\"T-1\", \"-\")]:\n        sub = scored[(scored[\"model\"] == cfg[\"name\"]) &\n                     (scored[\"snapshot\"] == snap)].dropna(subset=[\"outcome\"])\n        if len(sub) < 10:\n            continue\n        mx, fy = calibration_curve(sub)\n        if mx:\n            ax.plot(mx, fy, marker=\"o\", ls=ls, ms=4,\n                    label=f\"{cfg['name']} ({snap})\")\n\n# Kalshi calibration\nksub = scored[(scored[\"model\"] == \"Kalshi Market\") &\n              (scored[\"snapshot\"] == \"T-1\")].dropna(subset=[\"outcome\"])\nif len(ksub) >= 10:\n    km, kf = calibration_curve(ksub)\n    if km:\n        ax.plot(km, kf, marker=\"s\", lw=2, color=\"black\", label=\"Kalshi Market\")\n\nax.plot([0, 1], [0, 1], \"k--\", lw=1, alpha=0.35)\nax.set_xlabel(\"Predicted Probability\")\nax.set_ylabel(\"Observed Frequency\")\nax.set_title(\"Calibration  (solid=T-1, dashed=T-7)\")\nax.legend(fontsize=6, ncol=2)\n\nplt.tight_layout()\nplt.savefig(\"cache/results_plots.png\", dpi=150, bbox_inches=\"tight\")\nplt.show()\nprint(\"Saved: cache/results_plots.png\")\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 5: Summary\n\nFinal leaderboard ranking all forecasters by mean Brier score at each snapshot,\nbest forecaster per city at T-1, and instructions for reloading the persisted\nresults from `cache/results.parquet` or `cache/results.csv`."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Final Summary ─────────────────────────────────────────────────────────\nSEP = \"=\" * 72\nprint(SEP)\nprint(\"FORECASTING SHOWDOWN — FINAL LEADERBOARD\")\nprint(SEP)\nprint(f\"Markets: {sample_df['ticker'].nunique():,} | \"\n      f\"Cities: {sample_df['city'].nunique()} | \"\n      f\"Span: {sample_df['event_date'].min().date()} \"\n      f\"→ {sample_df['event_date'].max().date()}\")\nprint()\n\nleaderboard = (\n    scored.groupby([\"snapshot\",\"model\"])[\"brier\"]\n    .mean().round(4).reset_index()\n    .rename(columns={\"brier\":\"Mean Brier\"})\n    .sort_values([\"snapshot\",\"Mean Brier\"])\n)\nprint(leaderboard.to_string(index=False))\nprint()\nprint(f\"  Baseline (always 0.50):  0.2500\")\nprint(f\"  Perfect forecaster:      0.0000\")\n\nprint(f\"\\n{SEP}\")\nprint(\"BEST FORECASTER PER CITY  (T-1 snapshot)\")\nprint(SEP)\nt1 = scored[scored[\"snapshot\"] == \"T-1\"]\nfor city, g in t1.groupby(\"city\"):\n    best = g.groupby(\"model\")[\"brier\"].mean().idxmin()\n    bs   = g.groupby(\"model\")[\"brier\"].mean().min()\n    print(f\"  {city:15s}  {best:25s}  Brier={bs:.4f}\")\n\nprint(f\"\\n{SEP}\")\nprint(\"HOW TO RELOAD RESULTS\")\nprint(SEP)\nprint(\"  import pandas as pd\")\nprint(\"  results_df = pd.read_parquet('cache/results.parquet')\")\nprint(\"  # or:  pd.read_csv('cache/results.csv')\")\nprint()\nprint(\"Key columns: ticker, city, event_date, threshold_f, direction,\")\nprint(\"             actual_temp_f, kalshi_prob, outcome, result,\")\nprint(\"             snapshot, model, method, probability, brier, split, post_cutoff\")\nprint()\nprint(\"post_cutoff: True when event_date >= that model's knowledge cutoff date.\")\nprint(\"             Always False for Kalshi Market rows (no training cutoff).\")\n"
  }
 ]
}