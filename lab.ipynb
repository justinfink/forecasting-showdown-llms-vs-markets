{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting Showdown: Prediction Markets vs. Frontier LLMs\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This project compares forecasting accuracy across three categories of forecasters:\n",
    "\n",
    "1. **Prediction Markets** (Polymarket + Kalshi) \u00e2\u20ac\u201d real-money markets where participants trade on event outcomes\n",
    "2. **Frontier LLMs \u00e2\u20ac\u201d Vanilla** (GPT-5, Gemini, Claude) \u00e2\u20ac\u201d prompted with only the question, relying on training data\n",
    "3. **Frontier LLMs \u00e2\u20ac\u201d Tool-Augmented** (same models with real-time data tools) \u00e2\u20ac\u201d given access to FRED and EIA APIs\n",
    "\n",
    "### Metrics\n",
    "\n",
    "**Brier Score** measures calibration \u00e2\u20ac\u201d how well probability estimates match actual outcomes:\n",
    "\n",
    "$$BS = \\frac{1}{N} \\sum_{i=1}^{N} (p_i - o_i)^2$$\n",
    "\n",
    "- $p_i$ = predicted probability, $o_i$ = outcome (0 or 1)\n",
    "- Lower is better: 0 = perfect, 0.25 = no skill (always predicting 50%), 1 = worst\n",
    "\n",
    "**Hypothetical Returns** test profitability via a threshold-based betting strategy against prediction market prices.\n",
    "\n",
    "### Domains\n",
    "- **Federal Funds Rate**: Will the Fed cut rates at upcoming FOMC meetings?\n",
    "- **Gas Prices**: Will US national average gasoline prices exceed/fall below specific thresholds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Environment Setup\n# Loads API keys from a .env file (local) or Colab Secrets (Google Colab).\nimport os\nimport sys\nfrom pathlib import Path\n\n# --- Google Colab Support ---\nif \"google.colab\" in sys.modules:\n    print(\"Running in Google Colab\")\n    print(\"Add your API keys to Colab Secrets (key icon in the left sidebar).\")\n    try:\n        from google.colab import userdata\n        for key in [\n            \"OPENAI_API_KEY\", \"GOOGLE_API_KEY\", \"GEMINI_API_KEY\",\n            \"ANTHROPIC_API_KEY\", \"FRED_API_KEY\", \"EIA_API_KEY\",\n        ]:\n            try:\n                os.environ[key] = userdata.get(key)\n            except Exception:\n                pass  # Key not set in Colab secrets -- that's ok\n    except ImportError:\n        pass\n\n# --- Local: load from .env file ---\nelse:\n    try:\n        from dotenv import load_dotenv\n        env_file = Path(\".env\")\n        if env_file.exists():\n            load_dotenv(env_file, override=True)\n            print(\"Loaded API keys from .env\")\n        else:\n            print(\"No .env file found -- using existing environment variables.\")\n            print(\"Copy .env.example to .env and fill in your keys.\")\n    except ImportError:\n        print(\"python-dotenv not installed -- run: pip install python-dotenv\")\n\n# --- Report key status ---\nKEYS = {\n    \"OPENAI_API_KEY\":    \"Required -- GPT models\",\n    \"GOOGLE_API_KEY\":    \"Required -- Gemini models\",\n    \"GEMINI_API_KEY\":    \"Required -- Gemini models (alias)\",\n    \"ANTHROPIC_API_KEY\": \"Required -- Claude models\",\n    \"FRED_API_KEY\":      \"Required -- Fed rate data  (free at fred.stlouisfed.org/docs/api/api_key.html)\",\n    \"EIA_API_KEY\":       \"Required -- Gas price data (free at eia.gov/opendata)\",\n}\nall_set = True\nfor key, desc in KEYS.items():\n    status = \"set\" if os.environ.get(key) else \"MISSING\"\n    if not os.environ.get(key):\n        all_set = False\n    print(f\"  {status}  {key}  ({desc})\")\n\nif not all_set:\n    print(\"\nSome keys are missing. See README.md for setup instructions.\")\nelse:\n    print(\"\nAll API keys loaded.\")"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded.\n",
      "FRED API key: MISSING\n",
      "EIA API key: MISSING\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import seaborn as sns\n",
    "from fredapi import Fred\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# --- Model Configuration ---\n",
    "MODELS = {\n",
    "    \"gemini\": {\n",
    "        \"name\": \"Gemini 2.5 Flash Lite\",\n",
    "        \"provider\": \"google\",\n",
    "        \"model_id\": \"gemini-2.5-flash-lite\",\n",
    "    },\n",
    "    \"gpt\": {\n",
    "        \"name\": \"GPT-5\",\n",
    "        \"provider\": \"openai\",\n",
    "        \"model_id\": \"gpt-5-2025-08-07\",\n",
    "    },\n",
    "    \"claude\": {\n",
    "        \"name\": \"Claude Sonnet 4.5\",\n",
    "        \"provider\": \"anthropic\",\n",
    "        \"model_id\": \"claude-sonnet-4-5-20250929\",\n",
    "    },\n",
    "}\n",
    "\n",
    "# --- API Keys ---\n",
    "FRED_API_KEY = os.environ.get(\"FRED_API_KEY\", \"\")\n",
    "EIA_API_KEY = os.environ.get(\"EIA_API_KEY\", \"\")\n",
    "\n",
    "# --- Prediction Market API Base URLs ---\n",
    "POLYMARKET_GAMMA_BASE = \"https://gamma-api.polymarket.com\"\n",
    "POLYMARKET_CLOB_BASE = \"https://clob.polymarket.com\"\n",
    "KALSHI_BASE = \"https://api.elections.kalshi.com/trade-api/v2\"\n",
    "\n",
    "# --- FRED Series IDs ---\n",
    "FRED_SERIES = {\n",
    "    \"fed_funds_rate\": \"DFF\",\n",
    "    \"fed_funds_target_upper\": \"DFEDTARU\",\n",
    "    \"fed_funds_target_lower\": \"DFEDTARL\",\n",
    "}\n",
    "\n",
    "# --- EIA Endpoint ---\n",
    "EIA_GAS_PRICE_URL = \"https://api.eia.gov/v2/petroleum/pri/gp/data/\"\n",
    "\n",
    "# --- 2026 FOMC Meeting Dates (announcement day) ---\n",
    "FOMC_DATES_2026 = [\n",
    "    {\"meeting\": \"January\",   \"date\": \"2026-01-28\"},\n",
    "    {\"meeting\": \"March\",     \"date\": \"2026-03-18\"},\n",
    "    {\"meeting\": \"April\",     \"date\": \"2026-04-29\"},\n",
    "    {\"meeting\": \"June\",      \"date\": \"2026-06-17\"},\n",
    "    {\"meeting\": \"July\",      \"date\": \"2026-07-29\"},\n",
    "    {\"meeting\": \"September\", \"date\": \"2026-09-16\"},\n",
    "    {\"meeting\": \"October\",   \"date\": \"2026-10-28\"},\n",
    "    {\"meeting\": \"December\",  \"date\": \"2026-12-09\"},\n",
    "]\n",
    "\n",
    "# Ensure cache directory exists\n",
    "Path(\"cache\").mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Configuration loaded.\")\n",
    "print(f\"FRED API key: {'set' if FRED_API_KEY else 'MISSING'}\")\n",
    "print(f\"EIA API key: {'set' if EIA_API_KEY else 'MISSING'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Caching Infrastructure ---\n",
    "# Same pattern as lab_02: JSON file-based cache to avoid redundant API calls\n",
    "\n",
    "CACHE_FILE = Path(\"cache/response_cache.json\")\n",
    "\n",
    "\n",
    "def load_cache():\n",
    "    if CACHE_FILE.exists():\n",
    "        return json.loads(CACHE_FILE.read_text())\n",
    "    return {}\n",
    "\n",
    "\n",
    "def save_cache(cache):\n",
    "    CACHE_FILE.write_text(json.dumps(cache, indent=2))\n",
    "\n",
    "\n",
    "def get_cache_key(prefix, *args):\n",
    "    key_str = f\"{prefix}:\" + \":\".join(str(a) for a in args)\n",
    "    return hashlib.sha256(key_str.encode()).hexdigest()[:16]\n",
    "\n",
    "\n",
    "def cached_call(cache, key, func, *args, **kwargs):\n",
    "    \"\"\"Execute func if key not in cache; otherwise return cached result.\"\"\"\n",
    "    if key in cache:\n",
    "        return cache[key]\n",
    "    result = func(*args, **kwargs)\n",
    "    cache[key] = result\n",
    "    save_cache(cache)\n",
    "    return result\n",
    "\n",
    "\n",
    "print(\"Caching infrastructure ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Data Collection\n",
    "\n",
    "We pull data from four external sources:\n",
    "\n",
    "| Source | What It Provides | API | Auth |\n",
    "|--------|-----------------|-----|------|\n",
    "| **FRED** (St. Louis Fed) | Federal funds rate (daily), target rate range | `fredapi` Python library | Free API key |\n",
    "| **EIA** (Energy Information Administration) | Weekly US retail gasoline prices | REST API v2 | Free API key |\n",
    "| **Polymarket** | Prediction market probabilities | Gamma + CLOB REST APIs | None |\n",
    "| **Kalshi** | Prediction market probabilities | REST API v2 | None (public data) |\n",
    "\n",
    "The FRED and EIA data serve two purposes:\n",
    "1. **Ground truth** for resolving our binary questions\n",
    "2. **Tool data** for the tool-augmented LLM category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1.1 FRED: Federal Funds Rate ---\n",
    "\n",
    "def fetch_fred_data():\n",
    "    \"\"\"Fetch federal funds rate data from FRED.\"\"\"\n",
    "    fred = Fred(api_key=FRED_API_KEY)\n",
    "\n",
    "    fed_funds = fred.get_series(\"DFF\", observation_start=\"2024-01-01\")\n",
    "    target_upper = fred.get_series(\"DFEDTARU\", observation_start=\"2024-01-01\")\n",
    "    target_lower = fred.get_series(\"DFEDTARL\", observation_start=\"2024-01-01\")\n",
    "\n",
    "    return {\n",
    "        \"fed_funds_rate\": fed_funds,\n",
    "        \"target_upper\": target_upper,\n",
    "        \"target_lower\": target_lower,\n",
    "    }\n",
    "\n",
    "\n",
    "fred_data = fetch_fred_data()\n",
    "print(f\"Fed funds rate: {len(fred_data['fed_funds_rate'])} observations\")\n",
    "print(f\"Latest effective rate: {fred_data['fed_funds_rate'].dropna().iloc[-1]:.2f}%\")\n",
    "print(\n",
    "    f\"Current target range: {fred_data['target_lower'].dropna().iloc[-1]:.2f}%\"\n",
    "    f\" - {fred_data['target_upper'].dropna().iloc[-1]:.2f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1.2 EIA: US Retail Gasoline Prices ---\n",
    "\n",
    "def fetch_eia_gas_prices(n_weeks=200):\n",
    "    \"\"\"Fetch weekly US regular gasoline retail prices from EIA API v2.\"\"\"\n",
    "    params = {\n",
    "        \"api_key\": EIA_API_KEY,\n",
    "        \"frequency\": \"weekly\",\n",
    "        \"data[0]\": \"value\",\n",
    "        \"facets[product][]\": \"EPMR\",   # Regular gasoline, all formulations\n",
    "        \"facets[duoarea][]\": \"NUS\",     # National US\n",
    "        \"sort[0][column]\": \"period\",\n",
    "        \"sort[0][direction]\": \"desc\",\n",
    "        \"offset\": 0,\n",
    "        \"length\": n_weeks,\n",
    "    }\n",
    "    response = requests.get(EIA_GAS_PRICE_URL, params=params)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "\n",
    "    records = data[\"response\"][\"data\"]\n",
    "    df = pd.DataFrame(records)\n",
    "    df[\"period\"] = pd.to_datetime(df[\"period\"])\n",
    "    df[\"value\"] = pd.to_numeric(df[\"value\"])\n",
    "    df = df.sort_values(\"period\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "gas_prices = fetch_eia_gas_prices()\n",
    "print(f\"Gas price data: {len(gas_prices)} weekly observations\")\n",
    "print(\n",
    "    f\"Latest: ${gas_prices['value'].iloc[-1]:.3f}/gal\"\n",
    "    f\" (week of {gas_prices['period'].iloc[-1].strftime('%Y-%m-%d')})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1.3 Polymarket ---\n",
    "\n",
    "def fetch_polymarket_events(search_term, limit=50):\n",
    "    \"\"\"Search Polymarket Gamma API for events matching a term.\"\"\"\n",
    "    url = f\"{POLYMARKET_GAMMA_BASE}/events\"\n",
    "    params = {\"closed\": \"false\", \"limit\": limit}\n",
    "    response = requests.get(url, params=params)\n",
    "    response.raise_for_status()\n",
    "    events = response.json()\n",
    "\n",
    "    relevant = []\n",
    "    for event in events:\n",
    "        title = event.get(\"title\", \"\").lower()\n",
    "        if search_term.lower() in title:\n",
    "            relevant.append(event)\n",
    "    return relevant\n",
    "\n",
    "\n",
    "def fetch_polymarket_price_history(token_id, interval=\"max\", fidelity=60):\n",
    "    \"\"\"Fetch price history for a Polymarket CLOB token.\"\"\"\n",
    "    url = f\"{POLYMARKET_CLOB_BASE}/prices-history\"\n",
    "    params = {\"market\": token_id, \"interval\": interval, \"fidelity\": fidelity}\n",
    "    response = requests.get(url, params=params)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    history = data.get(\"history\", [])\n",
    "    df = pd.DataFrame(history)\n",
    "    if not df.empty:\n",
    "        df[\"timestamp\"] = pd.to_datetime(df[\"t\"], unit=\"s\")\n",
    "        df[\"price\"] = df[\"p\"].astype(float)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Search for relevant markets\n",
    "poly_fed_events = fetch_polymarket_events(\"fed\")\n",
    "poly_gas_events = fetch_polymarket_events(\"gas\")\n",
    "print(f\"Polymarket: {len(poly_fed_events)} Fed-related events, {len(poly_gas_events)} gas-related events\")\n",
    "\n",
    "for e in poly_fed_events[:5]:\n",
    "    print(f\"  Fed: {e.get('title', 'N/A')}\")\n",
    "for e in poly_gas_events[:5]:\n",
    "    print(f\"  Gas: {e.get('title', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1.4 Kalshi ---\n",
    "\n",
    "def fetch_kalshi_markets(series_ticker, status=\"open\", limit=100):\n",
    "    \"\"\"Fetch markets from Kalshi for a given series.\"\"\"\n",
    "    url = f\"{KALSHI_BASE}/markets\"\n",
    "    params = {\"series_ticker\": series_ticker, \"status\": status, \"limit\": limit}\n",
    "    response = requests.get(url, params=params)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    return data.get(\"markets\", [])\n",
    "\n",
    "\n",
    "# Fetch Fed rate and gas price markets\n",
    "kalshi_fed = fetch_kalshi_markets(\"KXFED\")\n",
    "kalshi_gas = fetch_kalshi_markets(\"KXAAAGASM\")\n",
    "print(f\"Kalshi: {len(kalshi_fed)} Fed rate markets (KXFED), {len(kalshi_gas)} gas price markets (KXAAAGASM)\")\n",
    "\n",
    "print(\"\\nFed rate markets:\")\n",
    "for m in kalshi_fed[:5]:\n",
    "    yes_bid = m.get(\"yes_bid\", m.get(\"last_price\", \"N/A\"))\n",
    "    print(f\"  {m.get('ticker', 'N/A')}: {m.get('title', 'N/A')} | Yes: {yes_bid}\")\n",
    "\n",
    "print(\"\\nGas price markets:\")\n",
    "for m in kalshi_gas[:5]:\n",
    "    yes_bid = m.get(\"yes_bid\", m.get(\"last_price\", \"N/A\"))\n",
    "    print(f\"  {m.get('ticker', 'N/A')}: {m.get('title', 'N/A')} | Yes: {yes_bid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Binary Question Design\n",
    "\n",
    "## Design Principles\n",
    "1. **Clear resolution criteria**: each question has an unambiguous yes/no outcome\n",
    "2. **Authoritative data source**: resolution determined by a specific FRED/EIA data release\n",
    "3. **Alignment with prediction markets**: questions map to existing Kalshi/Polymarket contracts where possible\n",
    "4. **Diverse time horizons**: mix of near-term and medium-term questions\n",
    "\n",
    "## Question Categories\n",
    "\n",
    "### Category A: Federal Funds Rate (FOMC Decisions)\n",
    "**Template**: \"Will the Fed cut the federal funds rate at the [Month] 2026 FOMC meeting?\"\n",
    "- Resolves YES if the FRED target rate upper bound (`DFEDTARU`) decreases after the meeting\n",
    "- Resolves NO otherwise\n",
    "\n",
    "### Category B: US Retail Gas Prices\n",
    "**Template**: \"Will the US national average gas price exceed $X.XX per gallon by [date]?\"\n",
    "- Resolves YES if EIA weekly price exceeds the threshold\n",
    "- Thresholds set relative to the current price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2.1 Question Generation ---\n",
    "\n",
    "def generate_fed_questions(fomc_dates, current_rate_upper):\n",
    "    \"\"\"Generate binary questions about Fed rate cuts for upcoming FOMC meetings.\"\"\"\n",
    "    questions = []\n",
    "    for meeting in fomc_dates:\n",
    "        meeting_date = datetime.strptime(meeting[\"date\"], \"%Y-%m-%d\")\n",
    "        if meeting_date > datetime.now():\n",
    "            questions.append({\n",
    "                \"id\": f\"fed_cut_{meeting['meeting'].lower()}_2026\",\n",
    "                \"category\": \"fed_rate\",\n",
    "                \"text\": (\n",
    "                    f\"Will the Fed cut the federal funds rate at the\"\n",
    "                    f\" {meeting['meeting']} 2026 FOMC meeting?\"\n",
    "                ),\n",
    "                \"resolution_date\": meeting[\"date\"],\n",
    "                \"resolution_source\": \"FRED DFEDTARU\",\n",
    "                \"current_rate\": float(current_rate_upper),\n",
    "                \"kalshi_series\": \"KXFED\",\n",
    "                \"meeting_month\": meeting[\"meeting\"].lower(),\n",
    "            })\n",
    "    return questions\n",
    "\n",
    "\n",
    "def generate_gas_questions(current_price, weeks_ahead=(4, 8, 12)):\n",
    "    \"\"\"Generate binary questions about gas prices at various thresholds.\"\"\"\n",
    "    questions = []\n",
    "    offsets = [0.25, 0.50, -0.25]\n",
    "\n",
    "    for weeks in weeks_ahead:\n",
    "        target_date = datetime.now() + timedelta(weeks=weeks)\n",
    "        target_date_str = target_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        for offset in offsets:\n",
    "            threshold = round(current_price + offset, 2)\n",
    "            direction = \"exceed\" if offset > 0 else \"fall below\"\n",
    "\n",
    "            questions.append({\n",
    "                \"id\": f\"gas_{'above' if offset > 0 else 'below'}_{threshold:.2f}_{weeks}w\",\n",
    "                \"category\": \"gas_price\",\n",
    "                \"text\": (\n",
    "                    f\"Will the US national average gas price {direction}\"\n",
    "                    f\" ${threshold:.2f}/gal by the week of {target_date_str}?\"\n",
    "                ),\n",
    "                \"resolution_date\": target_date_str,\n",
    "                \"resolution_source\": \"EIA Weekly Retail Gasoline Prices\",\n",
    "                \"threshold\": threshold,\n",
    "                \"current_price\": float(current_price),\n",
    "                \"kalshi_series\": \"KXAAAGASM\",\n",
    "            })\n",
    "    return questions\n",
    "\n",
    "\n",
    "# Generate questions\n",
    "current_rate = fred_data[\"target_upper\"].dropna().iloc[-1]\n",
    "current_gas = gas_prices[\"value\"].iloc[-1]\n",
    "\n",
    "fed_questions = generate_fed_questions(FOMC_DATES_2026, current_rate)\n",
    "gas_questions = generate_gas_questions(current_gas)\n",
    "all_questions = fed_questions + gas_questions\n",
    "\n",
    "print(f\"Generated {len(fed_questions)} Fed rate questions and {len(gas_questions)} gas price questions\")\n",
    "print(f\"Total: {len(all_questions)} binary questions\\n\")\n",
    "\n",
    "for q in all_questions:\n",
    "    print(f\"  [{q['id']}] {q['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2.2 Collect Prediction Market Probabilities ---\n",
    "\n",
    "def match_kalshi_market(markets, question):\n",
    "    \"\"\"Find the Kalshi market that best matches our question.\"\"\"\n",
    "    for m in markets:\n",
    "        title_lower = m.get(\"title\", \"\").lower()\n",
    "        if question[\"category\"] == \"fed_rate\":\n",
    "            month = question[\"meeting_month\"]\n",
    "            if month in title_lower and (\"cut\" in title_lower or \"rate\" in title_lower):\n",
    "                return m\n",
    "        elif question[\"category\"] == \"gas_price\":\n",
    "            threshold_str = f\"{question['threshold']:.2f}\"\n",
    "            if threshold_str in title_lower or str(question[\"threshold\"]) in title_lower:\n",
    "                return m\n",
    "    return None\n",
    "\n",
    "\n",
    "def match_polymarket_event(events, question):\n",
    "    \"\"\"Find the Polymarket event that best matches our question.\"\"\"\n",
    "    for e in events:\n",
    "        title_lower = e.get(\"title\", \"\").lower()\n",
    "        if question[\"category\"] == \"fed_rate\":\n",
    "            month = question[\"meeting_month\"]\n",
    "            if month in title_lower and \"fed\" in title_lower:\n",
    "                return e\n",
    "        elif question[\"category\"] == \"gas_price\":\n",
    "            if \"gas\" in title_lower:\n",
    "                return e\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_market_price(market_obj, source):\n",
    "    \"\"\"Extract the YES probability from a market object.\"\"\"\n",
    "    if source == \"kalshi\":\n",
    "        # Kalshi prices are in cents (0-100) or dollars (0-1)\n",
    "        for key in [\"yes_bid\", \"last_price\", \"yes_ask\"]:\n",
    "            val = market_obj.get(key)\n",
    "            if val is not None:\n",
    "                val = float(val)\n",
    "                return val / 100 if val > 1 else val\n",
    "    elif source == \"polymarket\":\n",
    "        # Polymarket markets contain outcomes with prices\n",
    "        markets = market_obj.get(\"markets\", [])\n",
    "        if markets:\n",
    "            for mkt in markets:\n",
    "                price = mkt.get(\"outcomePrices\")\n",
    "                if price:\n",
    "                    prices = json.loads(price) if isinstance(price, str) else price\n",
    "                    if prices:\n",
    "                        return float(prices[0])  # YES price\n",
    "        # Try top-level price\n",
    "        if \"price\" in market_obj:\n",
    "            return float(market_obj[\"price\"])\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "def collect_market_probabilities(questions, kalshi_fed, kalshi_gas, poly_fed, poly_gas):\n",
    "    \"\"\"Collect prediction market probabilities for all questions.\"\"\"\n",
    "    results = []\n",
    "\n",
    "    for q in questions:\n",
    "        row = {\"question_id\": q[\"id\"], \"question_text\": q[\"text\"]}\n",
    "\n",
    "        # Kalshi\n",
    "        kalshi_markets = kalshi_fed if q[\"category\"] == \"fed_rate\" else kalshi_gas\n",
    "        match = match_kalshi_market(kalshi_markets, q)\n",
    "        if match:\n",
    "            row[\"kalshi_prob\"] = get_market_price(match, \"kalshi\")\n",
    "            row[\"kalshi_ticker\"] = match.get(\"ticker\", \"\")\n",
    "        else:\n",
    "            row[\"kalshi_prob\"] = np.nan\n",
    "            row[\"kalshi_ticker\"] = None\n",
    "\n",
    "        # Polymarket\n",
    "        poly_events = poly_fed if q[\"category\"] == \"fed_rate\" else poly_gas\n",
    "        match = match_polymarket_event(poly_events, q)\n",
    "        if match:\n",
    "            row[\"polymarket_prob\"] = get_market_price(match, \"polymarket\")\n",
    "        else:\n",
    "            row[\"polymarket_prob\"] = np.nan\n",
    "\n",
    "        results.append(row)\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "market_probs = collect_market_probabilities(\n",
    "    all_questions, kalshi_fed, kalshi_gas, poly_fed_events, poly_gas_events\n",
    ")\n",
    "\n",
    "print(\"Prediction Market Probabilities:\")\n",
    "print(market_probs[[\"question_id\", \"kalshi_prob\", \"polymarket_prob\"]].to_string(index=False))\n",
    "\n",
    "kalshi_coverage = market_probs[\"kalshi_prob\"].notna().sum()\n",
    "poly_coverage = market_probs[\"polymarket_prob\"].notna().sum()\n",
    "print(f\"\\nCoverage: Kalshi {kalshi_coverage}/{len(all_questions)}, Polymarket {poly_coverage}/{len(all_questions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: LLM Forecasting\n",
    "\n",
    "## 3.1 Vanilla Prompting (No Tools)\n",
    "\n",
    "Each model receives:\n",
    "1. A **system prompt** establishing the forecasting persona\n",
    "2. A **user prompt** with the specific binary question and resolution criteria\n",
    "3. Instructions to output a probability between 0.0 and 1.0\n",
    "\n",
    "No external data access \u00e2\u20ac\u201d the model relies entirely on its training data and reasoning.\n",
    "\n",
    "**Key design choice**: prompts deliberately exclude prediction market prices to ensure LLM forecasts are independent and can be fairly compared against market prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3.1 Vanilla Prompting Setup ---\n",
    "\n",
    "VANILLA_SYSTEM_PROMPT = \"\"\"You are an expert forecaster and superforecaster. Your task is to estimate\n",
    "the probability that a specific event will occur. You must provide a single\n",
    "probability estimate between 0.0 (certainly will NOT happen) and 1.0 (certainly WILL happen).\n",
    "\n",
    "Guidelines:\n",
    "- Consider base rates and historical patterns\n",
    "- Account for current economic conditions based on your training data\n",
    "- Be well-calibrated: events you assign 70% probability should occur about 70% of the time\n",
    "- Avoid anchoring to round numbers (0.5, 0.25, 0.75) unless truly justified\n",
    "- Consider both arguments for and against the event occurring\n",
    "\n",
    "You MUST end your response with exactly one line in this format:\n",
    "PROBABILITY: X.XX\n",
    "\n",
    "where X.XX is your probability estimate between 0.00 and 1.00.\"\"\"\n",
    "\n",
    "VANILLA_USER_TEMPLATE = \"\"\"Today's date is {today_date}.\n",
    "\n",
    "Question: {question_text}\n",
    "\n",
    "Resolution criteria: {resolution_criteria}\n",
    "\n",
    "Please reason through this step by step, then provide your probability estimate.\"\"\"\n",
    "\n",
    "\n",
    "def parse_probability_from_response(text):\n",
    "    \"\"\"Extract the probability value from an LLM response.\"\"\"\n",
    "    text = str(text)\n",
    "    # Look for PROBABILITY: X.XX pattern\n",
    "    match = re.search(r\"PROBABILITY:\\s*(0\\.\\d+|1\\.00?|0\\.0+|1\\.0)\", text)\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    # Fallback: look for any decimal between 0 and 1 near the end\n",
    "    matches = re.findall(r\"\\b(0\\.\\d+|1\\.0)\\b\", text[-300:])\n",
    "    if matches:\n",
    "        return float(matches[-1])\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "def get_llm_instance(model_key, temperature=0):\n",
    "    \"\"\"Factory function to create an LLM instance.\"\"\"\n",
    "    config = MODELS[model_key]\n",
    "    if config[\"provider\"] == \"google\":\n",
    "        return ChatGoogleGenerativeAI(model=config[\"model_id\"], temperature=temperature)\n",
    "    elif config[\"provider\"] == \"openai\":\n",
    "        return ChatOpenAI(model=config[\"model_id\"], temperature=temperature)\n",
    "    elif config[\"provider\"] == \"anthropic\":\n",
    "        return ChatAnthropic(model=config[\"model_id\"], temperature=temperature)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown provider: {config['provider']}\")\n",
    "\n",
    "\n",
    "def get_resolution_criteria(question):\n",
    "    \"\"\"Build resolution criteria string for a question.\"\"\"\n",
    "    if question[\"category\"] == \"fed_rate\":\n",
    "        return (\n",
    "            f\"Resolves YES if the FRED federal funds target rate upper bound (DFEDTARU)\"\n",
    "            f\" decreases after the {question['resolution_date']} FOMC meeting.\"\n",
    "            f\" Current target rate upper bound: {question['current_rate']:.2f}%.\"\n",
    "        )\n",
    "    else:\n",
    "        return (\n",
    "            f\"Resolves YES if the EIA weekly US national average retail gasoline price\"\n",
    "            f\" exceeds ${question['threshold']:.2f}/gal by {question['resolution_date']}.\"\n",
    "            f\" Current price: ${question['current_price']:.3f}/gal.\"\n",
    "        )\n",
    "\n",
    "\n",
    "print(\"Vanilla prompting setup complete.\")\n",
    "print(f\"Models to evaluate: {', '.join(MODELS[k]['name'] for k in MODELS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3.1 Run Vanilla Forecasting ---\n",
    "\n",
    "def run_vanilla_forecasting(questions, cache):\n",
    "    \"\"\"Run vanilla (no-tool) LLM forecasting across all models and questions.\"\"\"\n",
    "    results = []\n",
    "    today = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    for model_key in MODELS:\n",
    "        print(f\"\\nForecasting with {MODELS[model_key]['name']} (vanilla)...\")\n",
    "        llm = get_llm_instance(model_key, temperature=0)\n",
    "\n",
    "        for q in tqdm(questions, desc=MODELS[model_key][\"name\"]):\n",
    "            cache_key = get_cache_key(\"vanilla\", model_key, q[\"id\"])\n",
    "\n",
    "            if cache_key in cache:\n",
    "                output = cache[cache_key][\"output\"]\n",
    "            else:\n",
    "                criteria = get_resolution_criteria(q)\n",
    "                messages = [\n",
    "                    SystemMessage(content=VANILLA_SYSTEM_PROMPT),\n",
    "                    HumanMessage(content=VANILLA_USER_TEMPLATE.format(\n",
    "                        today_date=today,\n",
    "                        question_text=q[\"text\"],\n",
    "                        resolution_criteria=criteria,\n",
    "                    )),\n",
    "                ]\n",
    "\n",
    "                try:\n",
    "                    response = llm.invoke(messages)\n",
    "                    output = response.content\n",
    "                except Exception as e:\n",
    "                    print(f\"  Error ({model_key}, {q['id']}): {e}\")\n",
    "                    output = f\"ERROR: {str(e)}\"\n",
    "\n",
    "                cache[cache_key] = {\"output\": output}\n",
    "                save_cache(cache)\n",
    "\n",
    "            prob = parse_probability_from_response(output)\n",
    "            results.append({\n",
    "                \"question_id\": q[\"id\"],\n",
    "                \"model\": MODELS[model_key][\"name\"],\n",
    "                \"method\": \"vanilla\",\n",
    "                \"probability\": prob,\n",
    "                \"raw_output\": str(output)[-300:],\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "cache = load_cache()\n",
    "vanilla_results = run_vanilla_forecasting(all_questions, cache)\n",
    "print(f\"\\nCollected {len(vanilla_results)} vanilla forecasts\")\n",
    "print(vanilla_results.groupby(\"model\")[\"probability\"].describe().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Tool-Augmented LLM Forecasting\n",
    "\n",
    "Now we give the same models access to real-time data tools:\n",
    "1. **`get_federal_funds_rate`**: Fetch current and historical federal funds rate data from FRED\n",
    "2. **`get_gas_prices`**: Fetch current and historical gasoline prices from EIA\n",
    "3. **`get_fomc_schedule`**: Get the 2026 FOMC meeting schedule with past/upcoming status\n",
    "\n",
    "We use LangChain's `bind_tools()` interface, which works across all three providers. The model decides which tools to call, receives the results, and then produces its forecast.\n",
    "\n",
    "**The key question: does tool access improve forecasting accuracy?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3.2 Tool Definitions ---\n",
    "\n",
    "@tool\n",
    "def get_federal_funds_rate(lookback_days: int = 90) -> str:\n",
    "    \"\"\"Fetch the current and recent federal funds rate data from FRED.\n",
    "\n",
    "    Args:\n",
    "        lookback_days: Number of days of historical data to return (default 90)\n",
    "\n",
    "    Returns:\n",
    "        A string summary of the federal funds rate data.\n",
    "    \"\"\"\n",
    "    fred = Fred(api_key=FRED_API_KEY)\n",
    "    start = (datetime.now() - timedelta(days=lookback_days)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    rate = fred.get_series(\"DFF\", observation_start=start)\n",
    "    target_upper = fred.get_series(\"DFEDTARU\", observation_start=start)\n",
    "    target_lower = fred.get_series(\"DFEDTARL\", observation_start=start)\n",
    "\n",
    "    current_rate = rate.dropna().iloc[-1]\n",
    "    current_upper = target_upper.dropna().iloc[-1]\n",
    "    current_lower = target_lower.dropna().iloc[-1]\n",
    "\n",
    "    changes = target_upper.diff().dropna()\n",
    "    cuts = changes[changes < 0]\n",
    "    hikes = changes[changes > 0]\n",
    "\n",
    "    return (\n",
    "        f\"Federal Funds Rate Data (last {lookback_days} days):\\n\"\n",
    "        f\"- Current effective rate: {current_rate:.2f}%\\n\"\n",
    "        f\"- Current target range: {current_lower:.2f}% - {current_upper:.2f}%\\n\"\n",
    "        f\"- Rate cuts in period: {len(cuts)} (total: {cuts.sum():.2f}pp)\\n\"\n",
    "        f\"- Rate hikes in period: {len(hikes)} (total: {hikes.sum():.2f}pp)\\n\"\n",
    "        f\"- Rate on {rate.dropna().index[-1].strftime('%Y-%m-%d')}: {current_rate:.2f}%\\n\"\n",
    "        f\"- Rate {lookback_days} days ago: {rate.dropna().iloc[0]:.2f}%\"\n",
    "    )\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_gas_prices(weeks: int = 12) -> str:\n",
    "    \"\"\"Fetch recent US retail gasoline price data from the EIA.\n",
    "\n",
    "    Args:\n",
    "        weeks: Number of weeks of historical data to return (default 12)\n",
    "\n",
    "    Returns:\n",
    "        A string summary of gasoline price data.\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        \"api_key\": EIA_API_KEY,\n",
    "        \"frequency\": \"weekly\",\n",
    "        \"data[0]\": \"value\",\n",
    "        \"facets[product][]\": \"EPMR\",\n",
    "        \"facets[duoarea][]\": \"NUS\",\n",
    "        \"sort[0][column]\": \"period\",\n",
    "        \"sort[0][direction]\": \"desc\",\n",
    "        \"offset\": 0,\n",
    "        \"length\": weeks,\n",
    "    }\n",
    "    response = requests.get(EIA_GAS_PRICE_URL, params=params)\n",
    "    data = response.json()[\"response\"][\"data\"]\n",
    "\n",
    "    prices = [(d[\"period\"], float(d[\"value\"])) for d in data]\n",
    "    prices.sort(key=lambda x: x[0])\n",
    "\n",
    "    current = prices[-1][1]\n",
    "    high = max(p[1] for p in prices)\n",
    "    low = min(p[1] for p in prices)\n",
    "    avg = sum(p[1] for p in prices) / len(prices)\n",
    "    trend = current - prices[0][1]\n",
    "\n",
    "    return (\n",
    "        f\"US Retail Gasoline Prices (last {weeks} weeks):\\n\"\n",
    "        f\"- Current price: ${current:.3f}/gal (week of {prices[-1][0]})\\n\"\n",
    "        f\"- {weeks}-week high: ${high:.3f}/gal\\n\"\n",
    "        f\"- {weeks}-week low: ${low:.3f}/gal\\n\"\n",
    "        f\"- {weeks}-week average: ${avg:.3f}/gal\\n\"\n",
    "        f\"- Trend: {'Up' if trend > 0 else 'Down'} ${abs(trend):.3f}/gal over {weeks} weeks\\n\"\n",
    "        f\"- Recent weekly prices: {', '.join(f'${p[1]:.3f}' for p in prices[-6:])}\"\n",
    "    )\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_fomc_schedule() -> str:\n",
    "    \"\"\"Get the 2026 FOMC meeting schedule and status.\n",
    "\n",
    "    Returns:\n",
    "        A string listing upcoming FOMC meetings with dates and status.\n",
    "    \"\"\"\n",
    "    lines = []\n",
    "    for m in FOMC_DATES_2026:\n",
    "        meeting_date = datetime.strptime(m[\"date\"], \"%Y-%m-%d\")\n",
    "        status = \"PAST\" if meeting_date < datetime.now() else \"UPCOMING\"\n",
    "        lines.append(f\"  {m['meeting']} 2026 ({m['date']}): {status}\")\n",
    "\n",
    "    return (\n",
    "        \"2026 FOMC Meeting Schedule:\\n\"\n",
    "        + \"\\n\".join(lines)\n",
    "        + \"\\n\\nNote: The Fed announces its rate decision on the second day of each meeting.\"\n",
    "    )\n",
    "\n",
    "\n",
    "TOOLS = [get_federal_funds_rate, get_gas_prices, get_fomc_schedule]\n",
    "print(f\"Defined {len(TOOLS)} tools: {[t.name for t in TOOLS]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3.2 Run Tool-Augmented Forecasting ---\n",
    "\n",
    "TOOL_SYSTEM_PROMPT = \"\"\"You are an expert forecaster with access to real-time economic data tools.\n",
    "Your task is to estimate the probability that a specific event will occur.\n",
    "\n",
    "You have access to the following tools:\n",
    "- get_federal_funds_rate: Fetch current and historical federal funds rate data\n",
    "- get_gas_prices: Fetch recent US retail gasoline price data\n",
    "- get_fomc_schedule: Get the 2026 FOMC meeting schedule\n",
    "\n",
    "Instructions:\n",
    "1. FIRST, use the relevant tools to gather current data\n",
    "2. THEN, reason through the question using the data you retrieved\n",
    "3. Consider base rates, trends, and current conditions\n",
    "4. Provide a well-calibrated probability estimate\n",
    "\n",
    "You MUST end your response with exactly one line in this format:\n",
    "PROBABILITY: X.XX\"\"\"\n",
    "\n",
    "TOOL_USER_TEMPLATE = \"\"\"Today's date is {today_date}.\n",
    "\n",
    "Question: {question_text}\n",
    "\n",
    "Resolution criteria: {resolution_criteria}\n",
    "\n",
    "Please use the available tools to gather relevant data, then reason through this\n",
    "step by step and provide your probability estimate.\"\"\"\n",
    "\n",
    "\n",
    "def run_tool_augmented_forecasting(questions, cache):\n",
    "    \"\"\"Run tool-augmented LLM forecasting with LangChain tool calling.\"\"\"\n",
    "    results = []\n",
    "    today = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    tool_map = {t.name: t for t in TOOLS}\n",
    "\n",
    "    for model_key in MODELS:\n",
    "        print(f\"\\nForecasting with {MODELS[model_key]['name']} (with tools)...\")\n",
    "        llm = get_llm_instance(model_key, temperature=0)\n",
    "        llm_with_tools = llm.bind_tools(TOOLS)\n",
    "\n",
    "        for q in tqdm(questions, desc=f\"{MODELS[model_key]['name']} + tools\"):\n",
    "            cache_key = get_cache_key(\"tool\", model_key, q[\"id\"])\n",
    "\n",
    "            if cache_key in cache:\n",
    "                output = cache[cache_key][\"output\"]\n",
    "            else:\n",
    "                criteria = get_resolution_criteria(q)\n",
    "                messages = [\n",
    "                    SystemMessage(content=TOOL_SYSTEM_PROMPT),\n",
    "                    HumanMessage(content=TOOL_USER_TEMPLATE.format(\n",
    "                        today_date=today,\n",
    "                        question_text=q[\"text\"],\n",
    "                        resolution_criteria=criteria,\n",
    "                    )),\n",
    "                ]\n",
    "\n",
    "                # Agentic loop: let the model call tools until it produces a final answer\n",
    "                output = \"ERROR: max iterations reached\"\n",
    "                for _ in range(5):\n",
    "                    try:\n",
    "                        resp = llm_with_tools.invoke(messages)\n",
    "                    except Exception as e:\n",
    "                        output = f\"ERROR: {str(e)}\"\n",
    "                        break\n",
    "\n",
    "                    messages.append(resp)\n",
    "\n",
    "                    if resp.tool_calls:\n",
    "                        for tc in resp.tool_calls:\n",
    "                            tool_fn = tool_map[tc[\"name\"]]\n",
    "                            tool_result = tool_fn.invoke(tc[\"args\"])\n",
    "                            messages.append(ToolMessage(\n",
    "                                content=str(tool_result),\n",
    "                                tool_call_id=tc[\"id\"],\n",
    "                            ))\n",
    "                    else:\n",
    "                        output = resp.content\n",
    "                        break\n",
    "\n",
    "                cache[cache_key] = {\"output\": output}\n",
    "                save_cache(cache)\n",
    "\n",
    "            prob = parse_probability_from_response(output)\n",
    "            results.append({\n",
    "                \"question_id\": q[\"id\"],\n",
    "                \"model\": MODELS[model_key][\"name\"],\n",
    "                \"method\": \"tool_augmented\",\n",
    "                \"probability\": prob,\n",
    "                \"raw_output\": str(output)[-300:],\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "cache = load_cache()\n",
    "tool_results = run_tool_augmented_forecasting(all_questions, cache)\n",
    "print(f\"\\nCollected {len(tool_results)} tool-augmented forecasts\")\n",
    "print(tool_results.groupby(\"model\")[\"probability\"].describe().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4: Scoring and Evaluation\n",
    "\n",
    "## 4.1 Brier Score\n",
    "\n",
    "$$BS = \\frac{1}{N} \\sum_{i=1}^{N} (p_i - o_i)^2$$\n",
    "\n",
    "Reference benchmarks:\n",
    "- **Perfect forecaster**: BS = 0.000\n",
    "- **Always predict 50%** (no skill): BS = 0.250\n",
    "- **Always 100% confident and wrong**: BS = 1.000\n",
    "\n",
    "## 4.2 Hypothetical Returns\n",
    "\n",
    "We simulate a threshold-based betting strategy:\n",
    "- If forecast differs from market price by more than $\\delta$ (default 10pp):\n",
    "  - **Buy YES** if forecast > market + $\\delta$ (cost = market price, payout = $1 if YES)\n",
    "  - **Buy NO** if forecast < market - $\\delta$ (cost = 1 - market price, payout = $1 if NO)\n",
    "- Each bet is $1 notional\n",
    "\n",
    "This tests whether the forecaster can identify **mispriced** markets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4.1 Resolution & Scoring ---\n",
    "\n",
    "def resolve_questions(questions, fred_data, gas_prices):\n",
    "    \"\"\"Determine the actual outcomes for resolved questions.\"\"\"\n",
    "    outcomes = {}\n",
    "    today = datetime.now()\n",
    "\n",
    "    for q in questions:\n",
    "        res_date = datetime.strptime(q[\"resolution_date\"], \"%Y-%m-%d\")\n",
    "        if res_date > today:\n",
    "            outcomes[q[\"id\"]] = np.nan  # Not yet resolved\n",
    "            continue\n",
    "\n",
    "        if q[\"category\"] == \"fed_rate\":\n",
    "            target = fred_data[\"target_upper\"]\n",
    "            pre = target[target.index < res_date]\n",
    "            post = target[target.index >= res_date]\n",
    "            if len(pre) > 0 and len(post) > 0:\n",
    "                outcomes[q[\"id\"]] = 1 if post.iloc[0] < pre.iloc[-1] else 0\n",
    "            else:\n",
    "                outcomes[q[\"id\"]] = np.nan\n",
    "\n",
    "        elif q[\"category\"] == \"gas_price\":\n",
    "            prices_before = gas_prices[\n",
    "                gas_prices[\"period\"] <= res_date.strftime(\"%Y-%m-%d\")\n",
    "            ]\n",
    "            if len(prices_before) > 0:\n",
    "                latest = prices_before[\"value\"].iloc[-1]\n",
    "                outcomes[q[\"id\"]] = 1 if latest > q[\"threshold\"] else 0\n",
    "            else:\n",
    "                outcomes[q[\"id\"]] = np.nan\n",
    "\n",
    "    return outcomes\n",
    "\n",
    "\n",
    "def compute_brier_scores(forecast_df, outcomes):\n",
    "    \"\"\"Compute Brier scores for each forecast.\"\"\"\n",
    "    df = forecast_df.copy()\n",
    "    df[\"outcome\"] = df[\"question_id\"].map(outcomes)\n",
    "    df = df.dropna(subset=[\"outcome\", \"probability\"])\n",
    "\n",
    "    if len(df) == 0:\n",
    "        print(\"WARNING: No resolved questions with valid forecasts. Brier scores cannot be computed.\")\n",
    "        return df\n",
    "\n",
    "    df[\"brier_score\"] = (df[\"probability\"] - df[\"outcome\"]) ** 2\n",
    "    return df\n",
    "\n",
    "\n",
    "def compute_returns(forecast_df, market_probs, outcomes, delta=0.10):\n",
    "    \"\"\"Compute hypothetical returns from threshold-based betting.\"\"\"\n",
    "    df = forecast_df.copy()\n",
    "    df[\"outcome\"] = df[\"question_id\"].map(outcomes)\n",
    "\n",
    "    # Use Kalshi as the market benchmark\n",
    "    df = df.merge(\n",
    "        market_probs[[\"question_id\", \"kalshi_prob\"]],\n",
    "        on=\"question_id\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    df = df.dropna(subset=[\"outcome\", \"probability\", \"kalshi_prob\"])\n",
    "\n",
    "    rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        p_forecast = row[\"probability\"]\n",
    "        p_market = row[\"kalshi_prob\"]\n",
    "        outcome = row[\"outcome\"]\n",
    "\n",
    "        if p_forecast > p_market + delta:\n",
    "            profit = outcome * 1.0 - p_market\n",
    "            rows.append({**row, \"action\": \"BUY_YES\", \"profit\": profit})\n",
    "        elif p_forecast < p_market - delta:\n",
    "            profit = (1 - outcome) * 1.0 - (1 - p_market)\n",
    "            rows.append({**row, \"action\": \"BUY_NO\", \"profit\": profit})\n",
    "        else:\n",
    "            rows.append({**row, \"action\": \"NO_BET\", \"profit\": 0.0})\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "print(\"Scoring functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4.2 Compute Results ---\n",
    "\n",
    "# Combine all forecasts\n",
    "all_forecasts = pd.concat([vanilla_results, tool_results], ignore_index=True)\n",
    "\n",
    "# Add prediction market forecasts as their own \"model\"\n",
    "market_rows = []\n",
    "for _, row in market_probs.iterrows():\n",
    "    if pd.notna(row.get(\"kalshi_prob\")):\n",
    "        market_rows.append({\n",
    "            \"question_id\": row[\"question_id\"],\n",
    "            \"model\": \"Kalshi (Market)\",\n",
    "            \"method\": \"prediction_market\",\n",
    "            \"probability\": row[\"kalshi_prob\"],\n",
    "            \"raw_output\": \"\",\n",
    "        })\n",
    "    if pd.notna(row.get(\"polymarket_prob\")):\n",
    "        market_rows.append({\n",
    "            \"question_id\": row[\"question_id\"],\n",
    "            \"model\": \"Polymarket (Market)\",\n",
    "            \"method\": \"prediction_market\",\n",
    "            \"probability\": row[\"polymarket_prob\"],\n",
    "            \"raw_output\": \"\",\n",
    "        })\n",
    "\n",
    "if market_rows:\n",
    "    all_forecasts = pd.concat([all_forecasts, pd.DataFrame(market_rows)], ignore_index=True)\n",
    "\n",
    "print(f\"Total forecasts: {len(all_forecasts)}\")\n",
    "print(f\"Forecasters: {all_forecasts.groupby(['model', 'method']).size().reset_index(name='n').to_string(index=False)}\")\n",
    "\n",
    "# Resolve questions\n",
    "outcomes = resolve_questions(all_questions, fred_data, gas_prices)\n",
    "resolved_count = sum(1 for v in outcomes.values() if pd.notna(v))\n",
    "unresolved_count = sum(1 for v in outcomes.values() if pd.isna(v))\n",
    "print(f\"\\nResolved: {resolved_count}/{len(outcomes)} questions\")\n",
    "print(f\"Unresolved (future): {unresolved_count}/{len(outcomes)} questions\")\n",
    "\n",
    "for qid, outcome in outcomes.items():\n",
    "    status = f\"outcome={int(outcome)}\" if pd.notna(outcome) else \"pending\"\n",
    "    print(f\"  {qid}: {status}\")\n",
    "\n",
    "# Compute Brier scores\n",
    "scored_df = compute_brier_scores(all_forecasts, outcomes)\n",
    "if len(scored_df) > 0:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"BRIER SCORES\")\n",
    "    print(\"=\" * 60)\n",
    "    brier_summary = scored_df.groupby([\"method\", \"model\"])[\"brier_score\"].agg([\"mean\", \"std\", \"count\"])\n",
    "    brier_summary.columns = [\"Mean Brier\", \"Std Brier\", \"N\"]\n",
    "    print(brier_summary.sort_values(\"Mean Brier\").round(4))\n",
    "else:\n",
    "    print(\"\\nNo questions have resolved yet -- Brier scores will be available after resolution dates pass.\")\n",
    "\n",
    "# Compute returns\n",
    "returns_df = compute_returns(all_forecasts, market_probs, outcomes, delta=0.10)\n",
    "if len(returns_df) > 0 and returns_df[\"profit\"].abs().sum() > 0:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"HYPOTHETICAL RETURNS (delta=0.10)\")\n",
    "    print(\"=\" * 60)\n",
    "    returns_summary = returns_df.groupby([\"method\", \"model\"])[\"profit\"].agg([\"sum\", \"mean\", \"count\"])\n",
    "    returns_summary.columns = [\"Total P&L ($)\", \"Avg P&L/Bet ($)\", \"N Bets\"]\n",
    "    print(returns_summary.sort_values(\"Total P&L ($)\", ascending=False).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5: Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5.1 Brier Score and Returns Charts ---\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Plot 1: Mean Brier Score by forecaster\n",
    "if len(scored_df) > 0:\n",
    "    brier_by_method = scored_df.groupby([\"model\", \"method\"])[\"brier_score\"].mean().reset_index()\n",
    "    sns.barplot(data=brier_by_method, x=\"model\", y=\"brier_score\", hue=\"method\", ax=axs[0])\n",
    "    axs[0].set_title(\"Mean Brier Score by Forecaster\\n(Lower is Better)\")\n",
    "    axs[0].set_xlabel(\"\")\n",
    "    axs[0].set_ylabel(\"Mean Brier Score\")\n",
    "    axs[0].tick_params(axis=\"x\", rotation=45)\n",
    "    axs[0].axhline(y=0.25, color=\"red\", linestyle=\"--\", alpha=0.5, label=\"No-skill (0.25)\")\n",
    "    axs[0].legend(fontsize=7)\n",
    "else:\n",
    "    axs[0].text(0.5, 0.5, \"No resolved questions yet\", ha=\"center\", va=\"center\", transform=axs[0].transAxes)\n",
    "    axs[0].set_title(\"Mean Brier Score (pending)\")\n",
    "\n",
    "# Plot 2: Brier Score by question category\n",
    "if len(scored_df) > 0:\n",
    "    q_categories = pd.DataFrame(all_questions)[[\"id\", \"category\"]].rename(columns={\"id\": \"question_id\"})\n",
    "    scored_with_cat = scored_df.merge(q_categories, on=\"question_id\")\n",
    "    sns.barplot(data=scored_with_cat, x=\"category\", y=\"brier_score\", hue=\"method\", ax=axs[1])\n",
    "    axs[1].set_title(\"Brier Score by Category\")\n",
    "    axs[1].set_xlabel(\"\")\n",
    "    axs[1].set_ylabel(\"Mean Brier Score\")\n",
    "    axs[1].legend(fontsize=7)\n",
    "else:\n",
    "    axs[1].text(0.5, 0.5, \"No resolved questions yet\", ha=\"center\", va=\"center\", transform=axs[1].transAxes)\n",
    "    axs[1].set_title(\"Brier by Category (pending)\")\n",
    "\n",
    "# Plot 3: Cumulative returns\n",
    "if len(returns_df) > 0 and returns_df[\"profit\"].abs().sum() > 0:\n",
    "    for name, group in returns_df.groupby([\"model\", \"method\"]):\n",
    "        label = f\"{name[0]} ({name[1]})\"\n",
    "        cumulative = group[\"profit\"].cumsum()\n",
    "        axs[2].plot(range(len(cumulative)), cumulative, label=label, marker=\"o\", markersize=3)\n",
    "    axs[2].set_title(\"Cumulative Hypothetical Returns\")\n",
    "    axs[2].set_xlabel(\"Bet Number\")\n",
    "    axs[2].set_ylabel(\"Cumulative P&L ($)\")\n",
    "    axs[2].axhline(y=0, color=\"black\", linestyle=\"-\", linewidth=0.5)\n",
    "    axs[2].legend(fontsize=6)\n",
    "else:\n",
    "    axs[2].text(0.5, 0.5, \"No bets placed yet\", ha=\"center\", va=\"center\", transform=axs[2].transAxes)\n",
    "    axs[2].set_title(\"Cumulative Returns (pending)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5.2 Calibration Plot ---\n",
    "\n",
    "def plot_calibration(scored_df, n_bins=5):\n",
    "    \"\"\"Plot calibration curves for each forecaster.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    for (model, method), group in scored_df.groupby([\"model\", \"method\"]):\n",
    "        probs = group[\"probability\"].values\n",
    "        outcomes_arr = group[\"outcome\"].values\n",
    "\n",
    "        bins = np.linspace(0, 1, n_bins + 1)\n",
    "        bin_means = []\n",
    "        bin_freqs = []\n",
    "        for i in range(n_bins):\n",
    "            mask = (probs >= bins[i]) & (probs < bins[i + 1])\n",
    "            if mask.sum() > 0:\n",
    "                bin_means.append(probs[mask].mean())\n",
    "                bin_freqs.append(outcomes_arr[mask].mean())\n",
    "\n",
    "        if bin_means:\n",
    "            ax.plot(bin_means, bin_freqs, marker=\"o\", label=f\"{model} ({method})\")\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], \"k--\", label=\"Perfect calibration\")\n",
    "    ax.set_xlabel(\"Predicted Probability\")\n",
    "    ax.set_ylabel(\"Observed Frequency\")\n",
    "    ax.set_title(\"Calibration Plot\")\n",
    "    ax.legend(loc=\"lower right\", fontsize=7)\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if len(scored_df) > 0:\n",
    "    plot_calibration(scored_df)\n",
    "else:\n",
    "    print(\"Calibration plot will be available once questions resolve.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5.3 Forecast Comparison Heatmap ---\n",
    "\n",
    "def plot_forecast_heatmap(forecasts, questions):\n",
    "    \"\"\"Heatmap of all probabilities: questions (rows) x forecasters (columns).\"\"\"\n",
    "    forecasts = forecasts.copy()\n",
    "    forecasts[\"forecaster\"] = forecasts[\"model\"] + \"\\n(\" + forecasts[\"method\"] + \")\"\n",
    "\n",
    "    pivot = forecasts.pivot_table(\n",
    "        index=\"question_id\",\n",
    "        columns=\"forecaster\",\n",
    "        values=\"probability\",\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(16, max(8, len(pivot) * 0.5)))\n",
    "    sns.heatmap(\n",
    "        pivot, annot=True, fmt=\".2f\", cmap=\"RdYlGn\", center=0.5,\n",
    "        vmin=0, vmax=1, ax=ax, cbar_kws={\"label\": \"Probability\"},\n",
    "    )\n",
    "    ax.set_title(\"Forecast Comparison Heatmap\")\n",
    "    ax.set_ylabel(\"Question\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_forecast_heatmap(all_forecasts, all_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 6: Discussion and Conclusions\n",
    "\n",
    "## Key Questions\n",
    "\n",
    "1. **Do prediction markets outperform LLMs?**\n",
    "   - Compare Brier scores of Kalshi/Polymarket vs. vanilla LLMs vs. tool-augmented LLMs\n",
    "   - Markets aggregate information from many participants; can a single LLM match this?\n",
    "\n",
    "2. **Does tool access improve LLM forecasting?**\n",
    "   - Compare vanilla vs. tool-augmented Brier scores for each model\n",
    "   - Real-time data should help, but does the model use it effectively?\n",
    "\n",
    "3. **Which LLM is the best forecaster?**\n",
    "   - Rank GPT-5, Gemini, Claude by Brier score and returns\n",
    "   - Does the ranking change between vanilla and tool-augmented conditions?\n",
    "\n",
    "4. **Are there category-specific patterns?**\n",
    "   - Fed rate questions may favor models with strong economic reasoning\n",
    "   - Gas price questions may favor models with access to trend data\n",
    "\n",
    "5. **Can any forecaster generate positive returns against the market?**\n",
    "   - A positive total P&L means the forecaster identified genuine mispricings\n",
    "   - How sensitive are returns to the betting threshold delta?\n",
    "\n",
    "## Limitations\n",
    "\n",
    "- **Small sample size**: limited by the number of resolvable questions within the project timeframe\n",
    "- **Single market snapshot**: prediction market prices were captured at one point in time (markets update continuously)\n",
    "- **LLM training cutoffs**: models may lack recent economic data in their training, which is exactly what tool augmentation addresses\n",
    "- **Question design**: our questions may not perfectly overlap with existing prediction market contracts\n",
    "- **Not all questions may resolve**: FOMC meetings later in 2026 won't have outcomes during the semester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6.1 Summary Statistics ---\n",
    "\n",
    "if len(scored_df) > 0:\n",
    "    summary = scored_df.groupby([\"method\", \"model\"]).agg({\n",
    "        \"brier_score\": [\"mean\", \"std\"],\n",
    "        \"probability\": [\"mean\", \"std\"],\n",
    "        \"question_id\": \"count\",\n",
    "    }).round(4)\n",
    "    summary.columns = [\"Mean Brier\", \"Std Brier\", \"Mean Prob\", \"Std Prob\", \"N\"]\n",
    "    summary = summary.sort_values(\"Mean Brier\")\n",
    "\n",
    "    print(\"=\" * 70)\n",
    "    print(\"FINAL RESULTS: Forecaster Ranking by Brier Score\")\n",
    "    print(\"=\" * 70)\n",
    "    print(summary)\n",
    "    print(f\"\\nBaseline (always predict 0.5): Brier = 0.2500\")\n",
    "    print(f\"Perfect forecaster: Brier = 0.0000\")\n",
    "else:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"FORECAST SUMMARY (questions not yet resolved)\")\n",
    "    print(\"=\" * 70)\n",
    "    prob_summary = all_forecasts.groupby([\"method\", \"model\"])[\"probability\"].agg([\"mean\", \"std\", \"count\"])\n",
    "    prob_summary.columns = [\"Mean Prob\", \"Std Prob\", \"N\"]\n",
    "    print(prob_summary.round(4))\n",
    "    print(\"\\nBrier scores and returns will be computed after questions resolve.\")\n",
    "    print(\"Re-run this notebook after resolution dates to see final results.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}